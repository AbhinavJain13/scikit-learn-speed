

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Benchmarks for mixture &mdash; Vbench performance benchmarks for scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.12-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Vbench performance benchmarks for scikit-learn" href="index.html" />
    <link rel="next" title="Benchmarks for naive_bayes" href="vb_naive_bayes.html" />
    <link rel="prev" title="Benchmarks for manifold" href="vb_manifold.html" />

  <!-- Reference the theme's stylesheet on the Google CDN -->
  <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/excite-bike/jquery-ui.css"
        type="text/css" rel="Stylesheet" />
 
  <!-- Reference jQuery and jQuery UI from the CDN. Remember
       that the order of these two elements is important -->
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js"></script>

<script type="text/javascript">
      $(function(){
        $(".profiler-output").accordion({collapsible: true, header: "p", active: false} );
      });
    </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="http://scikit-learn.org/">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="quick_start.html">Speed Quick Start</a></li>
            <li><a href="http://scikit-learn.org/dev/user_guide.html">User's Guide</a></li>
            <li><a href="http://scikit-learn.org/dev/developers/performance.html">Performance</a></li>
            <li><a href="http://github.com/scikit-learn/scikit-learn">Github</a></li>
            <li><a href="http://github.com/vene/scikit-learn-speed">Speed Github</a></li>
       </ul>
</div>
<!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
          <h3>Table Of Contents</h3>
          <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vb_cluster.html">Benchmarks for cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_covariance.html">Benchmarks for covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_decomposition.html">Benchmarks for decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_ensemble.html">Benchmarks for ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_gaussian_process.html">Benchmarks for gaussian_process</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_linear_model.html">Benchmarks for linear_model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_manifold.html">Benchmarks for manifold</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Benchmarks for mixture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#dpgmm-blobs">DPGMM-blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gmm-blobs">GMM-blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vbgmm-blobs">VBGMM-blobs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vb_naive_bayes.html">Benchmarks for naive_bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_neighbors.html">Benchmarks for neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_pls.html">Benchmarks for pls</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_semi_supervised.html">Benchmarks for semi_supervised</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_svm.html">Benchmarks for svm</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_tree.html">Benchmarks for tree</a></li>
</ul>

          <!--
	   <div class="rel rellarge">
	     
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  --
	<div class="rellink">
	<a href="vb_manifold.html" title="Benchmarks for manifold"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Benchmarks for m...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for manifold
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="vb_naive_bayes.html" title="Benchmarks for naive_bayes"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Benchmarks for n...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for naive_bayes
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page --
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.12-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Benchmarks for mixture</a><ul>
<li><a class="reference internal" href="#dpgmm-blobs">DPGMM-blobs</a></li>
<li><a class="reference internal" href="#gmm-blobs">GMM-blobs</a></li>
<li><a class="reference internal" href="#vbgmm-blobs">VBGMM-blobs</a></li>
</ul>
</li>
</ul>

    
  -->
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="benchmarks-for-mixture">
<h1>Benchmarks for mixture<a class="headerlink" href="#benchmarks-for-mixture" title="Permalink to this headline">¶</a></h1>
<div class="section" id="dpgmm-blobs">
<h2>DPGMM-blobs<a class="headerlink" href="#dpgmm-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">DPGMM</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">&#39;n_components&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">&#39;covariance_type&#39;</span><span class="p">:</span> <span class="s">&#39;full&#39;</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">DPGMM</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/DPGMM-blobs-step0-timing.png" src="_images/DPGMM-blobs-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/DPGMM-blobs-step0-memory.png" src="_images/DPGMM-blobs-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         41557 function calls in 1.315 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.315    1.315 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.315    1.315 &lt;f&gt;:1(&lt;module&gt;)
     1    0.001    0.001    1.315    1.315 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:471(fit)
    10    0.000    0.000    0.846    0.085 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:371(_do_mstep)
    10    0.011    0.001    0.450    0.045 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:284(_update_means)
   100    0.414    0.004    0.431    0.004 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:365(lstsq)
    10    0.024    0.002    0.396    0.040 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:303(_update_precisions)
    10    0.001    0.000    0.272    0.027 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:224(eval)
    10    0.003    0.000    0.263    0.026 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:92(_bound_state_log_lik)
   100    0.002    0.000    0.260    0.003 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:86(_sym_quad_form)
   100    0.004    0.000    0.257    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:1693(cdist)
   100    0.245    0.002    0.245    0.002 {scipy.spatial._distance_wrap.cdist_mahalanobis_wrap}
   100    0.009    0.000    0.219    0.002 /tmp/vb_sklearn/sklearn/utils/extmath.py:323(pinvh)
   100    0.171    0.002    0.181    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp.py:196(eigh)
     1    0.000    0.000    0.156    0.156 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:695(fit)
     1    0.000    0.000    0.156    0.156 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:151(k_means)
    10    0.001    0.000    0.155    0.015 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:304(_kmeans_single)
   121    0.014    0.000    0.117    0.001 /tmp/vb_sklearn/sklearn/metrics/pairwise.py:105(euclidean_distances)
    10    0.000    0.000    0.116    0.012 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:483(_init_centroids)
    10    0.013    0.001    0.115    0.012 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:36(_k_init)
   421    0.106    0.000    0.106    0.000 {numpy.core._dotblas.dot}
   100    0.070    0.001    0.080    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:336(det)
   121    0.001    0.000    0.052    0.000 /tmp/vb_sklearn/sklearn/metrics/pairwise.py:56(check_pairwise_arrays)
   364    0.001    0.000    0.045    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:110(atleast2d_or_csr)
   364    0.002    0.000    0.045    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:87(_atleast2d_or_sparse)
  2344    0.039    0.000    0.039    0.000 {method 'sum' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.037    0.004 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:449(_logprior)
   970    0.010    0.000    0.034    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:14(_assert_all_finite)
   121    0.002    0.000    0.033    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:70(safe_sparse_dot)
   500    0.021    0.000    0.031    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    21    0.000    0.000    0.030    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:436(_labels_inertia)
    21    0.006    0.000    0.029    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:419(_labels_inertia_precompute_dense)
    10    0.000    0.000    0.029    0.003 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:413(_bound_precisions)
   100    0.002    0.000    0.029    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:68(_bound_wishart)
   364    0.002    0.000    0.026    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:75(array2d)
  1733    0.003    0.000    0.023    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
  1733    0.013    0.000    0.020    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
   242    0.001    0.000    0.019    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(safe_asarray)
   200    0.010    0.000    0.018    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:58(wishart_logz)
   210    0.007    0.000    0.016    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:48(wishart_log_det)
   972    0.003    0.000    0.015    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   242    0.001    0.000    0.013    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:21(assert_all_finite)
   100    0.000    0.000    0.010    0.000 {map}
  1837    0.003    0.000    0.010    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
   430    0.007    0.000    0.009    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:28(digamma)
  1000    0.008    0.000    0.008    0.000 {method 'any' of 'numpy.ndarray' objects}
   200    0.002    0.000    0.007    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
  2202    0.007    0.000    0.007    0.000 {numpy.core.multiarray.array}
    21    0.000    0.000    0.006    0.000 {sklearn.cluster._k_means._centers_dense}
    21    0.006    0.000    0.006    0.000 _k_means.pyx:280(_centers_dense)
   240    0.005    0.000    0.006    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:32(gammaln)
   364    0.003    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
    10    0.002    0.000    0.006    0.001 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:36(log_normalize)
   300    0.001    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:132(_copy_arrays_if_base_present)
   300    0.001    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:120(_copy_array_if_base_present)
   790    0.002    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
  3782    0.005    0.000    0.005    0.000 {isinstance}
  3866    0.005    0.000    0.005    0.000 {method 'split' of 'str' objects}
   300    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:703(issubsctype)
   320    0.003    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1830(identity)
   200    0.002    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
   210    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:986(trace)
    10    0.002    0.000    0.004    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:436(_bound_proportions)
    10    0.001    0.000    0.004    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:389(_bound_concentration)
   600    0.002    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:608(obj2sctype)
   810    0.003    0.000    0.003    0.000 {method 'get' of 'dict' objects}
   210    0.002    0.000    0.002    0.000 {method 'trace' of 'numpy.ndarray' objects}
    10    0.002    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:223(logsumexp)
   451    0.002    0.000    0.002    0.000 {numpy.core.multiarray.zeros}
   364    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
   100    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/flinalg.py:24(get_flinalg_funcs)
   120    0.002    0.000    0.002    0.000 {method 'max' of 'numpy.ndarray' objects}
  1600    0.002    0.000    0.002    0.000 {issubclass}
   410    0.002    0.000    0.002    0.000 {numpy.core.multiarray.arange}
   209    0.001    0.000    0.001    0.000 {abs}
   100    0.001    0.000    0.001    0.000 {method 'cumsum' of 'numpy.ndarray' objects}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   300    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:65(zeros_like)
   500    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:151(_convert_to_double)
   202    0.001    0.000    0.001    0.000 {method 'reshape' of 'numpy.ndarray' objects}
   653    0.001    0.000    0.001    0.000 {getattr}
    90    0.001    0.000    0.001    0.000 {method 'random_sample' of 'mtrand.RandomState' objects}
  2235    0.001    0.000    0.001    0.000 {len}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/type_check.py:235(iscomplexobj)
    10    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:275(_update_concentration)
  1084    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}
    33    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:221(check_random_state)
   177    0.001    0.000    0.001    0.000 {method 'fill' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:406(_bound_means)
    90    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
    10    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:24(sqnorm)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:142(_tolerance)
   342    0.001    0.000    0.001    0.000 {range}
    87    0.001    0.000    0.001    0.000 {numpy.core.multiarray.empty}
   100    0.001    0.000    0.001    0.000 {method 'astype' of 'numpy.generic' objects}
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:15(norm)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    77    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    90    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
    33    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
    25    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:667(_check_fit_data)
   300    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
   200    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1643(cumsum)
   100    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty_like}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
   400    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1069(rollaxis)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:409(_squared_norms)
   100    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/flinalg.py:19(has_column_major_storage)
   200    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:44(as_float_array)
    65    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/shape_base.py:766(tile)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:397(swapaxes)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:385(_initialize_gamma)
   100    0.000    0.000    0.000    0.000 {callable}
    40    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:358(_monitor)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:647(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2299(mean)
    10    0.000    0.000    0.000    0.000 {method 'swapaxes' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
    10    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
    12    0.000    0.000    0.000    0.000 {max}
     2    0.000    0.000    0.000    0.000 {hasattr}
    10    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'repeat' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/mixture/dpgmm.py
Function: fit at line 471
Total time: 1.78727 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   471                                               def fit(self, X, **kwargs):
   472                                                   """Estimate model parameters with the variational
   473                                                   algorithm.
   474
   475                                                   For a full derivation and description of the algorithm see
   476                                                   doc/dp-derivation/dp-derivation.tex
   477
   478                                                   A initialization step is performed before entering the em
   479                                                   algorithm. If you want to avoid this step, set the keyword
   480                                                   argument init_params to the empty string '' when when creating
   481                                                   the object. Likewise, if you would like just to do an
   482                                                   initialization, set n_iter=0.
   483
   484                                                   Parameters
   485                                                   ----------
   486                                                   X : array_like, shape (n, n_features)
   487                                                       List of n_features-dimensional data points.  Each row
   488                                                       corresponds to a single data point.
   489                                                   """
   490         1           30     30.0      0.0          self.random_state = check_random_state(self.random_state)
   491         1            3      3.0      0.0          if kwargs:
   492                                                       warnings.warn("Setting parameters in the 'fit' method is"
   493                                                                     "deprecated and will be removed in 0.14. Set it on"
   494                                                                     "initialization instead.",
   495                                                                     DeprecationWarning)
   496                                                       # initialisations for in case the user still adds parameters to fit
   497                                                       # so things don't break
   498                                                       if 'n_iter' in kwargs:
   499                                                           self.n_iter = kwargs['n_iter']
   500                                                       if 'params' in kwargs:
   501                                                           self.params = kwargs['params']
   502                                                       if 'init_params' in kwargs:
   503                                                           self.init_params = kwargs['init_params']
   504
   505                                                   ## initialization step
   506         1            8      8.0      0.0          X = np.asarray(X)
   507         1            3      3.0      0.0          if X.ndim == 1:
   508                                                       X = X[:, np.newaxis]
   509
   510         1            3      3.0      0.0          n_features = X.shape[1]
   511         1           15     15.0      0.0          z = np.ones((X.shape[0], self.n_components))
   512         1           46     46.0      0.0          z /= self.n_components
   513
   514         1           15     15.0      0.0          self._initial_bound = - 0.5 * n_features * np.log(2 * np.pi)
   515         1            9      9.0      0.0          self._initial_bound -= np.log(2 * np.pi * np.e)
   516
   517         1            3      3.0      0.0          if (self.init_params != '') or not hasattr(self, 'gamma_'):
   518         1           21     21.0      0.0              self._initialize_gamma()
   519
   520         1            3      3.0      0.0          if 'm' in self.init_params or not hasattr(self, 'means_'):
   521         1            3      3.0      0.0              self.means_ = cluster.KMeans(
   522         1            3      3.0      0.0                  n_clusters=self.n_components,
   523         1       289206 289206.0     16.2                  random_state=self.random_state).fit(X).cluster_centers_[::-1]
   524
   525         1            6      6.0      0.0          if 'w' in self.init_params or not hasattr(self, 'weights_'):
   526         1          121    121.0      0.0              self.weights_ = np.tile(1.0 / self.n_components, self.n_components)
   527
   528         1            6      6.0      0.0          if 'c' in self.init_params or not hasattr(self, 'precs_'):
   529         1            5      5.0      0.0              if self.covariance_type == 'spherical':
   530                                                           self.dof_ = np.ones(self.n_components)
   531                                                           self.scale_ = np.ones(self.n_components)
   532                                                           self.precs_ = np.ones((self.n_components, n_features))
   533                                                           self.bound_prec_ = 0.5 * n_features * (
   534                                                               digamma(self.dof_) - np.log(self.scale_))
   535         1            4      4.0      0.0              elif self.covariance_type == 'diag':
   536                                                           self.dof_ = 1 + 0.5 * n_features
   537                                                           self.dof_ *= np.ones((self.n_components, n_features))
   538                                                           self.scale_ = np.ones((self.n_components, n_features))
   539                                                           self.precs_ = np.ones((self.n_components, n_features))
   540                                                           self.bound_prec_ = 0.5 * (np.sum(digamma(self.dof_) -
   541                                                                                            np.log(self.scale_), 1))
   542                                                           self.bound_prec_ -= 0.5 * np.sum(self.precs_, 1)
   543         1            4      4.0      0.0              elif self.covariance_type == 'tied':
   544                                                           self.dof_ = 1.
   545                                                           self.scale_ = np.identity(n_features)
   546                                                           self.precs_ = np.identity(n_features)
   547                                                           self.det_scale_ = 1.
   548                                                           self.bound_prec_ = 0.5 * wishart_log_det(
   549                                                               self.dof_, self.scale_, self.det_scale_, n_features)
   550                                                           self.bound_prec_ -= 0.5 * self.dof_ * np.trace(self.scale_)
   551         1            5      5.0      0.0              elif self.covariance_type == 'full':
   552         1            7      7.0      0.0                  self.dof_ = (1 + self.n_components + X.shape[0])
   553         1           54     54.0      0.0                  self.dof_ *= np.ones(self.n_components)
   554         1            5      5.0      0.0                  self.scale_ = [2 * np.identity(n_features)
   555        11          455     41.4      0.0                                 for i in xrange(self.n_components)]
   556         1            5      5.0      0.0                  self.precs_ = [np.identity(n_features)
   557        11          204     18.5      0.0                                 for i in xrange(self.n_components)]
   558         1           20     20.0      0.0                  self.det_scale_ = np.ones(self.n_components)
   559         1           10     10.0      0.0                  self.bound_prec_ = np.zeros(self.n_components)
   560        11           59      5.4      0.0                  for k in xrange(self.n_components):
   561        10           44      4.4      0.0                      self.bound_prec_[k] = wishart_log_det(
   562        10           61      6.1      0.0                          self.dof_[k], self.scale_[k], self.det_scale_[k],
   563        10         1275    127.5      0.1                          n_features)
   564        10           74      7.4      0.0                      self.bound_prec_[k] -= (self.dof_[k] *
   565        10          423     42.3      0.0                                              np.trace(self.scale_[k]))
   566         1           16     16.0      0.0                  self.bound_prec_ *= 0.5
   567
   568         1            5      5.0      0.0          logprob = []
   569                                                   # reset self.converged_ to False
   570         1            5      5.0      0.0          self.converged_ = False
   571        11           71      6.5      0.0          for i in xrange(self.n_iter):
   572                                                       # Expectation step
   573        10       321874  32187.4     18.0              curr_logprob, z = self.eval(X)
   574        10        72068   7206.8      4.0              logprob.append(curr_logprob.sum() + self._logprior(z))
   575
   576                                                       # Check for convergence.
   577        10          133     13.3      0.0              if i &gt; 0 and abs(logprob[-1] - logprob[-2]) &lt; self.thresh:
   578                                                           self.converged_ = True
   579                                                           break
   580
   581                                                       # Maximization step
   582        10      1100881 110088.1     61.6              self._do_mstep(X, z, self.params)
   583
   584         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: predict at line 327
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               def predict(self, X):
   328                                                   """Predict label for data.
   329
   330                                                   Parameters
   331                                                   ----------
   332                                                   X : array-like, shape = [n_samples, n_features]
   333
   334                                                   Returns
   335                                                   -------
   336                                                   C : array, shape = (n_samples,)
   337                                                   """
   338                                                   logprob, responsibilities = self.eval(X)
   339                                                   return responsibilities.argmax(axis=1)</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/DPGMM-blobs-step1-timing.png" src="_images/DPGMM-blobs-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/DPGMM-blobs-step1-memory.png" src="_images/DPGMM-blobs-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         615 function calls in 0.010 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.010    0.010 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.009    0.009 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/mixture/gmm.py:327(predict)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:224(eval)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:92(_bound_state_log_lik)
    10    0.000    0.000    0.009    0.001 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:86(_sym_quad_form)
    10    0.000    0.000    0.008    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:1693(cdist)
    10    0.007    0.001    0.007    0.001 {scipy.spatial._distance_wrap.cdist_mahalanobis_wrap}
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:132(_copy_arrays_if_base_present)
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:120(_copy_array_if_base_present)
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:703(issubsctype)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:36(log_normalize)
    60    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:608(obj2sctype)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:223(logsumexp)
    13    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:28(digamma)
    31    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    90    0.000    0.000    0.000    0.000 {issubclass}
    31    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    50    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:151(_convert_to_double)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     2    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
   103    0.000    0.000    0.000    0.000 {isinstance}
     3    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
    14    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1069(rollaxis)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    20    0.000    0.000    0.000    0.000 {len}
    10    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:397(swapaxes)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'swapaxes' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
    10    0.000    0.000    0.000    0.000 {callable}
     1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/mixture/dpgmm.py
Function: fit at line 471
Total time: 1.78727 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   471                                               def fit(self, X, **kwargs):
   472                                                   """Estimate model parameters with the variational
   473                                                   algorithm.
   474
   475                                                   For a full derivation and description of the algorithm see
   476                                                   doc/dp-derivation/dp-derivation.tex
   477
   478                                                   A initialization step is performed before entering the em
   479                                                   algorithm. If you want to avoid this step, set the keyword
   480                                                   argument init_params to the empty string '' when when creating
   481                                                   the object. Likewise, if you would like just to do an
   482                                                   initialization, set n_iter=0.
   483
   484                                                   Parameters
   485                                                   ----------
   486                                                   X : array_like, shape (n, n_features)
   487                                                       List of n_features-dimensional data points.  Each row
   488                                                       corresponds to a single data point.
   489                                                   """
   490         1           30     30.0      0.0          self.random_state = check_random_state(self.random_state)
   491         1            3      3.0      0.0          if kwargs:
   492                                                       warnings.warn("Setting parameters in the 'fit' method is"
   493                                                                     "deprecated and will be removed in 0.14. Set it on"
   494                                                                     "initialization instead.",
   495                                                                     DeprecationWarning)
   496                                                       # initialisations for in case the user still adds parameters to fit
   497                                                       # so things don't break
   498                                                       if 'n_iter' in kwargs:
   499                                                           self.n_iter = kwargs['n_iter']
   500                                                       if 'params' in kwargs:
   501                                                           self.params = kwargs['params']
   502                                                       if 'init_params' in kwargs:
   503                                                           self.init_params = kwargs['init_params']
   504
   505                                                   ## initialization step
   506         1            8      8.0      0.0          X = np.asarray(X)
   507         1            3      3.0      0.0          if X.ndim == 1:
   508                                                       X = X[:, np.newaxis]
   509
   510         1            3      3.0      0.0          n_features = X.shape[1]
   511         1           15     15.0      0.0          z = np.ones((X.shape[0], self.n_components))
   512         1           46     46.0      0.0          z /= self.n_components
   513
   514         1           15     15.0      0.0          self._initial_bound = - 0.5 * n_features * np.log(2 * np.pi)
   515         1            9      9.0      0.0          self._initial_bound -= np.log(2 * np.pi * np.e)
   516
   517         1            3      3.0      0.0          if (self.init_params != '') or not hasattr(self, 'gamma_'):
   518         1           21     21.0      0.0              self._initialize_gamma()
   519
   520         1            3      3.0      0.0          if 'm' in self.init_params or not hasattr(self, 'means_'):
   521         1            3      3.0      0.0              self.means_ = cluster.KMeans(
   522         1            3      3.0      0.0                  n_clusters=self.n_components,
   523         1       289206 289206.0     16.2                  random_state=self.random_state).fit(X).cluster_centers_[::-1]
   524
   525         1            6      6.0      0.0          if 'w' in self.init_params or not hasattr(self, 'weights_'):
   526         1          121    121.0      0.0              self.weights_ = np.tile(1.0 / self.n_components, self.n_components)
   527
   528         1            6      6.0      0.0          if 'c' in self.init_params or not hasattr(self, 'precs_'):
   529         1            5      5.0      0.0              if self.covariance_type == 'spherical':
   530                                                           self.dof_ = np.ones(self.n_components)
   531                                                           self.scale_ = np.ones(self.n_components)
   532                                                           self.precs_ = np.ones((self.n_components, n_features))
   533                                                           self.bound_prec_ = 0.5 * n_features * (
   534                                                               digamma(self.dof_) - np.log(self.scale_))
   535         1            4      4.0      0.0              elif self.covariance_type == 'diag':
   536                                                           self.dof_ = 1 + 0.5 * n_features
   537                                                           self.dof_ *= np.ones((self.n_components, n_features))
   538                                                           self.scale_ = np.ones((self.n_components, n_features))
   539                                                           self.precs_ = np.ones((self.n_components, n_features))
   540                                                           self.bound_prec_ = 0.5 * (np.sum(digamma(self.dof_) -
   541                                                                                            np.log(self.scale_), 1))
   542                                                           self.bound_prec_ -= 0.5 * np.sum(self.precs_, 1)
   543         1            4      4.0      0.0              elif self.covariance_type == 'tied':
   544                                                           self.dof_ = 1.
   545                                                           self.scale_ = np.identity(n_features)
   546                                                           self.precs_ = np.identity(n_features)
   547                                                           self.det_scale_ = 1.
   548                                                           self.bound_prec_ = 0.5 * wishart_log_det(
   549                                                               self.dof_, self.scale_, self.det_scale_, n_features)
   550                                                           self.bound_prec_ -= 0.5 * self.dof_ * np.trace(self.scale_)
   551         1            5      5.0      0.0              elif self.covariance_type == 'full':
   552         1            7      7.0      0.0                  self.dof_ = (1 + self.n_components + X.shape[0])
   553         1           54     54.0      0.0                  self.dof_ *= np.ones(self.n_components)
   554         1            5      5.0      0.0                  self.scale_ = [2 * np.identity(n_features)
   555        11          455     41.4      0.0                                 for i in xrange(self.n_components)]
   556         1            5      5.0      0.0                  self.precs_ = [np.identity(n_features)
   557        11          204     18.5      0.0                                 for i in xrange(self.n_components)]
   558         1           20     20.0      0.0                  self.det_scale_ = np.ones(self.n_components)
   559         1           10     10.0      0.0                  self.bound_prec_ = np.zeros(self.n_components)
   560        11           59      5.4      0.0                  for k in xrange(self.n_components):
   561        10           44      4.4      0.0                      self.bound_prec_[k] = wishart_log_det(
   562        10           61      6.1      0.0                          self.dof_[k], self.scale_[k], self.det_scale_[k],
   563        10         1275    127.5      0.1                          n_features)
   564        10           74      7.4      0.0                      self.bound_prec_[k] -= (self.dof_[k] *
   565        10          423     42.3      0.0                                              np.trace(self.scale_[k]))
   566         1           16     16.0      0.0                  self.bound_prec_ *= 0.5
   567
   568         1            5      5.0      0.0          logprob = []
   569                                                   # reset self.converged_ to False
   570         1            5      5.0      0.0          self.converged_ = False
   571        11           71      6.5      0.0          for i in xrange(self.n_iter):
   572                                                       # Expectation step
   573        10       321874  32187.4     18.0              curr_logprob, z = self.eval(X)
   574        10        72068   7206.8      4.0              logprob.append(curr_logprob.sum() + self._logprior(z))
   575
   576                                                       # Check for convergence.
   577        10          133     13.3      0.0              if i &gt; 0 and abs(logprob[-1] - logprob[-2]) &lt; self.thresh:
   578                                                           self.converged_ = True
   579                                                           break
   580
   581                                                       # Maximization step
   582        10      1100881 110088.1     61.6              self._do_mstep(X, z, self.params)
   583
   584         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: predict at line 327
Total time: 0.018903 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               def predict(self, X):
   328                                                   """Predict label for data.
   329
   330                                                   Parameters
   331                                                   ----------
   332                                                   X : array-like, shape = [n_samples, n_features]
   333
   334                                                   Returns
   335                                                   -------
   336                                                   C : array, shape = (n_samples,)
   337                                                   """
   338         1        18863  18863.0     99.8          logprob, responsibilities = self.eval(X)
   339         1           40     40.0      0.2          return responsibilities.argmax(axis=1)</pre>
</div>
</div>
</div>
<div class="section" id="gmm-blobs">
<h2>GMM-blobs<a class="headerlink" href="#gmm-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GMM</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">&#39;n_components&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">&#39;covariance_type&#39;</span><span class="p">:</span> <span class="s">&#39;full&#39;</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">GMM</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/GMM-blobs-step0-timing.png" src="_images/GMM-blobs-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/GMM-blobs-step0-memory.png" src="_images/GMM-blobs-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         21592 function calls in 0.284 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.284    0.284 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.284    0.284 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.284    0.284 /tmp/vb_sklearn/sklearn/mixture/gmm.py:398(fit)
     1    0.000    0.000    0.156    0.156 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:695(fit)
     1    0.000    0.000    0.156    0.156 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:151(k_means)
    10    0.001    0.000    0.155    0.015 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:304(_kmeans_single)
   121    0.014    0.000    0.117    0.001 /tmp/vb_sklearn/sklearn/metrics/pairwise.py:105(euclidean_distances)
    10    0.000    0.000    0.116    0.012 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:483(_init_centroids)
    10    0.013    0.001    0.115    0.012 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:36(_k_init)
     4    0.001    0.000    0.086    0.022 /tmp/vb_sklearn/sklearn/mixture/gmm.py:274(eval)
     4    0.000    0.000    0.084    0.021 /tmp/vb_sklearn/sklearn/mixture/gmm.py:22(log_multivariate_normal_density)
     4    0.011    0.003    0.084    0.021 /tmp/vb_sklearn/sklearn/mixture/gmm.py:582(_log_multivariate_normal_density_full)
   185    0.059    0.000    0.059    0.000 {numpy.core._dotblas.dot}
    40    0.031    0.001    0.056    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:72(solve_triangular)
   121    0.001    0.000    0.051    0.000 /tmp/vb_sklearn/sklearn/metrics/pairwise.py:56(check_pairwise_arrays)
   364    0.001    0.000    0.045    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:110(atleast2d_or_csr)
   364    0.002    0.000    0.044    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:87(_atleast2d_or_sparse)
     3    0.000    0.000    0.039    0.013 /tmp/vb_sklearn/sklearn/mixture/gmm.py:483(_do_mstep)
     3    0.008    0.003    0.038    0.013 /tmp/vb_sklearn/sklearn/mixture/gmm.py:685(_covar_mstep_full)
   970    0.010    0.000    0.035    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:14(_assert_all_finite)
   121    0.002    0.000    0.034    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:70(safe_sparse_dot)
  1628    0.034    0.000    0.034    0.000 {method 'sum' of 'numpy.ndarray' objects}
    21    0.000    0.000    0.030    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:436(_labels_inertia)
    21    0.006    0.000    0.029    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:419(_labels_inertia_precompute_dense)
   120    0.019    0.000    0.027    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
   364    0.002    0.000    0.026    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:75(array2d)
    40    0.000    0.000    0.023    0.001 {map}
  1733    0.003    0.000    0.022    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
  1733    0.013    0.000    0.019    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
   242    0.001    0.000    0.019    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(safe_asarray)
   242    0.001    0.000    0.013    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:21(assert_all_finite)
    40    0.000    0.000    0.013    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.py:30(cholesky)
    40    0.006    0.000    0.012    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.py:13(_cholesky)
   240    0.008    0.000    0.008    0.000 {method 'any' of 'numpy.ndarray' objects}
   226    0.001    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    21    0.000    0.000    0.006    0.000 {sklearn.cluster._k_means._centers_dense}
    21    0.006    0.000    0.006    0.000 _k_means.pyx:280(_centers_dense)
   364    0.003    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
  3626    0.005    0.000    0.005    0.000 {method 'split' of 'str' objects}
    80    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
   772    0.002    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
  1139    0.003    0.000    0.003    0.000 {numpy.core.multiarray.array}
  2024    0.003    0.000    0.003    0.000 {isinstance}
    80    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
   364    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     4    0.001    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:223(logsumexp)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:1888(cov)
    90    0.001    0.000    0.001    0.000 {method 'cumsum' of 'numpy.ndarray' objects}
    90    0.001    0.000    0.001    0.000 {method 'random_sample' of 'mtrand.RandomState' objects}
    40    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:902(diagonal)
    31    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/twodim_base.py:169(eye)
    90    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
    32    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:221(check_random_state)
   120    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:142(_tolerance)
    30    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:2036(seterr)
  1500    0.000    0.000    0.000    0.000 {len}
    81    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    67    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
   568    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    90    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
    40    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:667(_check_fit_data)
    32    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
    41    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
    21    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
   117    0.000    0.000    0.000    0.000 {range}
   152    0.000    0.000    0.000    0.000 {getattr}
    63    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
   240    0.000    0.000    0.000    0.000 {issubclass}
     4    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:2132(geterr)
     3    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:409(_squared_norms)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/shape_base.py:766(tile)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:44(as_float_array)
    80    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    80    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    63    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/gmm.py:651(distribute_covar_matrix_to_match_covariance_type)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1069(rollaxis)
    30    0.000    0.000    0.000    0.000 {numpy.core.umath.seterrobj}
    80    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
    60    0.000    0.000    0.000    0.000 {numpy.core.umath.geterrobj}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/ufunclike.py:113(isneginf)
     2    0.000    0.000    0.000    0.000 {method 'repeat' of 'numpy.ndarray' objects}
    40    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2299(mean)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:647(__init__)
    10    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     4    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
     6    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
     3    0.000    0.000    0.000    0.000 {abs}
     1    0.000    0.000    0.000    0.000 {method 'conj' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: predict at line 327
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               def predict(self, X):
   328                                                   """Predict label for data.
   329
   330                                                   Parameters
   331                                                   ----------
   332                                                   X : array-like, shape = [n_samples, n_features]
   333
   334                                                   Returns
   335                                                   -------
   336                                                   C : array, shape = (n_samples,)
   337                                                   """
   338                                                   logprob, responsibilities = self.eval(X)
   339                                                   return responsibilities.argmax(axis=1)

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: fit at line 398
Total time: 0.306332 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   398                                               def fit(self, X):
   399                                                   """Estimate model parameters with the expectation-maximization
   400                                                   algorithm.
   401
   402                                                   A initialization step is performed before entering the em
   403                                                   algorithm. If you want to avoid this step, set the keyword
   404                                                   argument init_params to the empty string '' when creating the
   405                                                   GMM object. Likewise, if you would like just to do an
   406                                                   initialization, set n_iter=0.
   407
   408                                                   Parameters
   409                                                   ----------
   410                                                   X : array_like, shape (n, n_features)
   411                                                       List of n_features-dimensional data points.  Each row
   412                                                       corresponds to a single data point.
   413                                                   """
   414                                                   ## initialization step
   415         1           17     17.0      0.0          X = np.asarray(X, dtype=np.float)
   416         1            5      5.0      0.0          if X.ndim == 1:
   417                                                       X = X[:, np.newaxis]
   418         1            5      5.0      0.0          if X.shape[0] &lt; self.n_components:
   419                                                       raise ValueError(
   420                                                           'GMM estimation with %s components, but got only %s samples' %
   421                                                           (self.n_components, X.shape[0]))
   422
   423         1            5      5.0      0.0          max_log_prob = -np.infty
   424
   425         2            9      4.5      0.0          for _ in range(self.n_init):
   426         1            5      5.0      0.0              if 'm' in self.init_params or not hasattr(self, 'means_'):
   427         1            5      5.0      0.0                  self.means_ = cluster.KMeans(
   428         1            4      4.0      0.0                      n_clusters=self.n_components,
   429         1       175473 175473.0     57.3                      random_state=self.random_state).fit(X).cluster_centers_
   430
   431         1            5      5.0      0.0              if 'w' in self.init_params or not hasattr(self, 'weights_'):
   432         1            7      7.0      0.0                  self.weights_ = np.tile(1.0 / self.n_components,
   433         1           81     81.0      0.0                                          self.n_components)
   434
   435         1            4      4.0      0.0              if 'c' in self.init_params or not hasattr(self, 'covars_'):
   436         1         1230   1230.0      0.4                  cv = np.cov(X.T) + self.min_covar * np.eye(X.shape[1])
   437         1            6      6.0      0.0                  if not cv.shape:
   438                                                               cv.shape = (1, 1)
   439                                                           self.covars_ = \
   440         1            4      4.0      0.0                      distribute_covar_matrix_to_match_covariance_type(
   441         1          115    115.0      0.0                          cv, self.covariance_type, self.n_components)
   442
   443                                                       # EM algorithms
   444         1            4      4.0      0.0              log_likelihood = []
   445                                                       # reset self.converged_ to False
   446         1            5      5.0      0.0              self.converged_ = False
   447         4           23      5.8      0.0              for i in xrange(self.n_iter):
   448                                                           # Expectation step
   449         4        88903  22225.8     29.0                  curr_log_likelihood, responsibilities = self.eval(X)
   450         4           65     16.2      0.0                  log_likelihood.append(curr_log_likelihood.sum())
   451
   452                                                           # Check for convergence.
   453         4           25      6.2      0.0                  if i &gt; 0 and abs(log_likelihood[-1] - log_likelihood[-2]) &lt; \
   454         3           23      7.7      0.0                          self.thresh:
   455         1            3      3.0      0.0                      self.converged_ = True
   456         1            2      2.0      0.0                      break
   457
   458                                                           # Maximization step
   459         3           16      5.3      0.0                  self._do_mstep(X, responsibilities, self.params,
   460         3        40208  13402.7     13.1                                 self.min_covar)
   461
   462                                                       # if the results are better, keep it
   463         1            2      2.0      0.0              if self.n_iter:
   464         1            4      4.0      0.0                  if log_likelihood[-1] &gt; max_log_prob:
   465         1            2      2.0      0.0                      max_log_prob = log_likelihood[-1]
   466         1            2      2.0      0.0                      best_params = {'weights': self.weights_,
   467         1            2      2.0      0.0                                     'means': self.means_,
   468         1            3      3.0      0.0                                     'covars': self.covars_}
   469                                                   # check the existence of an init param that was not subject to
   470                                                   # likelihood computation issue.
   471         1           48     48.0      0.0          if np.isneginf(max_log_prob) and self.n_iter:
   472                                                       raise RuntimeError(
   473                                                           "EM algorithm was never able to compute a valid likelihood " +
   474                                                           "given initial parameters. Try different init parameters " +
   475                                                           "(or increasing n_init) or check for degenerate data.")
   476                                                   # self.n_iter == 0 occurs when using GMM within HMM
   477         1            3      3.0      0.0          if self.n_iter:
   478         1            2      2.0      0.0              self.covars_ = best_params['covars']
   479         1            2      2.0      0.0              self.means_ = best_params['means']
   480         1            3      3.0      0.0              self.weights_ = best_params['weights']
   481         1            2      2.0      0.0          return self</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/GMM-blobs-step1-timing.png" src="_images/GMM-blobs-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/GMM-blobs-step1-memory.png" src="_images/GMM-blobs-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         693 function calls in 0.018 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.018    0.018 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.017    0.017 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.017    0.017 /tmp/vb_sklearn/sklearn/mixture/gmm.py:327(predict)
     1    0.000    0.000    0.017    0.017 /tmp/vb_sklearn/sklearn/mixture/gmm.py:274(eval)
     1    0.000    0.000    0.017    0.017 /tmp/vb_sklearn/sklearn/mixture/gmm.py:22(log_multivariate_normal_density)
     1    0.002    0.002    0.017    0.017 /tmp/vb_sklearn/sklearn/mixture/gmm.py:582(_log_multivariate_normal_density_full)
    10    0.006    0.001    0.011    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:72(solve_triangular)
    30    0.004    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    10    0.000    0.000    0.004    0.000 {map}
    10    0.000    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.py:30(cholesky)
    10    0.002    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp_cholesky.py:13(_cholesky)
    60    0.002    0.000    0.002    0.000 {method 'any' of 'numpy.ndarray' objects}
    20    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    21    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    21    0.001    0.000    0.001    0.000 {method 'sum' of 'numpy.ndarray' objects}
    20    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:223(logsumexp)
    41    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:902(diagonal)
    41    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    10    0.000    0.000    0.000    0.000 {method 'diagonal' of 'numpy.ndarray' objects}
    21    0.000    0.000    0.000    0.000 {isinstance}
    40    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    60    0.000    0.000    0.000    0.000 {issubclass}
    30    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    21    0.000    0.000    0.000    0.000 {range}
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    20    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    50    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1069(rollaxis)
    41    0.000    0.000    0.000    0.000 {len}
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
    10    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: predict at line 327
Total time: 0.010472 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               def predict(self, X):
   328                                                   """Predict label for data.
   329
   330                                                   Parameters
   331                                                   ----------
   332                                                   X : array-like, shape = [n_samples, n_features]
   333
   334                                                   Returns
   335                                                   -------
   336                                                   C : array, shape = (n_samples,)
   337                                                   """
   338         1        10456  10456.0     99.8          logprob, responsibilities = self.eval(X)
   339         1           16     16.0      0.2          return responsibilities.argmax(axis=1)

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: fit at line 398
Total time: 0.306332 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   398                                               def fit(self, X):
   399                                                   """Estimate model parameters with the expectation-maximization
   400                                                   algorithm.
   401
   402                                                   A initialization step is performed before entering the em
   403                                                   algorithm. If you want to avoid this step, set the keyword
   404                                                   argument init_params to the empty string '' when creating the
   405                                                   GMM object. Likewise, if you would like just to do an
   406                                                   initialization, set n_iter=0.
   407
   408                                                   Parameters
   409                                                   ----------
   410                                                   X : array_like, shape (n, n_features)
   411                                                       List of n_features-dimensional data points.  Each row
   412                                                       corresponds to a single data point.
   413                                                   """
   414                                                   ## initialization step
   415         1           17     17.0      0.0          X = np.asarray(X, dtype=np.float)
   416         1            5      5.0      0.0          if X.ndim == 1:
   417                                                       X = X[:, np.newaxis]
   418         1            5      5.0      0.0          if X.shape[0] &lt; self.n_components:
   419                                                       raise ValueError(
   420                                                           'GMM estimation with %s components, but got only %s samples' %
   421                                                           (self.n_components, X.shape[0]))
   422
   423         1            5      5.0      0.0          max_log_prob = -np.infty
   424
   425         2            9      4.5      0.0          for _ in range(self.n_init):
   426         1            5      5.0      0.0              if 'm' in self.init_params or not hasattr(self, 'means_'):
   427         1            5      5.0      0.0                  self.means_ = cluster.KMeans(
   428         1            4      4.0      0.0                      n_clusters=self.n_components,
   429         1       175473 175473.0     57.3                      random_state=self.random_state).fit(X).cluster_centers_
   430
   431         1            5      5.0      0.0              if 'w' in self.init_params or not hasattr(self, 'weights_'):
   432         1            7      7.0      0.0                  self.weights_ = np.tile(1.0 / self.n_components,
   433         1           81     81.0      0.0                                          self.n_components)
   434
   435         1            4      4.0      0.0              if 'c' in self.init_params or not hasattr(self, 'covars_'):
   436         1         1230   1230.0      0.4                  cv = np.cov(X.T) + self.min_covar * np.eye(X.shape[1])
   437         1            6      6.0      0.0                  if not cv.shape:
   438                                                               cv.shape = (1, 1)
   439                                                           self.covars_ = \
   440         1            4      4.0      0.0                      distribute_covar_matrix_to_match_covariance_type(
   441         1          115    115.0      0.0                          cv, self.covariance_type, self.n_components)
   442
   443                                                       # EM algorithms
   444         1            4      4.0      0.0              log_likelihood = []
   445                                                       # reset self.converged_ to False
   446         1            5      5.0      0.0              self.converged_ = False
   447         4           23      5.8      0.0              for i in xrange(self.n_iter):
   448                                                           # Expectation step
   449         4        88903  22225.8     29.0                  curr_log_likelihood, responsibilities = self.eval(X)
   450         4           65     16.2      0.0                  log_likelihood.append(curr_log_likelihood.sum())
   451
   452                                                           # Check for convergence.
   453         4           25      6.2      0.0                  if i &gt; 0 and abs(log_likelihood[-1] - log_likelihood[-2]) &lt; \
   454         3           23      7.7      0.0                          self.thresh:
   455         1            3      3.0      0.0                      self.converged_ = True
   456         1            2      2.0      0.0                      break
   457
   458                                                           # Maximization step
   459         3           16      5.3      0.0                  self._do_mstep(X, responsibilities, self.params,
   460         3        40208  13402.7     13.1                                 self.min_covar)
   461
   462                                                       # if the results are better, keep it
   463         1            2      2.0      0.0              if self.n_iter:
   464         1            4      4.0      0.0                  if log_likelihood[-1] &gt; max_log_prob:
   465         1            2      2.0      0.0                      max_log_prob = log_likelihood[-1]
   466         1            2      2.0      0.0                      best_params = {'weights': self.weights_,
   467         1            2      2.0      0.0                                     'means': self.means_,
   468         1            3      3.0      0.0                                     'covars': self.covars_}
   469                                                   # check the existence of an init param that was not subject to
   470                                                   # likelihood computation issue.
   471         1           48     48.0      0.0          if np.isneginf(max_log_prob) and self.n_iter:
   472                                                       raise RuntimeError(
   473                                                           "EM algorithm was never able to compute a valid likelihood " +
   474                                                           "given initial parameters. Try different init parameters " +
   475                                                           "(or increasing n_init) or check for degenerate data.")
   476                                                   # self.n_iter == 0 occurs when using GMM within HMM
   477         1            3      3.0      0.0          if self.n_iter:
   478         1            2      2.0      0.0              self.covars_ = best_params['covars']
   479         1            2      2.0      0.0              self.means_ = best_params['means']
   480         1            3      3.0      0.0              self.weights_ = best_params['weights']
   481         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="vbgmm-blobs">
<h2>VBGMM-blobs<a class="headerlink" href="#vbgmm-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">VBGMM</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">&#39;n_components&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">&#39;covariance_type&#39;</span><span class="p">:</span> <span class="s">&#39;full&#39;</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">VBGMM</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/VBGMM-blobs-step0-timing.png" src="_images/VBGMM-blobs-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/VBGMM-blobs-step0-memory.png" src="_images/VBGMM-blobs-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         41337 function calls in 1.304 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.304    1.304 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.304    1.304 &lt;f&gt;:1(&lt;module&gt;)
     1    0.001    0.001    1.304    1.304 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:471(fit)
    10    0.000    0.000    0.910    0.091 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:371(_do_mstep)
    10    0.013    0.001    0.526    0.053 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:284(_update_means)
   100    0.484    0.005    0.503    0.005 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:365(lstsq)
    10    0.083    0.008    0.383    0.038 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:303(_update_precisions)
    10    0.001    0.000    0.195    0.019 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:663(eval)
   100    0.010    0.000    0.193    0.002 /tmp/vb_sklearn/sklearn/utils/extmath.py:323(pinvh)
    10    0.004    0.000    0.186    0.019 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:92(_bound_state_log_lik)
   100    0.003    0.000    0.183    0.002 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:86(_sym_quad_form)
   100    0.004    0.000    0.179    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:1693(cdist)
   100    0.166    0.002    0.166    0.002 {scipy.spatial._distance_wrap.cdist_mahalanobis_wrap}
     1    0.000    0.000    0.156    0.156 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:695(fit)
     1    0.000    0.000    0.155    0.155 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:151(k_means)
    10    0.001    0.000    0.154    0.015 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:304(_kmeans_single)
   100    0.138    0.001    0.150    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp.py:196(eigh)
   421    0.117    0.000    0.117    0.000 {numpy.core._dotblas.dot}
   121    0.014    0.000    0.116    0.001 /tmp/vb_sklearn/sklearn/metrics/pairwise.py:105(euclidean_distances)
    10    0.000    0.000    0.115    0.012 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:483(_init_centroids)
    10    0.013    0.001    0.115    0.011 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:36(_k_init)
   121    0.001    0.000    0.051    0.000 /tmp/vb_sklearn/sklearn/metrics/pairwise.py:56(check_pairwise_arrays)
   364    0.001    0.000    0.045    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:110(atleast2d_or_csr)
   364    0.002    0.000    0.044    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:87(_atleast2d_or_sparse)
  2434    0.040    0.000    0.040    0.000 {method 'sum' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.040    0.004 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:449(_logprior)
   500    0.024    0.000    0.036    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    10    0.000    0.000    0.034    0.003 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:413(_bound_precisions)
   970    0.010    0.000    0.034    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:14(_assert_all_finite)
   100    0.002    0.000    0.034    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:68(_bound_wishart)
   121    0.002    0.000    0.034    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:70(safe_sparse_dot)
    21    0.000    0.000    0.030    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:436(_labels_inertia)
    21    0.006    0.000    0.029    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:419(_labels_inertia_precompute_dense)
   364    0.002    0.000    0.026    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:75(array2d)
   100    0.014    0.000    0.025    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:336(det)
  1733    0.003    0.000    0.022    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
   200    0.012    0.000    0.021    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:58(wishart_logz)
  1733    0.012    0.000    0.019    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
   242    0.001    0.000    0.018    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(safe_asarray)
   210    0.008    0.000    0.018    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:48(wishart_log_det)
  1062    0.003    0.000    0.018    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   242    0.001    0.000    0.013    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:21(assert_all_finite)
   100    0.001    0.000    0.012    0.000 {map}
  1837    0.004    0.000    0.011    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
  1000    0.009    0.000    0.009    0.000 {method 'any' of 'numpy.ndarray' objects}
   200    0.003    0.000    0.008    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
  2202    0.008    0.000    0.008    0.000 {numpy.core.multiarray.array}
   270    0.006    0.000    0.008    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:28(digamma)
   240    0.005    0.000    0.007    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:32(gammaln)
    10    0.003    0.000    0.007    0.001 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:36(log_normalize)
   300    0.001    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:132(_copy_arrays_if_base_present)
    21    0.000    0.000    0.006    0.000 {sklearn.cluster._k_means._centers_dense}
    21    0.006    0.000    0.006    0.000 _k_means.pyx:280(_centers_dense)
   300    0.001    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:120(_copy_array_if_base_present)
   364    0.003    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
   300    0.001    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:703(issubsctype)
  3872    0.005    0.000    0.005    0.000 {isinstance}
   630    0.002    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
  3866    0.005    0.000    0.005    0.000 {method 'split' of 'str' objects}
   320    0.003    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1830(identity)
   210    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:986(trace)
   200    0.002    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
   600    0.002    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:608(obj2sctype)
    10    0.002    0.000    0.003    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:714(_bound_proportions)
    10    0.002    0.000    0.003    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:223(logsumexp)
   210    0.003    0.000    0.003    0.000 {method 'trace' of 'numpy.ndarray' objects}
   650    0.003    0.000    0.003    0.000 {method 'get' of 'dict' objects}
   461    0.002    0.000    0.002    0.000 {numpy.core.multiarray.zeros}
   100    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/flinalg.py:24(get_flinalg_funcs)
    10    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:723(_bound_concentration)
   364    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
   120    0.002    0.000    0.002    0.000 {method 'max' of 'numpy.ndarray' objects}
  1600    0.002    0.000    0.002    0.000 {issubclass}
   410    0.002    0.000    0.002    0.000 {numpy.core.multiarray.arange}
   209    0.002    0.000    0.002    0.000 {abs}
    10    0.001    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:707(_update_concentration)
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   500    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:151(_convert_to_double)
   300    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    90    0.001    0.000    0.001    0.000 {method 'cumsum' of 'numpy.ndarray' objects}
   653    0.001    0.000    0.001    0.000 {getattr}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:65(zeros_like)
   212    0.001    0.000    0.001    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    90    0.001    0.000    0.001    0.000 {method 'random_sample' of 'mtrand.RandomState' objects}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/type_check.py:235(iscomplexobj)
  2235    0.001    0.000    0.001    0.000 {len}
    10    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:406(_bound_means)
    10    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:24(sqnorm)
    10    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:15(norm)
  1084    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}
    33    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:221(check_random_state)
   167    0.001    0.000    0.001    0.000 {method 'fill' of 'numpy.ndarray' objects}
   100    0.001    0.000    0.001    0.000 {method 'astype' of 'numpy.generic' objects}
    90    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
   342    0.001    0.000    0.001    0.000 {range}
    77    0.001    0.000    0.001    0.000 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:142(_tolerance)
    87    0.001    0.000    0.001    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    90    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
   300    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    25    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    33    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:667(_check_fit_data)
   200    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
   100    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty_like}
   400    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:409(_squared_norms)
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1069(rollaxis)
   200    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
   100    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/flinalg.py:19(has_column_major_storage)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:44(as_float_array)
    65    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:397(swapaxes)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/shape_base.py:766(tile)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:711(_initialize_gamma)
   100    0.000    0.000    0.000    0.000 {callable}
    40    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:733(_monitor)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/cluster/k_means_.py:647(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2299(mean)
    10    0.000    0.000    0.000    0.000 {method 'swapaxes' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
    12    0.000    0.000    0.000    0.000 {max}
    10    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {hasattr}
    10    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'repeat' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/mixture/dpgmm.py
Function: fit at line 471
Total time: 1.74626 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   471                                               def fit(self, X, **kwargs):
   472                                                   """Estimate model parameters with the variational
   473                                                   algorithm.
   474
   475                                                   For a full derivation and description of the algorithm see
   476                                                   doc/dp-derivation/dp-derivation.tex
   477
   478                                                   A initialization step is performed before entering the em
   479                                                   algorithm. If you want to avoid this step, set the keyword
   480                                                   argument init_params to the empty string '' when when creating
   481                                                   the object. Likewise, if you would like just to do an
   482                                                   initialization, set n_iter=0.
   483
   484                                                   Parameters
   485                                                   ----------
   486                                                   X : array_like, shape (n, n_features)
   487                                                       List of n_features-dimensional data points.  Each row
   488                                                       corresponds to a single data point.
   489                                                   """
   490         1           30     30.0      0.0          self.random_state = check_random_state(self.random_state)
   491         1            3      3.0      0.0          if kwargs:
   492                                                       warnings.warn("Setting parameters in the 'fit' method is"
   493                                                                     "deprecated and will be removed in 0.14. Set it on"
   494                                                                     "initialization instead.",
   495                                                                     DeprecationWarning)
   496                                                       # initialisations for in case the user still adds parameters to fit
   497                                                       # so things don't break
   498                                                       if 'n_iter' in kwargs:
   499                                                           self.n_iter = kwargs['n_iter']
   500                                                       if 'params' in kwargs:
   501                                                           self.params = kwargs['params']
   502                                                       if 'init_params' in kwargs:
   503                                                           self.init_params = kwargs['init_params']
   504
   505                                                   ## initialization step
   506         1            8      8.0      0.0          X = np.asarray(X)
   507         1            4      4.0      0.0          if X.ndim == 1:
   508                                                       X = X[:, np.newaxis]
   509
   510         1            3      3.0      0.0          n_features = X.shape[1]
   511         1           14     14.0      0.0          z = np.ones((X.shape[0], self.n_components))
   512         1           46     46.0      0.0          z /= self.n_components
   513
   514         1           14     14.0      0.0          self._initial_bound = - 0.5 * n_features * np.log(2 * np.pi)
   515         1           10     10.0      0.0          self._initial_bound -= np.log(2 * np.pi * np.e)
   516
   517         1            3      3.0      0.0          if (self.init_params != '') or not hasattr(self, 'gamma_'):
   518         1           21     21.0      0.0              self._initialize_gamma()
   519
   520         1            3      3.0      0.0          if 'm' in self.init_params or not hasattr(self, 'means_'):
   521         1            3      3.0      0.0              self.means_ = cluster.KMeans(
   522         1            2      2.0      0.0                  n_clusters=self.n_components,
   523         1       217197 217197.0     12.4                  random_state=self.random_state).fit(X).cluster_centers_[::-1]
   524
   525         1            3      3.0      0.0          if 'w' in self.init_params or not hasattr(self, 'weights_'):
   526         1           51     51.0      0.0              self.weights_ = np.tile(1.0 / self.n_components, self.n_components)
   527
   528         1            3      3.0      0.0          if 'c' in self.init_params or not hasattr(self, 'precs_'):
   529         1            3      3.0      0.0              if self.covariance_type == 'spherical':
   530                                                           self.dof_ = np.ones(self.n_components)
   531                                                           self.scale_ = np.ones(self.n_components)
   532                                                           self.precs_ = np.ones((self.n_components, n_features))
   533                                                           self.bound_prec_ = 0.5 * n_features * (
   534                                                               digamma(self.dof_) - np.log(self.scale_))
   535         1            2      2.0      0.0              elif self.covariance_type == 'diag':
   536                                                           self.dof_ = 1 + 0.5 * n_features
   537                                                           self.dof_ *= np.ones((self.n_components, n_features))
   538                                                           self.scale_ = np.ones((self.n_components, n_features))
   539                                                           self.precs_ = np.ones((self.n_components, n_features))
   540                                                           self.bound_prec_ = 0.5 * (np.sum(digamma(self.dof_) -
   541                                                                                            np.log(self.scale_), 1))
   542                                                           self.bound_prec_ -= 0.5 * np.sum(self.precs_, 1)
   543         1            2      2.0      0.0              elif self.covariance_type == 'tied':
   544                                                           self.dof_ = 1.
   545                                                           self.scale_ = np.identity(n_features)
   546                                                           self.precs_ = np.identity(n_features)
   547                                                           self.det_scale_ = 1.
   548                                                           self.bound_prec_ = 0.5 * wishart_log_det(
   549                                                               self.dof_, self.scale_, self.det_scale_, n_features)
   550                                                           self.bound_prec_ -= 0.5 * self.dof_ * np.trace(self.scale_)
   551         1            2      2.0      0.0              elif self.covariance_type == 'full':
   552         1            4      4.0      0.0                  self.dof_ = (1 + self.n_components + X.shape[0])
   553         1           24     24.0      0.0                  self.dof_ *= np.ones(self.n_components)
   554         1            2      2.0      0.0                  self.scale_ = [2 * np.identity(n_features)
   555        11          271     24.6      0.0                                 for i in xrange(self.n_components)]
   556         1            3      3.0      0.0                  self.precs_ = [np.identity(n_features)
   557        11          121     11.0      0.0                                 for i in xrange(self.n_components)]
   558         1           12     12.0      0.0                  self.det_scale_ = np.ones(self.n_components)
   559         1            5      5.0      0.0                  self.bound_prec_ = np.zeros(self.n_components)
   560        11           35      3.2      0.0                  for k in xrange(self.n_components):
   561        10           28      2.8      0.0                      self.bound_prec_[k] = wishart_log_det(
   562        10           35      3.5      0.0                          self.dof_[k], self.scale_[k], self.det_scale_[k],
   563        10          667     66.7      0.0                          n_features)
   564        10           39      3.9      0.0                      self.bound_prec_[k] -= (self.dof_[k] *
   565        10          233     23.3      0.0                                              np.trace(self.scale_[k]))
   566         1           10     10.0      0.0                  self.bound_prec_ *= 0.5
   567
   568         1            3      3.0      0.0          logprob = []
   569                                                   # reset self.converged_ to False
   570         1            3      3.0      0.0          self.converged_ = False
   571        11           67      6.1      0.0          for i in xrange(self.n_iter):
   572                                                       # Expectation step
   573        10       261501  26150.1     15.0              curr_logprob, z = self.eval(X)
   574        10        51258   5125.8      2.9              logprob.append(curr_logprob.sum() + self._logprior(z))
   575
   576                                                       # Check for convergence.
   577        10          161     16.1      0.0              if i &gt; 0 and abs(logprob[-1] - logprob[-2]) &lt; self.thresh:
   578                                                           self.converged_ = True
   579                                                           break
   580
   581                                                       # Maximization step
   582        10      1214346 121434.6     69.5              self._do_mstep(X, z, self.params)
   583
   584         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: predict at line 327
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               def predict(self, X):
   328                                                   """Predict label for data.
   329
   330                                                   Parameters
   331                                                   ----------
   332                                                   X : array-like, shape = [n_samples, n_features]
   333
   334                                                   Returns
   335                                                   -------
   336                                                   C : array, shape = (n_samples,)
   337                                                   """
   338                                                   logprob, responsibilities = self.eval(X)
   339                                                   return responsibilities.argmax(axis=1)</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/VBGMM-blobs-step1-timing.png" src="_images/VBGMM-blobs-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/VBGMM-blobs-step1-memory.png" src="_images/VBGMM-blobs-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         586 function calls in 0.009 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.009    0.009 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.009    0.009 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/mixture/gmm.py:327(predict)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:663(eval)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:92(_bound_state_log_lik)
    10    0.000    0.000    0.009    0.001 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:86(_sym_quad_form)
    10    0.000    0.000    0.008    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:1693(cdist)
    10    0.007    0.001    0.007    0.001 {scipy.spatial._distance_wrap.cdist_mahalanobis_wrap}
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:132(_copy_arrays_if_base_present)
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:120(_copy_array_if_base_present)
    30    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:703(issubsctype)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:36(log_normalize)
    60    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:608(obj2sctype)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:223(logsumexp)
    31    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    90    0.000    0.000    0.000    0.000 {issubclass}
    50    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/spatial/distance.py:151(_convert_to_double)
    31    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     2    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
   104    0.000    0.000    0.000    0.000 {isinstance}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/mixture/dpgmm.py:28(digamma)
    10    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    13    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1069(rollaxis)
     3    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    20    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:397(swapaxes)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'swapaxes' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}
    10    0.000    0.000    0.000    0.000 {callable}
     1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/mixture/dpgmm.py
Function: fit at line 471
Total time: 1.74626 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   471                                               def fit(self, X, **kwargs):
   472                                                   """Estimate model parameters with the variational
   473                                                   algorithm.
   474
   475                                                   For a full derivation and description of the algorithm see
   476                                                   doc/dp-derivation/dp-derivation.tex
   477
   478                                                   A initialization step is performed before entering the em
   479                                                   algorithm. If you want to avoid this step, set the keyword
   480                                                   argument init_params to the empty string '' when when creating
   481                                                   the object. Likewise, if you would like just to do an
   482                                                   initialization, set n_iter=0.
   483
   484                                                   Parameters
   485                                                   ----------
   486                                                   X : array_like, shape (n, n_features)
   487                                                       List of n_features-dimensional data points.  Each row
   488                                                       corresponds to a single data point.
   489                                                   """
   490         1           30     30.0      0.0          self.random_state = check_random_state(self.random_state)
   491         1            3      3.0      0.0          if kwargs:
   492                                                       warnings.warn("Setting parameters in the 'fit' method is"
   493                                                                     "deprecated and will be removed in 0.14. Set it on"
   494                                                                     "initialization instead.",
   495                                                                     DeprecationWarning)
   496                                                       # initialisations for in case the user still adds parameters to fit
   497                                                       # so things don't break
   498                                                       if 'n_iter' in kwargs:
   499                                                           self.n_iter = kwargs['n_iter']
   500                                                       if 'params' in kwargs:
   501                                                           self.params = kwargs['params']
   502                                                       if 'init_params' in kwargs:
   503                                                           self.init_params = kwargs['init_params']
   504
   505                                                   ## initialization step
   506         1            8      8.0      0.0          X = np.asarray(X)
   507         1            4      4.0      0.0          if X.ndim == 1:
   508                                                       X = X[:, np.newaxis]
   509
   510         1            3      3.0      0.0          n_features = X.shape[1]
   511         1           14     14.0      0.0          z = np.ones((X.shape[0], self.n_components))
   512         1           46     46.0      0.0          z /= self.n_components
   513
   514         1           14     14.0      0.0          self._initial_bound = - 0.5 * n_features * np.log(2 * np.pi)
   515         1           10     10.0      0.0          self._initial_bound -= np.log(2 * np.pi * np.e)
   516
   517         1            3      3.0      0.0          if (self.init_params != '') or not hasattr(self, 'gamma_'):
   518         1           21     21.0      0.0              self._initialize_gamma()
   519
   520         1            3      3.0      0.0          if 'm' in self.init_params or not hasattr(self, 'means_'):
   521         1            3      3.0      0.0              self.means_ = cluster.KMeans(
   522         1            2      2.0      0.0                  n_clusters=self.n_components,
   523         1       217197 217197.0     12.4                  random_state=self.random_state).fit(X).cluster_centers_[::-1]
   524
   525         1            3      3.0      0.0          if 'w' in self.init_params or not hasattr(self, 'weights_'):
   526         1           51     51.0      0.0              self.weights_ = np.tile(1.0 / self.n_components, self.n_components)
   527
   528         1            3      3.0      0.0          if 'c' in self.init_params or not hasattr(self, 'precs_'):
   529         1            3      3.0      0.0              if self.covariance_type == 'spherical':
   530                                                           self.dof_ = np.ones(self.n_components)
   531                                                           self.scale_ = np.ones(self.n_components)
   532                                                           self.precs_ = np.ones((self.n_components, n_features))
   533                                                           self.bound_prec_ = 0.5 * n_features * (
   534                                                               digamma(self.dof_) - np.log(self.scale_))
   535         1            2      2.0      0.0              elif self.covariance_type == 'diag':
   536                                                           self.dof_ = 1 + 0.5 * n_features
   537                                                           self.dof_ *= np.ones((self.n_components, n_features))
   538                                                           self.scale_ = np.ones((self.n_components, n_features))
   539                                                           self.precs_ = np.ones((self.n_components, n_features))
   540                                                           self.bound_prec_ = 0.5 * (np.sum(digamma(self.dof_) -
   541                                                                                            np.log(self.scale_), 1))
   542                                                           self.bound_prec_ -= 0.5 * np.sum(self.precs_, 1)
   543         1            2      2.0      0.0              elif self.covariance_type == 'tied':
   544                                                           self.dof_ = 1.
   545                                                           self.scale_ = np.identity(n_features)
   546                                                           self.precs_ = np.identity(n_features)
   547                                                           self.det_scale_ = 1.
   548                                                           self.bound_prec_ = 0.5 * wishart_log_det(
   549                                                               self.dof_, self.scale_, self.det_scale_, n_features)
   550                                                           self.bound_prec_ -= 0.5 * self.dof_ * np.trace(self.scale_)
   551         1            2      2.0      0.0              elif self.covariance_type == 'full':
   552         1            4      4.0      0.0                  self.dof_ = (1 + self.n_components + X.shape[0])
   553         1           24     24.0      0.0                  self.dof_ *= np.ones(self.n_components)
   554         1            2      2.0      0.0                  self.scale_ = [2 * np.identity(n_features)
   555        11          271     24.6      0.0                                 for i in xrange(self.n_components)]
   556         1            3      3.0      0.0                  self.precs_ = [np.identity(n_features)
   557        11          121     11.0      0.0                                 for i in xrange(self.n_components)]
   558         1           12     12.0      0.0                  self.det_scale_ = np.ones(self.n_components)
   559         1            5      5.0      0.0                  self.bound_prec_ = np.zeros(self.n_components)
   560        11           35      3.2      0.0                  for k in xrange(self.n_components):
   561        10           28      2.8      0.0                      self.bound_prec_[k] = wishart_log_det(
   562        10           35      3.5      0.0                          self.dof_[k], self.scale_[k], self.det_scale_[k],
   563        10          667     66.7      0.0                          n_features)
   564        10           39      3.9      0.0                      self.bound_prec_[k] -= (self.dof_[k] *
   565        10          233     23.3      0.0                                              np.trace(self.scale_[k]))
   566         1           10     10.0      0.0                  self.bound_prec_ *= 0.5
   567
   568         1            3      3.0      0.0          logprob = []
   569                                                   # reset self.converged_ to False
   570         1            3      3.0      0.0          self.converged_ = False
   571        11           67      6.1      0.0          for i in xrange(self.n_iter):
   572                                                       # Expectation step
   573        10       261501  26150.1     15.0              curr_logprob, z = self.eval(X)
   574        10        51258   5125.8      2.9              logprob.append(curr_logprob.sum() + self._logprior(z))
   575
   576                                                       # Check for convergence.
   577        10          161     16.1      0.0              if i &gt; 0 and abs(logprob[-1] - logprob[-2]) &lt; self.thresh:
   578                                                           self.converged_ = True
   579                                                           break
   580
   581                                                       # Maximization step
   582        10      1214346 121434.6     69.5              self._do_mstep(X, z, self.params)
   583
   584         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/mixture/gmm.py
Function: predict at line 327
Total time: 0.030607 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   327                                               def predict(self, X):
   328                                                   """Predict label for data.
   329
   330                                                   Parameters
   331                                                   ----------
   332                                                   X : array-like, shape = [n_samples, n_features]
   333
   334                                                   Returns
   335                                                   -------
   336                                                   C : array, shape = (n_samples,)
   337                                                   """
   338         1        30567  30567.0     99.9          logprob, responsibilities = self.eval(X)
   339         1           40     40.0      0.1          return responsibilities.argmax(axis=1)</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>

        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; .
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/vb_mixture.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="vb_manifold.html">
        Previous
      </a>  
    </div>
    <div class="buttonNext">
      <a href="vb_naive_bayes.html">
        Next
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>