

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Benchmarks for linear_model &mdash; Vbench performance benchmarks for scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.12-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Vbench performance benchmarks for scikit-learn" href="index.html" />
    <link rel="next" title="Benchmarks for manifold" href="vb_manifold.html" />
    <link rel="prev" title="Benchmarks for gaussian_process" href="vb_gaussian_process.html" />

  <!-- Reference the theme's stylesheet on the Google CDN -->
  <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/excite-bike/jquery-ui.css"
        type="text/css" rel="Stylesheet" />
 
  <!-- Reference jQuery and jQuery UI from the CDN. Remember
       that the order of these two elements is important -->
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js"></script>

<script type="text/javascript">
      $(function(){
        $(".profiler-output").accordion({collapsible: true, header: "p", active: false} );
      });
    </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="http://scikit-learn.org/">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="quick_start.html">Speed Quick Start</a></li>
            <li><a href="http://scikit-learn.org/dev/user_guide.html">User's Guide</a></li>
            <li><a href="http://scikit-learn.org/dev/developers/performance.html">Performance</a></li>
            <li><a href="http://github.com/scikit-learn/scikit-learn">Github</a></li>
            <li><a href="http://github.com/vene/scikit-learn-speed">Speed Github</a></li>
       </ul>
</div>
<!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
          <h3>Table Of Contents</h3>
          <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vb_cluster.html">Benchmarks for cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_covariance.html">Benchmarks for covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_decomposition.html">Benchmarks for decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_ensemble.html">Benchmarks for ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_gaussian_process.html">Benchmarks for gaussian_process</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Benchmarks for linear_model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ridge-arcene">Ridge-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ridge-madelon">Ridge-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lars-minimadelon-oney">Lars-minimadelon-oney</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lars-madelon">Lars-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lassolars-minimadelon-oney">LassoLars-minimadelon-oney</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lassolars-madelon">LassoLars-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lasso-minimadelon-oney">Lasso-minimadelon-oney</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lasso-madelon">Lasso-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#elasticnet-minimadelon-oney">ElasticNet-minimadelon-oney</a></li>
<li class="toctree-l2"><a class="reference internal" href="#orthogonalmatchingpursuit-minimadelon">OrthogonalMatchingPursuit-minimadelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#orthogonalmatchingpursuit-madelon">OrthogonalMatchingPursuit-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sgdclassifier-madelon">SGDClassifier-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sgdclassifier-newsgroups">SGDClassifier-newsgroups</a></li>
<li class="toctree-l2"><a class="reference internal" href="#logisticregression-arcene">LogisticRegression-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#logisticregression-madelon">LogisticRegression-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ardregression-minimadelon-oney">ARDRegression-minimadelon-oney</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ardregression-blobs">ARDRegression-blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bayesianridge-arcene">BayesianRidge-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bayesianridge-madelon">BayesianRidge-madelon</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vb_manifold.html">Benchmarks for manifold</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_mixture.html">Benchmarks for mixture</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_naive_bayes.html">Benchmarks for naive_bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_neighbors.html">Benchmarks for neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_pls.html">Benchmarks for pls</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_semi_supervised.html">Benchmarks for semi_supervised</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_svm.html">Benchmarks for svm</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_tree.html">Benchmarks for tree</a></li>
</ul>

          <!--
	   <div class="rel rellarge">
	     
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  --
	<div class="rellink">
	<a href="vb_gaussian_process.html" title="Benchmarks for gaussian_process"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Benchmarks for g...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for gaussian_process
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="vb_manifold.html" title="Benchmarks for manifold"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Benchmarks for m...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for manifold
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page --
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.12-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Benchmarks for linear_model</a><ul>
<li><a class="reference internal" href="#ridge-arcene">Ridge-arcene</a></li>
<li><a class="reference internal" href="#ridge-madelon">Ridge-madelon</a></li>
<li><a class="reference internal" href="#lars-minimadelon-oney">Lars-minimadelon-oney</a></li>
<li><a class="reference internal" href="#lars-madelon">Lars-madelon</a></li>
<li><a class="reference internal" href="#lassolars-minimadelon-oney">LassoLars-minimadelon-oney</a></li>
<li><a class="reference internal" href="#lassolars-madelon">LassoLars-madelon</a></li>
<li><a class="reference internal" href="#lasso-minimadelon-oney">Lasso-minimadelon-oney</a></li>
<li><a class="reference internal" href="#lasso-madelon">Lasso-madelon</a></li>
<li><a class="reference internal" href="#elasticnet-minimadelon-oney">ElasticNet-minimadelon-oney</a></li>
<li><a class="reference internal" href="#orthogonalmatchingpursuit-minimadelon">OrthogonalMatchingPursuit-minimadelon</a></li>
<li><a class="reference internal" href="#orthogonalmatchingpursuit-madelon">OrthogonalMatchingPursuit-madelon</a></li>
<li><a class="reference internal" href="#sgdclassifier-madelon">SGDClassifier-madelon</a></li>
<li><a class="reference internal" href="#sgdclassifier-newsgroups">SGDClassifier-newsgroups</a></li>
<li><a class="reference internal" href="#logisticregression-arcene">LogisticRegression-arcene</a></li>
<li><a class="reference internal" href="#logisticregression-madelon">LogisticRegression-madelon</a></li>
<li><a class="reference internal" href="#ardregression-minimadelon-oney">ARDRegression-minimadelon-oney</a></li>
<li><a class="reference internal" href="#ardregression-blobs">ARDRegression-blobs</a></li>
<li><a class="reference internal" href="#bayesianridge-arcene">BayesianRidge-arcene</a></li>
<li><a class="reference internal" href="#bayesianridge-madelon">BayesianRidge-madelon</a></li>
</ul>
</li>
</ul>

    
  -->
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="benchmarks-for-linear-model">
<h1>Benchmarks for linear_model<a class="headerlink" href="#benchmarks-for-linear-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="ridge-arcene">
<h2>Ridge-arcene<a class="headerlink" href="#ridge-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/Ridge-arcene-step0-timing.png" src="_images/Ridge-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/Ridge-arcene-step0-memory.png" src="_images/Ridge-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         77 function calls in 0.110 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.110    0.110 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.110    0.110 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.110    0.110 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:141(fit)
     1    0.000    0.000    0.092    0.092 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:55(ridge_regression)
     3    0.091    0.030    0.091    0.030 {numpy.core._dotblas.dot}
     1    0.003    0.003    0.014    0.014 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.006    0.006    0.006    0.006 {method 'copy' of 'numpy.ndarray' objects}
     2    0.005    0.002    0.005    0.002 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:23(safe_asarray)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.003    0.003    0.003    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:23(_solve)
     1    0.001    0.001    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:19(solve)
     1    0.000    0.000    0.000    0.000 {map}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     4    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 {hasattr}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     5    0.000    0.000    0.000    0.000 {isinstance}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     4    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     3    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/ridge.py
Function: fit at line 141
Total time: 0.095972 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   141                                               def fit(self, X, y, sample_weight=1.0, solver='auto'):
   142                                                   """Fit Ridge regression model
   143
   144                                                   Parameters
   145                                                   ----------
   146                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   147                                                       Training data
   148
   149                                                   y : array-like, shape = [n_samples] or [n_samples, n_responses]
   150                                                       Target values
   151
   152                                                   sample_weight : float or numpy array of shape [n_samples]
   153                                                       Individual weights for each sample
   154
   155                                                   solver : {'auto', 'dense_cholesky', 'sparse_cg'}
   156                                                       Solver to use in the computational
   157                                                       routines. 'dense_cholesky' will use the standard
   158                                                       scipy.linalg.solve function, 'sparse_cg' will use the
   159                                                       conjugate gradient solver as found in
   160                                                       scipy.sparse.linalg.cg while 'auto' will chose the most
   161                                                       appropriate depending on the matrix X.
   162
   163                                                   Returns
   164                                                   -------
   165                                                   self : returns an instance of self.
   166                                                   """
   167         1         2765   2765.0      2.9          X = safe_asarray(X, dtype=np.float)
   168         1           24     24.0      0.0          y = np.asarray(y, dtype=np.float)
   169
   170                                                   X, y, X_mean, y_mean, X_std = \
   171         1            3      3.0      0.0             self._center_data(X, y, self.fit_intercept,
   172         1         9097   9097.0      9.5                     self.normalize, self.copy_X)
   173
   174         1            4      4.0      0.0          self.coef_ = ridge_regression(X, y, self.alpha, sample_weight,
   175         1        83930  83930.0     87.5                                        solver, self.tol)
   176         1          147    147.0      0.2          self._set_intercept(X_mean, y_mean, X_std)
   177         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="ridge-madelon">
<h2>Ridge-madelon<a class="headerlink" href="#ridge-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/Ridge-madelon-step0-timing.png" src="_images/Ridge-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/Ridge-madelon-step0-memory.png" src="_images/Ridge-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         78 function calls in 0.445 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.445    0.445 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.445    0.445 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.445    0.445 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:141(fit)
     1    0.000    0.000    0.403    0.403 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:55(ridge_regression)
     3    0.370    0.123    0.370    0.123 {numpy.core._dotblas.dot}
     1    0.004    0.004    0.040    0.040 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     1    0.000    0.000    0.033    0.033 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:23(_solve)
     1    0.024    0.024    0.033    0.033 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:19(solve)
     2    0.030    0.015    0.030    0.015 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.008    0.008 {map}
     2    0.007    0.004    0.008    0.004 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:23(safe_asarray)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.003    0.003    0.003    0.003 {method 'sum' of 'numpy.ndarray' objects}
     4    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     3    0.000    0.000    0.000    0.000 {hasattr}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     6    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     3    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/ridge.py
Function: fit at line 141
Total time: 0.494425 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   141                                               def fit(self, X, y, sample_weight=1.0, solver='auto'):
   142                                                   """Fit Ridge regression model
   143
   144                                                   Parameters
   145                                                   ----------
   146                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   147                                                       Training data
   148
   149                                                   y : array-like, shape = [n_samples] or [n_samples, n_responses]
   150                                                       Target values
   151
   152                                                   sample_weight : float or numpy array of shape [n_samples]
   153                                                       Individual weights for each sample
   154
   155                                                   solver : {'auto', 'dense_cholesky', 'sparse_cg'}
   156                                                       Solver to use in the computational
   157                                                       routines. 'dense_cholesky' will use the standard
   158                                                       scipy.linalg.solve function, 'sparse_cg' will use the
   159                                                       conjugate gradient solver as found in
   160                                                       scipy.sparse.linalg.cg while 'auto' will chose the most
   161                                                       appropriate depending on the matrix X.
   162
   163                                                   Returns
   164                                                   -------
   165                                                   self : returns an instance of self.
   166                                                   """
   167         1         2790   2790.0      0.6          X = safe_asarray(X, dtype=np.float)
   168         1           30     30.0      0.0          y = np.asarray(y, dtype=np.float)
   169
   170                                                   X, y, X_mean, y_mean, X_std = \
   171         1            4      4.0      0.0             self._center_data(X, y, self.fit_intercept,
   172         1        36137  36137.0      7.3                     self.normalize, self.copy_X)
   173
   174         1            5      5.0      0.0          self.coef_ = ridge_regression(X, y, self.alpha, sample_weight,
   175         1       455409 455409.0     92.1                                        solver, self.tol)
   176         1           48     48.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   177         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lars-minimadelon-oney">
<h2>Lars-minimadelon-oney<a class="headerlink" href="#lars-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/Lars-minimadelon-oney-step0-timing.png" src="_images/Lars-minimadelon-oney-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/Lars-minimadelon-oney-step0-memory.png" src="_images/Lars-minimadelon-oney-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7132 function calls in 0.525 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.525    0.525 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.525    0.525 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.525    0.525 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:420(fit)
     1    0.432    0.432    0.524    0.524 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:26(lars_path)
  1520    0.052    0.000    0.052    0.000 {numpy.core._dotblas.dot}
   502    0.002    0.000    0.010    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   259    0.010    0.000    0.010    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
  1500    0.009    0.000    0.009    0.000 {sklearn.utils.arrayfuncs.min_pos}
   502    0.006    0.000    0.006    0.000 {method 'sum' of 'numpy.ndarray' objects}
   501    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   501    0.003    0.000    0.003    0.000 {min}
   501    0.003    0.000    0.003    0.000 {method 'argmax' of 'numpy.ndarray' objects}
   508    0.002    0.000    0.002    0.000 {isinstance}
   242    0.002    0.000    0.002    0.000 {numpy.core.multiarray.where}
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
   261    0.001    0.000    0.001    0.000 {max}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
   264    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     2    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     6    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:408(_get_gram)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     2    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 420
Total time: 0.721654 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   420                                               def fit(self, X, y):
   421                                                   """Fit the model using X, y as training data.
   422
   423                                                   parameters
   424                                                   ----------
   425                                                   X : array-like, shape = [n_samples, n_features]
   426                                                       training data.
   427
   428                                                   y : array-like, shape = [n_samples]
   429                                                       target values.
   430
   431                                                   returns
   432                                                   -------
   433                                                   self : object
   434                                                       returns an instance of self.
   435                                                   """
   436         1           85     85.0      0.0          X = array2d(X)
   437         1           10     10.0      0.0          y = np.asarray(y)
   438
   439         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   440         1            3      3.0      0.0                                                          self.fit_intercept,
   441         1            2      2.0      0.0                                                          self.normalize,
   442         1          691    691.0      0.1                                                          self.copy_X)
   443         1           11     11.0      0.0          alpha = getattr(self, 'alpha', 0.)
   444         1            4      4.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   445         1            3      3.0      0.0              alpha = 0.  # n_nonzero_coefs parametrization takes priority
   446         1            3      3.0      0.0              max_iter = self.n_nonzero_coefs
   447                                                   else:
   448                                                       max_iter = self.max_iter
   449
   450         1           12     12.0      0.0          Gram = self._get_gram()
   451
   452         1            3      3.0      0.0          self.alphas_, self.active_, self.coef_path_ = lars_path(X, y,
   453         1            3      3.0      0.0                    Gram=Gram, copy_X=self.copy_X,
   454         1            3      3.0      0.0                    copy_Gram=False, alpha_min=alpha,
   455         1            6      6.0      0.0                    method=self.method, verbose=max(0, self.verbose - 1),
   456         1       720765 720765.0     99.9                    max_iter=max_iter, eps=self.eps)
   457
   458         1            8      8.0      0.0          self.coef_ = self.coef_path_[:, -1]
   459
   460         1           35     35.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   461
   462         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lars-madelon">
<h2>Lars-madelon<a class="headerlink" href="#lars-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/Lars-madelon-step0-timing.png" src="_images/Lars-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/Lars-madelon-step0-memory.png" src="_images/Lars-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7026 function calls in 1.328 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.328    1.328 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.328    1.328 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.328    1.328 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:420(fit)
     1    0.582    0.582    1.304    1.304 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:26(lars_path)
   982    0.481    0.000    0.481    0.000 {numpy.core._dotblas.dot}
   479    0.189    0.000    0.189    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
   500    0.001    0.000    0.041    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   506    0.036    0.000    0.036    0.000 {isinstance}
     1    0.002    0.002    0.023    0.023 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     2    0.017    0.009    0.017    0.009 {method 'mean' of 'numpy.ndarray' objects}
  1500    0.004    0.000    0.004    0.000 {sklearn.utils.arrayfuncs.min_pos}
   500    0.004    0.000    0.004    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.004    0.004 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.004    0.004    0.004    0.004 {method 'copy' of 'numpy.ndarray' objects}
   501    0.001    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   501    0.002    0.000    0.002    0.000 {min}
   501    0.002    0.000    0.002    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     2    0.001    0.000    0.001    0.000 {numpy.core.multiarray.zeros}
   481    0.001    0.000    0.001    0.000 {max}
   484    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
    21    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     6    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:408(_get_gram)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     2    0.000    0.000    0.000    0.000 {hasattr}
     4    0.000    0.000    0.000    0.000 {len}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 420
Total time: 1.53222 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   420                                               def fit(self, X, y):
   421                                                   """Fit the model using X, y as training data.
   422
   423                                                   parameters
   424                                                   ----------
   425                                                   X : array-like, shape = [n_samples, n_features]
   426                                                       training data.
   427
   428                                                   y : array-like, shape = [n_samples]
   429                                                       target values.
   430
   431                                                   returns
   432                                                   -------
   433                                                   self : object
   434                                                       returns an instance of self.
   435                                                   """
   436         1           41     41.0      0.0          X = array2d(X)
   437         1            4      4.0      0.0          y = np.asarray(y)
   438
   439         1            2      2.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   440         1            2      2.0      0.0                                                          self.fit_intercept,
   441         1            2      2.0      0.0                                                          self.normalize,
   442         1        71195  71195.0      4.6                                                          self.copy_X)
   443         1            8      8.0      0.0          alpha = getattr(self, 'alpha', 0.)
   444         1            3      3.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   445         1            2      2.0      0.0              alpha = 0.  # n_nonzero_coefs parametrization takes priority
   446         1            1      1.0      0.0              max_iter = self.n_nonzero_coefs
   447                                                   else:
   448                                                       max_iter = self.max_iter
   449
   450         1            9      9.0      0.0          Gram = self._get_gram()
   451
   452         1            2      2.0      0.0          self.alphas_, self.active_, self.coef_path_ = lars_path(X, y,
   453         1            2      2.0      0.0                    Gram=Gram, copy_X=self.copy_X,
   454         1            2      2.0      0.0                    copy_Gram=False, alpha_min=alpha,
   455         1            5      5.0      0.0                    method=self.method, verbose=max(0, self.verbose - 1),
   456         1      1460879 1460879.0     95.3                    max_iter=max_iter, eps=self.eps)
   457
   458         1            6      6.0      0.0          self.coef_ = self.coef_path_[:, -1]
   459
   460         1           53     53.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   461
   462         1            1      1.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lassolars-minimadelon-oney">
<h2>LassoLars-minimadelon-oney<a class="headerlink" href="#lassolars-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoLars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LassoLars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/LassoLars-minimadelon-oney-step0-timing.png" src="_images/LassoLars-minimadelon-oney-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/LassoLars-minimadelon-oney-step0-memory.png" src="_images/LassoLars-minimadelon-oney-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         13357 function calls in 0.685 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.685    0.685 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.685    0.685 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.685    0.685 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:420(fit)
     1    0.524    0.524    0.684    0.684 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:26(lars_path)
  2004    0.064    0.000    0.064    0.000 {numpy.core._dotblas.dot}
    94    0.003    0.000    0.031    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:3267(delete)
    94    0.004    0.000    0.027    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:376(setdiff1d)
   407    0.025    0.000    0.025    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
   188    0.005    0.000    0.012    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
    94    0.004    0.000    0.010    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:281(in1d)
   500    0.002    0.000    0.010    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
  1500    0.009    0.000    0.009    0.000 {sklearn.utils.arrayfuncs.min_pos}
   564    0.009    0.000    0.009    0.000 {numpy.core.multiarray.concatenate}
    94    0.003    0.000    0.008    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/index_tricks.py:237(__getitem__)
   500    0.006    0.000    0.006    0.000 {method 'sum' of 'numpy.ndarray' objects}
   501    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   188    0.003    0.000    0.003    0.000 {method 'argsort' of 'numpy.ndarray' objects}
   501    0.003    0.000    0.003    0.000 {min}
   501    0.003    0.000    0.003    0.000 {method 'argmax' of 'numpy.ndarray' objects}
  1070    0.003    0.000    0.003    0.000 {isinstance}
    94    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:3525(append)
   567    0.002    0.000    0.002    0.000 {numpy.core.multiarray.array}
   284    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    94    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:961(find_common_type)
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
   188    0.001    0.000    0.001    0.000 {method 'sort' of 'numpy.ndarray' objects}
   409    0.001    0.000    0.001    0.000 {max}
    94    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
    95    0.001    0.000    0.001    0.000 {numpy.core.multiarray.arange}
   188    0.001    0.000    0.001    0.000 {method 'flatten' of 'numpy.ndarray' objects}
    94    0.001    0.000    0.001    0.000 {numpy.core.multiarray.where}
    94    0.001    0.000    0.001    0.000 {sklearn.utils.arrayfuncs.cholesky_delete}
    95    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
   882    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
   188    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:946(_can_coerce_all)
   189    0.000    0.000    0.000    0.000 {range}
    94    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
    94    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/index_tricks.py:217(_retval)
   188    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
    94    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
    94    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
   380    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     6    0.000    0.000    0.000    0.000 {getattr}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:408(_get_gram)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 420
Total time: 0.899558 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   420                                               def fit(self, X, y):
   421                                                   """Fit the model using X, y as training data.
   422
   423                                                   parameters
   424                                                   ----------
   425                                                   X : array-like, shape = [n_samples, n_features]
   426                                                       training data.
   427
   428                                                   y : array-like, shape = [n_samples]
   429                                                       target values.
   430
   431                                                   returns
   432                                                   -------
   433                                                   self : object
   434                                                       returns an instance of self.
   435                                                   """
   436         1           58     58.0      0.0          X = array2d(X)
   437         1            7      7.0      0.0          y = np.asarray(y)
   438
   439         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   440         1            2      2.0      0.0                                                          self.fit_intercept,
   441         1            3      3.0      0.0                                                          self.normalize,
   442         1          300    300.0      0.0                                                          self.copy_X)
   443         1            4      4.0      0.0          alpha = getattr(self, 'alpha', 0.)
   444         1            8      8.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   445                                                       alpha = 0.  # n_nonzero_coefs parametrization takes priority
   446                                                       max_iter = self.n_nonzero_coefs
   447                                                   else:
   448         1            3      3.0      0.0              max_iter = self.max_iter
   449
   450         1           10     10.0      0.0          Gram = self._get_gram()
   451
   452         1            2      2.0      0.0          self.alphas_, self.active_, self.coef_path_ = lars_path(X, y,
   453         1            3      3.0      0.0                    Gram=Gram, copy_X=self.copy_X,
   454         1            3      3.0      0.0                    copy_Gram=False, alpha_min=alpha,
   455         1            5      5.0      0.0                    method=self.method, verbose=max(0, self.verbose - 1),
   456         1       899103 899103.0     99.9                    max_iter=max_iter, eps=self.eps)
   457
   458         1            9      9.0      0.0          self.coef_ = self.coef_path_[:, -1]
   459
   460         1           32     32.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   461
   462         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lassolars-madelon">
<h2>LassoLars-madelon<a class="headerlink" href="#lassolars-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoLars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LassoLars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/LassoLars-madelon-step0-timing.png" src="_images/LassoLars-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/LassoLars-madelon-step0-memory.png" src="_images/LassoLars-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         5372 function calls in 0.996 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.996    0.996 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.996    0.996 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.996    0.996 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:420(fit)
     1    0.425    0.425    0.955    0.955 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:26(lars_path)
   722    0.489    0.001    0.489    0.001 {numpy.core._dotblas.dot}
     1    0.004    0.004    0.040    0.040 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     2    0.031    0.015    0.031    0.015 {method 'mean' of 'numpy.ndarray' objects}
   352    0.019    0.000    0.019    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
   357    0.001    0.000    0.007    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
  1071    0.004    0.000    0.004    0.000 {sklearn.utils.arrayfuncs.min_pos}
   357    0.004    0.000    0.004    0.000 {method 'sum' of 'numpy.ndarray' objects}
   358    0.001    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   358    0.002    0.000    0.002    0.000 {method 'argmax' of 'numpy.ndarray' objects}
   358    0.002    0.000    0.002    0.000 {min}
     5    0.000    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:3267(delete)
     5    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:376(setdiff1d)
   393    0.001    0.000    0.001    0.000 {isinstance}
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
   354    0.001    0.000    0.001    0.000 {max}
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     5    0.001    0.000    0.001    0.000 {sklearn.utils.arrayfuncs.cholesky_delete}
     5    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/index_tricks.py:237(__getitem__)
     5    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:281(in1d)
    30    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
   382    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    10    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:3525(append)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
    33    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:961(find_common_type)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    17    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/index_tricks.py:217(_retval)
    10    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
    11    0.000    0.000    0.000    0.000 {range}
    10    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     5    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numerictypes.py:946(_can_coerce_all)
     6    0.000    0.000    0.000    0.000 {getattr}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
    24    0.000    0.000    0.000    0.000 {len}
    10    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
     5    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:408(_get_gram)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 420
Total time: 1.18333 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   420                                               def fit(self, X, y):
   421                                                   """Fit the model using X, y as training data.
   422
   423                                                   parameters
   424                                                   ----------
   425                                                   X : array-like, shape = [n_samples, n_features]
   426                                                       training data.
   427
   428                                                   y : array-like, shape = [n_samples]
   429                                                       target values.
   430
   431                                                   returns
   432                                                   -------
   433                                                   self : object
   434                                                       returns an instance of self.
   435                                                   """
   436         1           61     61.0      0.0          X = array2d(X)
   437         1            7      7.0      0.0          y = np.asarray(y)
   438
   439         1            3      3.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   440         1            2      2.0      0.0                                                          self.fit_intercept,
   441         1            2      2.0      0.0                                                          self.normalize,
   442         1        32762  32762.0      2.8                                                          self.copy_X)
   443         1            6      6.0      0.0          alpha = getattr(self, 'alpha', 0.)
   444         1           10     10.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   445                                                       alpha = 0.  # n_nonzero_coefs parametrization takes priority
   446                                                       max_iter = self.n_nonzero_coefs
   447                                                   else:
   448         1            3      3.0      0.0              max_iter = self.max_iter
   449
   450         1           13     13.0      0.0          Gram = self._get_gram()
   451
   452         1            3      3.0      0.0          self.alphas_, self.active_, self.coef_path_ = lars_path(X, y,
   453         1            2      2.0      0.0                    Gram=Gram, copy_X=self.copy_X,
   454         1            2      2.0      0.0                    copy_Gram=False, alpha_min=alpha,
   455         1            6      6.0      0.0                    method=self.method, verbose=max(0, self.verbose - 1),
   456         1      1150410 1150410.0     97.2                    max_iter=max_iter, eps=self.eps)
   457
   458         1            7      7.0      0.0          self.coef_ = self.coef_path_[:, -1]
   459
   460         1           29     29.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   461
   462         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lasso-minimadelon-oney">
<h2>Lasso-minimadelon-oney<a class="headerlink" href="#lasso-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/Lasso-minimadelon-oney-step0-timing.png" src="_images/Lasso-minimadelon-oney-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/Lasso-minimadelon-oney-step0-memory.png" src="_images/Lasso-minimadelon-oney-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         69 function calls in 0.003 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.003    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.003    0.003 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:131(fit)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:161(_dense_fit)
     1    0.002    0.002    0.002    0.002 {sklearn.linear_model.cd_fast.enet_coordinate_descent}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/linalg/linalg.py:1840(norm)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     8    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 {abs}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {method 'conj' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 131
Total time: 0.002601 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   131                                               def fit(self, X, y, Xy=None, coef_init=None):
   132                                                   """Fit Elastic Net model with coordinate descent
   133
   134                                                   Parameters
   135                                                   -----------
   136                                                   X: ndarray or scipy.sparse matrix, (n_samples, n_features)
   137                                                       Data
   138                                                   y: ndarray, (n_samples)
   139                                                       Target
   140                                                   Xy : array-like, optional
   141                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   142                                                       only when the Gram matrix is precomputed.
   143                                                   coef_init: ndarray of shape n_features
   144                                                       The initial coeffients to warm-start the optimization
   145
   146                                                   Notes
   147                                                   -----
   148
   149                                                   Coordinate descent is an algorithm that considers each column of
   150                                                   data at a time hence it will automatically convert the X input
   151                                                   as a fortran contiguous numpy array if necessary.
   152
   153                                                   To avoid memory re-allocation it is advised to allocate the
   154                                                   initial data in memory directly using that format.
   155                                                   """
   156
   157         1           19     19.0      0.7          fit = self._sparse_fit if sparse.isspmatrix(X) else self._dense_fit
   158         1         2580   2580.0     99.2          fit(X, y, Xy, coef_init)
   159         1            2      2.0      0.1          return self</pre>
</div>
</div>
</div>
<div class="section" id="lasso-madelon">
<h2>Lasso-madelon<a class="headerlink" href="#lasso-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/Lasso-madelon-step0-timing.png" src="_images/Lasso-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/Lasso-madelon-step0-memory.png" src="_images/Lasso-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         68 function calls in 0.900 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.900    0.900 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.900    0.900 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.900    0.900 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:131(fit)
     1    0.000    0.000    0.900    0.900 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:161(_dense_fit)
     1    0.501    0.501    0.502    0.502 {sklearn.linear_model.cd_fast.enet_coordinate_descent_gram}
     3    0.346    0.115    0.346    0.115 {numpy.core._dotblas.dot}
     1    0.004    0.004    0.039    0.039 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     2    0.030    0.015    0.030    0.015 {method 'mean' of 'numpy.ndarray' objects}
     7    0.014    0.002    0.014    0.002 {numpy.core.multiarray.array}
     1    0.000    0.000    0.013    0.013 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/linalg/linalg.py:1840(norm)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     2    0.000    0.000    0.000    0.000 {abs}
     3    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     2    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     6    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'conj' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 131
Total time: 0.982633 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   131                                               def fit(self, X, y, Xy=None, coef_init=None):
   132                                                   """Fit Elastic Net model with coordinate descent
   133
   134                                                   Parameters
   135                                                   -----------
   136                                                   X: ndarray or scipy.sparse matrix, (n_samples, n_features)
   137                                                       Data
   138                                                   y: ndarray, (n_samples)
   139                                                       Target
   140                                                   Xy : array-like, optional
   141                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   142                                                       only when the Gram matrix is precomputed.
   143                                                   coef_init: ndarray of shape n_features
   144                                                       The initial coeffients to warm-start the optimization
   145
   146                                                   Notes
   147                                                   -----
   148
   149                                                   Coordinate descent is an algorithm that considers each column of
   150                                                   data at a time hence it will automatically convert the X input
   151                                                   as a fortran contiguous numpy array if necessary.
   152
   153                                                   To avoid memory re-allocation it is advised to allocate the
   154                                                   initial data in memory directly using that format.
   155                                                   """
   156
   157         1           30     30.0      0.0          fit = self._sparse_fit if sparse.isspmatrix(X) else self._dense_fit
   158         1       982600 982600.0    100.0          fit(X, y, Xy, coef_init)
   159         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="elasticnet-minimadelon-oney">
<h2>ElasticNet-minimadelon-oney<a class="headerlink" href="#elasticnet-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s">&#39;rho&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ElasticNet-minimadelon-oney-step0-timing.png" src="_images/ElasticNet-minimadelon-oney-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ElasticNet-minimadelon-oney-step0-memory.png" src="_images/ElasticNet-minimadelon-oney-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         69 function calls in 0.025 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.025    0.025 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.025    0.025 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.025    0.025 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:131(fit)
     1    0.000    0.000    0.025    0.025 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:161(_dense_fit)
     1    0.024    0.024    0.024    0.024 {sklearn.linear_model.cd_fast.enet_coordinate_descent}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/linalg/linalg.py:1840(norm)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     8    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     2    0.000    0.000    0.000    0.000 {abs}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     2    0.000    0.000    0.000    0.000 {hasattr}
     5    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     3    0.000    0.000    0.000    0.000 {method 'conj' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 122
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   122                                               def predict(self, X):
   123                                                   """Predict using the linear model
   124
   125                                                   Parameters
   126                                                   ----------
   127                                                   X : numpy array of shape [n_samples, n_features]
   128
   129                                                   Returns
   130                                                   -------
   131                                                   C : array, shape = [n_samples]
   132                                                       Returns predicted values.
   133                                                   """
   134                                                   return self.decision_function(X)

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 131
Total time: 0.024582 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   131                                               def fit(self, X, y, Xy=None, coef_init=None):
   132                                                   """Fit Elastic Net model with coordinate descent
   133
   134                                                   Parameters
   135                                                   -----------
   136                                                   X: ndarray or scipy.sparse matrix, (n_samples, n_features)
   137                                                       Data
   138                                                   y: ndarray, (n_samples)
   139                                                       Target
   140                                                   Xy : array-like, optional
   141                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   142                                                       only when the Gram matrix is precomputed.
   143                                                   coef_init: ndarray of shape n_features
   144                                                       The initial coeffients to warm-start the optimization
   145
   146                                                   Notes
   147                                                   -----
   148
   149                                                   Coordinate descent is an algorithm that considers each column of
   150                                                   data at a time hence it will automatically convert the X input
   151                                                   as a fortran contiguous numpy array if necessary.
   152
   153                                                   To avoid memory re-allocation it is advised to allocate the
   154                                                   initial data in memory directly using that format.
   155                                                   """
   156
   157         1           26     26.0      0.1          fit = self._sparse_fit if sparse.isspmatrix(X) else self._dense_fit
   158         1        24553  24553.0     99.9          fit(X, y, Xy, coef_init)
   159         1            3      3.0      0.0          return self</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ElasticNet-minimadelon-oney-step1-timing.png" src="_images/ElasticNet-minimadelon-oney-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ElasticNet-minimadelon-oney-step1-memory.png" src="_images/ElasticNet-minimadelon-oney-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         33 function calls in 0.000 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.000    0.000 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:122(predict)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:275(decision_function)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:107(decision_function)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:23(safe_asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:70(safe_sparse_dot)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     4    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 122
Total time: 0.000207 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   122                                               def predict(self, X):
   123                                                   """Predict using the linear model
   124
   125                                                   Parameters
   126                                                   ----------
   127                                                   X : numpy array of shape [n_samples, n_features]
   128
   129                                                   Returns
   130                                                   -------
   131                                                   C : array, shape = [n_samples]
   132                                                       Returns predicted values.
   133                                                   """
   134         1          207    207.0    100.0          return self.decision_function(X)

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 131
Total time: 0.024582 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   131                                               def fit(self, X, y, Xy=None, coef_init=None):
   132                                                   """Fit Elastic Net model with coordinate descent
   133
   134                                                   Parameters
   135                                                   -----------
   136                                                   X: ndarray or scipy.sparse matrix, (n_samples, n_features)
   137                                                       Data
   138                                                   y: ndarray, (n_samples)
   139                                                       Target
   140                                                   Xy : array-like, optional
   141                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   142                                                       only when the Gram matrix is precomputed.
   143                                                   coef_init: ndarray of shape n_features
   144                                                       The initial coeffients to warm-start the optimization
   145
   146                                                   Notes
   147                                                   -----
   148
   149                                                   Coordinate descent is an algorithm that considers each column of
   150                                                   data at a time hence it will automatically convert the X input
   151                                                   as a fortran contiguous numpy array if necessary.
   152
   153                                                   To avoid memory re-allocation it is advised to allocate the
   154                                                   initial data in memory directly using that format.
   155                                                   """
   156
   157         1           26     26.0      0.1          fit = self._sparse_fit if sparse.isspmatrix(X) else self._dense_fit
   158         1        24553  24553.0     99.9          fit(X, y, Xy, coef_init)
   159         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="orthogonalmatchingpursuit-minimadelon">
<h2>OrthogonalMatchingPursuit-minimadelon<a class="headerlink" href="#orthogonalmatchingpursuit-minimadelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">OrthogonalMatchingPursuit</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;n_nonzero_coefs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">OrthogonalMatchingPursuit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/OrthogonalMatchingPursuit-minimadelon-step0-timing.png" src="_images/OrthogonalMatchingPursuit-minimadelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/OrthogonalMatchingPursuit-minimadelon-step0-memory.png" src="_images/OrthogonalMatchingPursuit-minimadelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         952 function calls in 0.023 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.023    0.023 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.023    0.023 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.023    0.023 /tmp/vb_sklearn/sklearn/linear_model/omp.py:484(fit)
     1    0.001    0.001    0.022    0.022 /tmp/vb_sklearn/sklearn/linear_model/omp.py:206(orthogonal_mp)
    10    0.014    0.001    0.021    0.002 /tmp/vb_sklearn/sklearn/linear_model/omp.py:24(_cholesky_omp)
   301    0.004    0.000    0.004    0.000 {numpy.core._dotblas.dot}
     1    0.001    0.001    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   100    0.001    0.000    0.001    0.000 {method 'argmax' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
    90    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
    20    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    20    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    40    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    30    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
    26    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    16    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
    20    0.000    0.000    0.000    0.000 {issubclass}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    10    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    10    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    41    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
    13    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/omp.py
Function: fit at line 484
Total time: 0.027282 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                               def fit(self, X, y, Gram=None, Xy=None):
   485                                                   """Fit the model using X, y as training data.
   486
   487                                                   Parameters
   488                                                   ----------
   489                                                   X: array-like, shape = (n_samples, n_features)
   490                                                       Training data.
   491
   492                                                   y: array-like, shape = (n_samples,) or (n_samples, n_targets)
   493                                                       Target values.
   494
   495                                                   Gram: array-like, shape = (n_features, n_features) (optional)
   496                                                       Gram matrix of the input data: X.T * X
   497
   498                                                   Xy: array-like, shape = (n_features,) or (n_features, n_targets)
   499                                                       (optional)
   500                                                       Input targets multiplied by X: X.T * y
   501
   502
   503                                                   Returns
   504                                                   -------
   505                                                   self: object
   506                                                       returns an instance of self.
   507                                                   """
   508         1          101    101.0      0.4          X = array2d(X)
   509         1            8      8.0      0.0          y = np.asarray(y)
   510         1            4      4.0      0.0          n_features = X.shape[1]
   511
   512         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   513         1            4      4.0      0.0                                                          self.fit_intercept,
   514         1            3      3.0      0.0                                                          self.normalize,
   515         1          803    803.0      2.9                                                          self.copy_X)
   516
   517         1            5      5.0      0.0          if y.ndim == 1:
   518                                                       y = y[:, np.newaxis]
   519
   520         1            5      5.0      0.0          if self.n_nonzero_coefs == None and self.tol is None:
   521                                                       self.n_nonzero_coefs = int(0.1 * n_features)
   522         1            4      4.0      0.0          if (Gram is not None or Xy is not None) and (self.fit_intercept is True
   523                                                                                            or self.normalize is True):
   524                                                       warnings.warn('Mean subtraction (fit_intercept) and '
   525                                                            'normalization cannot be applied on precomputed Gram '
   526                                                            'and Xy matrices. Your precomputed values are ignored '
   527                                                            'and recomputed. To avoid this, do the scaling yourself '
   528                                                            'and call with fit_intercept and normalize set to False.',
   529                                                            RuntimeWarning, stacklevel=2)
   530                                                       Gram, Xy = None, None
   531
   532         1            3      3.0      0.0          if Gram is not None:
   533                                                       Gram = array2d(Gram)
   534
   535                                                       if self.copy_Gram:
   536                                                           copy_Gram = False
   537                                                           Gram = Gram.copy('F')
   538                                                       else:
   539                                                           Gram = np.asfortranarray(Gram)
   540
   541                                                       copy_Gram = self.copy_Gram
   542
   543                                                       if y.shape[1] &gt; 1:  # subsequent targets will be affected
   544                                                           copy_Gram = True
   545
   546                                                       if Xy is None:
   547                                                           Xy = np.dot(X.T, y)
   548                                                       else:
   549                                                           if self.copy_Xy:
   550                                                               Xy = Xy.copy()
   551                                                           if self.normalize:
   552                                                               if len(Xy.shape) == 1:
   553                                                                   Xy /= X_std
   554                                                               else:
   555                                                                   Xy /= X_std[:, np.newaxis]
   556
   557                                                       if self.normalize:
   558                                                           Gram /= X_std
   559                                                           Gram /= X_std[:, np.newaxis]
   560
   561                                                       norms_sq = np.sum(y ** 2, axis=0) if self.tol is not None else None
   562                                                       self.coef_ = orthogonal_mp_gram(Gram, Xy, self.n_nonzero_coefs,
   563                                                                                       self.tol, norms_sq,
   564                                                                                       copy_Gram, True).T
   565                                                   else:
   566         1            3      3.0      0.0              precompute_gram = self.precompute_gram
   567         1            4      4.0      0.0              if precompute_gram == 'auto':
   568                                                           precompute_gram = X.shape[0] &gt; X.shape[1]
   569         1            4      4.0      0.0              self.coef_ = orthogonal_mp(X, y, self.n_nonzero_coefs, self.tol,
   570         1            4      4.0      0.0                                         precompute_gram=self.precompute_gram,
   571         1        26203  26203.0     96.0                                         copy_X=self.copy_X).T
   572
   573         1          116    116.0      0.4          self._set_intercept(X_mean, y_mean, X_std)
   574         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="orthogonalmatchingpursuit-madelon">
<h2>OrthogonalMatchingPursuit-madelon<a class="headerlink" href="#orthogonalmatchingpursuit-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">OrthogonalMatchingPursuit</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;n_nonzero_coefs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">OrthogonalMatchingPursuit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/OrthogonalMatchingPursuit-madelon-step0-timing.png" src="_images/OrthogonalMatchingPursuit-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/OrthogonalMatchingPursuit-madelon-step0-memory.png" src="_images/OrthogonalMatchingPursuit-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         143 function calls in 0.129 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.129    0.129 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.129    0.129 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.129    0.129 /tmp/vb_sklearn/sklearn/linear_model/omp.py:484(fit)
     1    0.029    0.029    0.095    0.095 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     1    0.000    0.000    0.034    0.034 /tmp/vb_sklearn/sklearn/linear_model/omp.py:206(orthogonal_mp)
     2    0.030    0.015    0.030    0.015 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.030    0.030 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.030    0.030    0.030    0.030 {method 'sum' of 'numpy.ndarray' objects}
     1    0.002    0.002    0.023    0.023 /tmp/vb_sklearn/sklearn/linear_model/omp.py:24(_cholesky_omp)
    31    0.021    0.001    0.021    0.001 {numpy.core._dotblas.dot}
     2    0.016    0.008    0.016    0.008 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
    10    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     9    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     2    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     7    0.000    0.000    0.000    0.000 {isinstance}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     3    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     5    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {max}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/omp.py
Function: fit at line 484
Total time: 0.123942 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                               def fit(self, X, y, Gram=None, Xy=None):
   485                                                   """Fit the model using X, y as training data.
   486
   487                                                   Parameters
   488                                                   ----------
   489                                                   X: array-like, shape = (n_samples, n_features)
   490                                                       Training data.
   491
   492                                                   y: array-like, shape = (n_samples,) or (n_samples, n_targets)
   493                                                       Target values.
   494
   495                                                   Gram: array-like, shape = (n_features, n_features) (optional)
   496                                                       Gram matrix of the input data: X.T * X
   497
   498                                                   Xy: array-like, shape = (n_features,) or (n_features, n_targets)
   499                                                       (optional)
   500                                                       Input targets multiplied by X: X.T * y
   501
   502
   503                                                   Returns
   504                                                   -------
   505                                                   self: object
   506                                                       returns an instance of self.
   507                                                   """
   508         1           67     67.0      0.1          X = array2d(X)
   509         1            8      8.0      0.0          y = np.asarray(y)
   510         1            4      4.0      0.0          n_features = X.shape[1]
   511
   512         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   513         1            4      4.0      0.0                                                          self.fit_intercept,
   514         1            4      4.0      0.0                                                          self.normalize,
   515         1        89287  89287.0     72.0                                                          self.copy_X)
   516
   517         1            7      7.0      0.0          if y.ndim == 1:
   518         1           15     15.0      0.0              y = y[:, np.newaxis]
   519
   520         1            6      6.0      0.0          if self.n_nonzero_coefs == None and self.tol is None:
   521                                                       self.n_nonzero_coefs = int(0.1 * n_features)
   522         1            4      4.0      0.0          if (Gram is not None or Xy is not None) and (self.fit_intercept is True
   523                                                                                            or self.normalize is True):
   524                                                       warnings.warn('Mean subtraction (fit_intercept) and '
   525                                                            'normalization cannot be applied on precomputed Gram '
   526                                                            'and Xy matrices. Your precomputed values are ignored '
   527                                                            'and recomputed. To avoid this, do the scaling yourself '
   528                                                            'and call with fit_intercept and normalize set to False.',
   529                                                            RuntimeWarning, stacklevel=2)
   530                                                       Gram, Xy = None, None
   531
   532         1            3      3.0      0.0          if Gram is not None:
   533                                                       Gram = array2d(Gram)
   534
   535                                                       if self.copy_Gram:
   536                                                           copy_Gram = False
   537                                                           Gram = Gram.copy('F')
   538                                                       else:
   539                                                           Gram = np.asfortranarray(Gram)
   540
   541                                                       copy_Gram = self.copy_Gram
   542
   543                                                       if y.shape[1] &gt; 1:  # subsequent targets will be affected
   544                                                           copy_Gram = True
   545
   546                                                       if Xy is None:
   547                                                           Xy = np.dot(X.T, y)
   548                                                       else:
   549                                                           if self.copy_Xy:
   550                                                               Xy = Xy.copy()
   551                                                           if self.normalize:
   552                                                               if len(Xy.shape) == 1:
   553                                                                   Xy /= X_std
   554                                                               else:
   555                                                                   Xy /= X_std[:, np.newaxis]
   556
   557                                                       if self.normalize:
   558                                                           Gram /= X_std
   559                                                           Gram /= X_std[:, np.newaxis]
   560
   561                                                       norms_sq = np.sum(y ** 2, axis=0) if self.tol is not None else None
   562                                                       self.coef_ = orthogonal_mp_gram(Gram, Xy, self.n_nonzero_coefs,
   563                                                                                       self.tol, norms_sq,
   564                                                                                       copy_Gram, True).T
   565                                                   else:
   566         1            3      3.0      0.0              precompute_gram = self.precompute_gram
   567         1            5      5.0      0.0              if precompute_gram == 'auto':
   568                                                           precompute_gram = X.shape[0] &gt; X.shape[1]
   569         1            4      4.0      0.0              self.coef_ = orthogonal_mp(X, y, self.n_nonzero_coefs, self.tol,
   570         1            4      4.0      0.0                                         precompute_gram=self.precompute_gram,
   571         1        34467  34467.0     27.8                                         copy_X=self.copy_X).T
   572
   573         1           42     42.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   574         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="sgdclassifier-madelon">
<h2>SGDClassifier-madelon<a class="headerlink" href="#sgdclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/SGDClassifier-madelon-step0-timing.png" src="_images/SGDClassifier-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/SGDClassifier-madelon-step0-memory.png" src="_images/SGDClassifier-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         115 function calls in 0.042 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.042    0.042 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.042    0.042 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.042    0.042 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:460(fit)
     1    0.000    0.000    0.039    0.039 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:383(_partial_fit)
     1    0.000    0.000    0.035    0.035 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:600(_fit_binary)
     1    0.000    0.000    0.035    0.035 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:653(fit_binary)
     1    0.035    0.035    0.035    0.035 {sklearn.linear_model.sgd_fast.plain_sgd}
     2    0.000    0.000    0.006    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:23(safe_asarray)
     2    0.000    0.000    0.006    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     2    0.006    0.003    0.006    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1508(any)
    10    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:635(_prepare_fit_binary)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:82(_init_t)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:119(_set_coef)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:182(_make_dataset)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     8    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:358(_set_class_weight)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:128(_allocate_parameter_mem)
     3    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:106(_validate_sample_weight)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     5    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:176(_check_fit_data)
     1    0.000    0.000    0.000    0.000 {max}
     6    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'dloss' of 'sklearn.linear_model.sgd_fast.Hinge' objects}
     2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 460
Total time: 0.041418 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   460                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   461                                                       class_weight=None, sample_weight=None):
   462                                                   """Fit linear model with Stochastic Gradient Descent.
   463
   464                                                   Parameters
   465                                                   ----------
   466                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   467                                                       Training data
   468
   469                                                   y : numpy array of shape [n_samples]
   470                                                       Target values
   471
   472                                                   coef_init : array, shape = [n_classes,n_features]
   473                                                       The initial coeffients to warm-start the optimization.
   474
   475                                                   intercept_init : array, shape = [n_classes]
   476                                                       The initial intercept to warm-start the optimization.
   477
   478                                                   sample_weight : array-like, shape = [n_samples], optional
   479                                                       Weights applied to individual samples.
   480                                                       If not provided, uniform weights are assumed.
   481
   482                                                   Returns
   483                                                   -------
   484                                                   self : returns an instance of self.
   485                                                   """
   486         1            4      4.0      0.0          if class_weight is not None:
   487                                                       warnings.warn("Using 'class_weight' as a parameter to the 'fit'"
   488                                                               "method is deprecated. Set it on initialization instead.",
   489                                                               DeprecationWarning)
   490                                                       self.class_weight = class_weight
   491
   492         1         2769   2769.0      6.7          X = safe_asarray(X, dtype=np.float64, order="C")
   493                                                   # labels can be encoded as float, int, or string literals
   494         1           18     18.0      0.0          y = np.asarray(y)
   495
   496         1            4      4.0      0.0          n_samples, n_features = X.shape
   497         1            8      8.0      0.0          _check_fit_data(X, y)
   498
   499                                                   # np.unique sorts in asc order; largest class id is positive class
   500         1          193    193.0      0.5          classes = np.unique(y)
   501
   502         1            4      4.0      0.0          if self.warm_start and self.coef_ is not None:
   503                                                       if coef_init is None:
   504                                                           coef_init = self.coef_
   505                                                       if intercept_init is None:
   506                                                           intercept_init = self.intercept_
   507                                                   else:
   508         1            4      4.0      0.0              self.coef_ = None
   509         1            3      3.0      0.0              self.intercept_ = None
   510
   511                                                   # Need to re-initialize in case of multiple call to fit.
   512         1           52     52.0      0.1          self._init_t()
   513
   514         1            3      3.0      0.0          self._partial_fit(X, y, self.n_iter, classes,
   515         1        38260  38260.0     92.4                            sample_weight, coef_init, intercept_init)
   516
   517                                                   # fitting is over, we can now transform coef_ to fortran order
   518                                                   # for faster predictions
   519         1           94     94.0      0.2          self._set_coef(self.coef_)
   520
   521         1            2      2.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: predict at line 542
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   542                                               def predict(self, X):
   543                                                   """Predict using the linear model
   544
   545                                                   Parameters
   546                                                   ----------
   547                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   548
   549                                                   Returns
   550                                                   -------
   551                                                   array, shape = [n_samples]
   552                                                      Array containing the predicted class labels.
   553                                                   """
   554                                                   scores = self.decision_function(X)
   555                                                   if self.classes_.shape[0] == 2:
   556                                                       indices = np.array(scores &gt; 0, dtype=np.int)
   557                                                   else:
   558                                                       indices = scores.argmax(axis=1)
   559                                                   return self.classes_[np.ravel(indices)]</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/SGDClassifier-madelon-step1-timing.png" src="_images/SGDClassifier-madelon-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/SGDClassifier-madelon-step1-memory.png" src="_images/SGDClassifier-madelon-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         49 function calls in 0.002 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.002    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.002    0.002 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:542(predict)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:523(decision_function)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:72(atleast2d_or_csr)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.001    0.001    0.001    0.001 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/extmath.py:70(safe_sparse_dot)
     1    0.001    0.001    0.001    0.001 {numpy.core._dotblas.dot}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     4    0.000    0.000    0.000    0.000 {isinstance}
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 460
Total time: 0.041418 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   460                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   461                                                       class_weight=None, sample_weight=None):
   462                                                   """Fit linear model with Stochastic Gradient Descent.
   463
   464                                                   Parameters
   465                                                   ----------
   466                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   467                                                       Training data
   468
   469                                                   y : numpy array of shape [n_samples]
   470                                                       Target values
   471
   472                                                   coef_init : array, shape = [n_classes,n_features]
   473                                                       The initial coeffients to warm-start the optimization.
   474
   475                                                   intercept_init : array, shape = [n_classes]
   476                                                       The initial intercept to warm-start the optimization.
   477
   478                                                   sample_weight : array-like, shape = [n_samples], optional
   479                                                       Weights applied to individual samples.
   480                                                       If not provided, uniform weights are assumed.
   481
   482                                                   Returns
   483                                                   -------
   484                                                   self : returns an instance of self.
   485                                                   """
   486         1            4      4.0      0.0          if class_weight is not None:
   487                                                       warnings.warn("Using 'class_weight' as a parameter to the 'fit'"
   488                                                               "method is deprecated. Set it on initialization instead.",
   489                                                               DeprecationWarning)
   490                                                       self.class_weight = class_weight
   491
   492         1         2769   2769.0      6.7          X = safe_asarray(X, dtype=np.float64, order="C")
   493                                                   # labels can be encoded as float, int, or string literals
   494         1           18     18.0      0.0          y = np.asarray(y)
   495
   496         1            4      4.0      0.0          n_samples, n_features = X.shape
   497         1            8      8.0      0.0          _check_fit_data(X, y)
   498
   499                                                   # np.unique sorts in asc order; largest class id is positive class
   500         1          193    193.0      0.5          classes = np.unique(y)
   501
   502         1            4      4.0      0.0          if self.warm_start and self.coef_ is not None:
   503                                                       if coef_init is None:
   504                                                           coef_init = self.coef_
   505                                                       if intercept_init is None:
   506                                                           intercept_init = self.intercept_
   507                                                   else:
   508         1            4      4.0      0.0              self.coef_ = None
   509         1            3      3.0      0.0              self.intercept_ = None
   510
   511                                                   # Need to re-initialize in case of multiple call to fit.
   512         1           52     52.0      0.1          self._init_t()
   513
   514         1            3      3.0      0.0          self._partial_fit(X, y, self.n_iter, classes,
   515         1        38260  38260.0     92.4                            sample_weight, coef_init, intercept_init)
   516
   517                                                   # fitting is over, we can now transform coef_ to fortran order
   518                                                   # for faster predictions
   519         1           94     94.0      0.2          self._set_coef(self.coef_)
   520
   521         1            2      2.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: predict at line 542
Total time: 0.001634 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   542                                               def predict(self, X):
   543                                                   """Predict using the linear model
   544
   545                                                   Parameters
   546                                                   ----------
   547                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   548
   549                                                   Returns
   550                                                   -------
   551                                                   array, shape = [n_samples]
   552                                                      Array containing the predicted class labels.
   553                                                   """
   554         1         1567   1567.0     95.9          scores = self.decision_function(X)
   555         1            3      3.0      0.2          if self.classes_.shape[0] == 2:
   556         1           33     33.0      2.0              indices = np.array(scores &gt; 0, dtype=np.int)
   557                                                   else:
   558                                                       indices = scores.argmax(axis=1)
   559         1           31     31.0      1.9          return self.classes_[np.ravel(indices)]</pre>
</div>
</div>
</div>
<div class="section" id="sgdclassifier-newsgroups">
<h2>SGDClassifier-newsgroups<a class="headerlink" href="#sgdclassifier-newsgroups" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;newsgroups&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/SGDClassifier-newsgroups-step0-timing.png" src="_images/SGDClassifier-newsgroups-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/SGDClassifier-newsgroups-step0-memory.png" src="_images/SGDClassifier-newsgroups-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         1585 function calls (1578 primitive calls) in 1.979 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.979    1.979 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.979    1.979 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.979    1.979 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:460(fit)
     1    0.000    0.000    1.880    1.880 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:383(_partial_fit)
     1    0.000    0.000    1.847    1.847 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:614(_fit_multiclass)
     1    0.000    0.000    1.780    1.780 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:430(__call__)
    20    0.000    0.000    1.778    0.089 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:292(dispatch)
    20    0.000    0.000    1.777    0.089 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:121(__init__)
    20    0.000    0.000    1.777    0.089 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:653(fit_binary)
    20    1.601    0.080    1.640    0.082 {sklearn.linear_model.sgd_fast.plain_sgd}
    20    0.074    0.004    0.135    0.007 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:635(_prepare_fit_binary)
    23    0.079    0.003    0.079    0.003 {numpy.core.multiarray.array}
     1    0.000    0.000    0.079    0.079 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:119(_set_coef)
     1    0.000    0.000    0.078    0.078 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.067    0.067 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:193(_tocsr)
   2/1    0.000    0.000    0.067    0.067 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:20(__init__)
    24    0.000    0.000    0.061    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    24    0.061    0.003    0.061    0.003 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.055    0.055 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:178(asformat)
     1    0.000    0.000    0.055    0.055 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/coo.py:281(tocsr)
     1    0.000    0.000    0.040    0.040 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/coo.py:75(coo_tocsr)
     1    0.040    0.040    0.040    0.040 {_coo.coo_tocsr}
   200    0.001    0.000    0.039    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1508(any)
     2    0.000    0.000    0.038    0.019 /tmp/vb_sklearn/sklearn/utils/validation.py:23(safe_asarray)
     2    0.000    0.000    0.038    0.019 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     2    0.000    0.000    0.038    0.019 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:486(sum)
   200    0.038    0.000    0.038    0.000 {method 'any' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.037    0.019 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:229(__mul__)
     2    0.000    0.000    0.037    0.018 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/coo.py:370(_mul_vector)
     2    0.000    0.000    0.036    0.018 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/coo.py:174(coo_matvec)
     2    0.036    0.018    0.036    0.018 {_coo.coo_matvec}
     4    0.015    0.004    0.015    0.004 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.014    0.014 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:128(_allocate_parameter_mem)
     1    0.000    0.000    0.014    0.014 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:567(sum_duplicates)
     1    0.012    0.012    0.012    0.012 {method 'astype' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.009    0.009 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:567(csr_sum_duplicates)
     1    0.009    0.009    0.009    0.009 {_csr.csr_sum_duplicates}
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:613(sort_indices)
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:581(__get_sorted)
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:85(csr_has_sorted_indices)
     1    0.005    0.005    0.005    0.005 {_csr.csr_has_sorted_indices}
    21    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:625(&lt;genexpr&gt;)
    20    0.001    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:182(_make_dataset)
    20    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:101(delayed)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     1    0.001    0.001    0.001    0.001 {method 'sort' of 'numpy.ndarray' objects}
    20    0.001    0.000    0.001    0.000 {cPickle.dumps}
    28    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    31    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    20    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:17(update_wrapper)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:101(check_format)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:18(upcast)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.py:403(sum)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:622(prune)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.py:55(asmatrix)
    27    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.py:233(__new__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:390(retrieve)
    62    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    20    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:39(wraps)
 16/10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.py:279(__array_finalize__)
    62    0.000    0.000    0.000    0.000 {isinstance}
     4    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}
   101    0.000    0.000    0.000    0.000 {getattr}
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/coo.py:194(getnnz)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:77(isscalarlike)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    86    0.000    0.000    0.000    0.000 {len}
    60    0.000    0.000    0.000    0.000 {setattr}
    41    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:82(_init_t)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:124(isdense)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.py:365(_align)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
    20    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:106(_validate_sample_weight)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.py:301(__getitem__)
    30    0.000    0.000    0.000    0.000 {numpy.core.multiarray.can_cast}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:358(_set_class_weight)
    20    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:49(_verbosity_filter)
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:50(to_native)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:59(set_shape)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:96(isshape)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1574(isscalar)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/data.py:17(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:90(_set_self)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:39(short_format_time)
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:81(get_shape)
    24    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2116(rank)
     8    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/csr.py:180(_swap)
     2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:85(getnnz)
    41    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/csr.py:395(isspmatrix_csr)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:51(__init__)
     7    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/data.py:20(_get_dtype)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:282(__init__)
    20    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:108(delayed_function)
    20    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:370(__getattr__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:23(_squeeze_time)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:176(_check_fit_data)
     2    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.dtype' objects}
    20    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:126(get)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:54(getdtype)
     1    0.000    0.000    0.000    0.000 {max}
     2    0.000    0.000    0.000    0.000 {time.time}
     1    0.000    0.000    0.000    0.000 {method 'dloss' of 'sklearn.linear_model.sgd_fast.Hinge' objects}
     1    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:337(_print)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 460
Total time: 2.19159 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   460                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   461                                                       class_weight=None, sample_weight=None):
   462                                                   """Fit linear model with Stochastic Gradient Descent.
   463
   464                                                   Parameters
   465                                                   ----------
   466                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   467                                                       Training data
   468
   469                                                   y : numpy array of shape [n_samples]
   470                                                       Target values
   471
   472                                                   coef_init : array, shape = [n_classes,n_features]
   473                                                       The initial coeffients to warm-start the optimization.
   474
   475                                                   intercept_init : array, shape = [n_classes]
   476                                                       The initial intercept to warm-start the optimization.
   477
   478                                                   sample_weight : array-like, shape = [n_samples], optional
   479                                                       Weights applied to individual samples.
   480                                                       If not provided, uniform weights are assumed.
   481
   482                                                   Returns
   483                                                   -------
   484                                                   self : returns an instance of self.
   485                                                   """
   486         1            2      2.0      0.0          if class_weight is not None:
   487                                                       warnings.warn("Using 'class_weight' as a parameter to the 'fit'"
   488                                                               "method is deprecated. Set it on initialization instead.",
   489                                                               DeprecationWarning)
   490                                                       self.class_weight = class_weight
   491
   492         1        11165  11165.0      0.5          X = safe_asarray(X, dtype=np.float64, order="C")
   493                                                   # labels can be encoded as float, int, or string literals
   494         1            9      9.0      0.0          y = np.asarray(y)
   495
   496         1            5      5.0      0.0          n_samples, n_features = X.shape
   497         1            5      5.0      0.0          _check_fit_data(X, y)
   498
   499                                                   # np.unique sorts in asc order; largest class id is positive class
   500         1          640    640.0      0.0          classes = np.unique(y)
   501
   502         1            3      3.0      0.0          if self.warm_start and self.coef_ is not None:
   503                                                       if coef_init is None:
   504                                                           coef_init = self.coef_
   505                                                       if intercept_init is None:
   506                                                           intercept_init = self.intercept_
   507                                                   else:
   508         1            2      2.0      0.0              self.coef_ = None
   509         1            3      3.0      0.0              self.intercept_ = None
   510
   511                                                   # Need to re-initialize in case of multiple call to fit.
   512         1           35     35.0      0.0          self._init_t()
   513
   514         1            2      2.0      0.0          self._partial_fit(X, y, self.n_iter, classes,
   515         1      2128544 2128544.0     97.1                            sample_weight, coef_init, intercept_init)
   516
   517                                                   # fitting is over, we can now transform coef_ to fortran order
   518                                                   # for faster predictions
   519         1        51168  51168.0      2.3          self._set_coef(self.coef_)
   520
   521         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: predict at line 542
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   542                                               def predict(self, X):
   543                                                   """Predict using the linear model
   544
   545                                                   Parameters
   546                                                   ----------
   547                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   548
   549                                                   Returns
   550                                                   -------
   551                                                   array, shape = [n_samples]
   552                                                      Array containing the predicted class labels.
   553                                                   """
   554                                                   scores = self.decision_function(X)
   555                                                   if self.classes_.shape[0] == 2:
   556                                                       indices = np.array(scores &gt; 0, dtype=np.int)
   557                                                   else:
   558                                                       indices = scores.argmax(axis=1)
   559                                                   return self.classes_[np.ravel(indices)]</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/SGDClassifier-newsgroups-step1-timing.png" src="_images/SGDClassifier-newsgroups-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/SGDClassifier-newsgroups-step1-memory.png" src="_images/SGDClassifier-newsgroups-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         187 function calls in 0.199 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.199    0.199 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.199    0.199 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.199    0.199 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:542(predict)
     1    0.001    0.001    0.198    0.198 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:523(decision_function)
     1    0.000    0.000    0.122    0.122 /tmp/vb_sklearn/sklearn/utils/extmath.py:70(safe_sparse_dot)
     1    0.000    0.000    0.122    0.122 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:229(__mul__)
     1    0.000    0.000    0.122    0.122 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:263(_mul_multivector)
     1    0.000    0.000    0.121    0.121 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:320(csr_matvecs)
     1    0.121    0.121    0.121    0.121 {_csr.csr_matvecs}
     1    0.000    0.000    0.076    0.076 /tmp/vb_sklearn/sklearn/utils/validation.py:72(atleast2d_or_csr)
     1    0.000    0.000    0.074    0.074 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/coo.py:281(tocsr)
     1    0.000    0.000    0.063    0.063 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:567(sum_duplicates)
     1    0.000    0.000    0.061    0.061 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:567(csr_sum_duplicates)
     1    0.061    0.061    0.061    0.061 {_csr.csr_sum_duplicates}
     1    0.000    0.000    0.011    0.011 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/coo.py:75(coo_tocsr)
     1    0.011    0.011    0.011    0.011 {_coo.coo_tocsr}
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.000    0.000    0.002    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:310(sum)
     1    0.002    0.002    0.002    0.002 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.002    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:613(sort_indices)
     1    0.000    0.000    0.002    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:581(__get_sorted)
     1    0.000    0.000    0.002    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:85(csr_has_sorted_indices)
     1    0.002    0.002    0.002    0.002 {_csr.csr_has_sorted_indices}
     1    0.001    0.001    0.001    0.001 {method 'argmax' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:20(__init__)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:101(check_format)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:622(prune)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:18(upcast)
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/coo.py:194(getnnz)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:77(isscalarlike)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
    20    0.000    0.000    0.000    0.000 {numpy.core.multiarray.can_cast}
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     8    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:96(isshape)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/data.py:17(__init__)
     8    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/compressed.py:85(getnnz)
    26    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:59(set_shape)
     1    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:50(to_native)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:124(isdense)
    15    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2116(rank)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:51(__init__)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/csr.py:180(_swap)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1574(isscalar)
     9    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:81(get_shape)
     3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:370(__getattr__)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/data.py:20(_get_dtype)
     1    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.dtype' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:54(getdtype)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 460
Total time: 2.19159 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   460                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   461                                                       class_weight=None, sample_weight=None):
   462                                                   """Fit linear model with Stochastic Gradient Descent.
   463
   464                                                   Parameters
   465                                                   ----------
   466                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   467                                                       Training data
   468
   469                                                   y : numpy array of shape [n_samples]
   470                                                       Target values
   471
   472                                                   coef_init : array, shape = [n_classes,n_features]
   473                                                       The initial coeffients to warm-start the optimization.
   474
   475                                                   intercept_init : array, shape = [n_classes]
   476                                                       The initial intercept to warm-start the optimization.
   477
   478                                                   sample_weight : array-like, shape = [n_samples], optional
   479                                                       Weights applied to individual samples.
   480                                                       If not provided, uniform weights are assumed.
   481
   482                                                   Returns
   483                                                   -------
   484                                                   self : returns an instance of self.
   485                                                   """
   486         1            2      2.0      0.0          if class_weight is not None:
   487                                                       warnings.warn("Using 'class_weight' as a parameter to the 'fit'"
   488                                                               "method is deprecated. Set it on initialization instead.",
   489                                                               DeprecationWarning)
   490                                                       self.class_weight = class_weight
   491
   492         1        11165  11165.0      0.5          X = safe_asarray(X, dtype=np.float64, order="C")
   493                                                   # labels can be encoded as float, int, or string literals
   494         1            9      9.0      0.0          y = np.asarray(y)
   495
   496         1            5      5.0      0.0          n_samples, n_features = X.shape
   497         1            5      5.0      0.0          _check_fit_data(X, y)
   498
   499                                                   # np.unique sorts in asc order; largest class id is positive class
   500         1          640    640.0      0.0          classes = np.unique(y)
   501
   502         1            3      3.0      0.0          if self.warm_start and self.coef_ is not None:
   503                                                       if coef_init is None:
   504                                                           coef_init = self.coef_
   505                                                       if intercept_init is None:
   506                                                           intercept_init = self.intercept_
   507                                                   else:
   508         1            2      2.0      0.0              self.coef_ = None
   509         1            3      3.0      0.0              self.intercept_ = None
   510
   511                                                   # Need to re-initialize in case of multiple call to fit.
   512         1           35     35.0      0.0          self._init_t()
   513
   514         1            2      2.0      0.0          self._partial_fit(X, y, self.n_iter, classes,
   515         1      2128544 2128544.0     97.1                            sample_weight, coef_init, intercept_init)
   516
   517                                                   # fitting is over, we can now transform coef_ to fortran order
   518                                                   # for faster predictions
   519         1        51168  51168.0      2.3          self._set_coef(self.coef_)
   520
   521         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: predict at line 542
Total time: 0.15388 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   542                                               def predict(self, X):
   543                                                   """Predict using the linear model
   544
   545                                                   Parameters
   546                                                   ----------
   547                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   548
   549                                                   Returns
   550                                                   -------
   551                                                   array, shape = [n_samples]
   552                                                      Array containing the predicted class labels.
   553                                                   """
   554         1       152888 152888.0     99.4          scores = self.decision_function(X)
   555         1            2      2.0      0.0          if self.classes_.shape[0] == 2:
   556                                                       indices = np.array(scores &gt; 0, dtype=np.int)
   557                                                   else:
   558         1          894    894.0      0.6              indices = scores.argmax(axis=1)
   559         1           96     96.0      0.1          return self.classes_[np.ravel(indices)]</pre>
</div>
</div>
</div>
<div class="section" id="logisticregression-arcene">
<h2>LogisticRegression-arcene<a class="headerlink" href="#logisticregression-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="mf">100000.0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/LogisticRegression-arcene-step0-timing.png" src="_images/LogisticRegression-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/LogisticRegression-arcene-step0-memory.png" src="_images/LogisticRegression-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         51 function calls in 0.536 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.536    0.536 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.536    0.536 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.536    0.536 /tmp/vb_sklearn/sklearn/svm/base.py:621(fit)
     1    0.533    0.533    0.533    0.533 {sklearn.svm.liblinear.train_wrap}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:72(atleast2d_or_csr)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.003    0.003    0.003    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:16(_get_class_weight)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:588(_get_solver_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {sklearn.svm.liblinear.set_verbosity_wrap}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:794(_get_bias)
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 621
Total time: 0.474452 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   621                                               def fit(self, X, y, class_weight=None):
   622                                                   """Fit the model according to the given training data.
   623
   624                                                   Parameters
   625                                                   ----------
   626                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   627                                                       Training vector, where n_samples in the number of samples and
   628                                                       n_features is the number of features.
   629
   630                                                   y : array-like, shape = [n_samples]
   631                                                       Target vector relative to X
   632
   633                                                   class_weight : {dict, 'auto'}, optional
   634                                                       Weights associated with classes. If not given, all classes
   635                                                       are supposed to have weight one.
   636
   637                                                   Returns
   638                                                   -------
   639                                                   self : object
   640                                                       Returns self.
   641                                                   """
   642         1          119    119.0      0.0          if len(np.unique(y)) &lt; 2:
   643                                                       raise ValueError("The number of classes has to be greater than"
   644                                                               " one.")
   645
   646         1            4      4.0      0.0          if class_weight != None:
   647                                                       warnings.warn("'class_weight' is now an initialization parameter."
   648                                                               "Using it in the 'fit' method is deprecated.",
   649                                                               DeprecationWarning)
   650                                                       self.class_weight = class_weight
   651
   652         1         2873   2873.0      0.6          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   653         1           31     31.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   654         1           36     36.0      0.0          self._sparse = sp.isspmatrix(X)
   655
   656                                                   self.class_weight_, self.class_weight_label_ = \
   657         1           72     72.0      0.0                       _get_class_weight(self.class_weight, y)
   658
   659         1            6      6.0      0.0          if X.shape[0] != y.shape[0]:
   660                                                       raise ValueError("X and y have incompatible shapes.\n" +
   661                                                                        "X has %s samples, but y has %s." % \
   662                                                                        (X.shape[0], y.shape[0]))
   663
   664         1            5      5.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   665
   666         1            3      3.0      0.0          if self._sparse:
   667                                                       train = liblinear.csr_train_wrap
   668                                                   else:
   669         1            3      3.0      0.0              train = liblinear.train_wrap
   670
   671         1            3      3.0      0.0          if self.verbose:
   672                                                       print '[LibLinear]',
   673         1           30     30.0      0.0          self.raw_coef_, self.label_ = train(X, y, self._get_solver_type(),
   674         1            7      7.0      0.0                                              self.tol, self._get_bias(), self.C,
   675         1            3      3.0      0.0                                              self.class_weight_label_,
   676         1       471254 471254.0     99.3                                              self.class_weight_)
   677
   678         1            3      3.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: predict at line 680
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   680                                               def predict(self, X):
   681                                                   """Predict target values of X according to the fitted model.
   682
   683                                                   Parameters
   684                                                   ----------
   685                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   686
   687                                                   Returns
   688                                                   -------
   689                                                   C : array, shape = [n_samples]
   690                                                   """
   691                                                   X = self._validate_for_predict(X)
   692
   693                                                   C = 0.0  # C is not useful here
   694
   695                                                   predict = liblinear.csr_predict_wrap if self._sparse \
   696                                                                                        else liblinear.predict_wrap
   697                                                   return predict(X, self.raw_coef_, self._get_solver_type(), self.tol,
   698                                                                  C, self.class_weight_label_, self.class_weight_,
   699                                                                  self.label_, self._get_bias())</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/LogisticRegression-arcene-step1-timing.png" src="_images/LogisticRegression-arcene-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/LogisticRegression-arcene-step1-memory.png" src="_images/LogisticRegression-arcene-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         39 function calls in 0.024 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.024    0.024 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.024    0.024 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.024    0.024 /tmp/vb_sklearn/sklearn/svm/base.py:680(predict)
     1    0.021    0.021    0.021    0.021 {sklearn.svm.liblinear.predict_wrap}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/svm/base.py:736(_validate_for_predict)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:72(atleast2d_or_csr)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.003    0.003    0.003    0.003 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:588(_get_solver_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:728(_check_n_features)
     2    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:794(_get_bias)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     3    0.000    0.000    0.000    0.000 {len}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 621
Total time: 0.474452 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   621                                               def fit(self, X, y, class_weight=None):
   622                                                   """Fit the model according to the given training data.
   623
   624                                                   Parameters
   625                                                   ----------
   626                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   627                                                       Training vector, where n_samples in the number of samples and
   628                                                       n_features is the number of features.
   629
   630                                                   y : array-like, shape = [n_samples]
   631                                                       Target vector relative to X
   632
   633                                                   class_weight : {dict, 'auto'}, optional
   634                                                       Weights associated with classes. If not given, all classes
   635                                                       are supposed to have weight one.
   636
   637                                                   Returns
   638                                                   -------
   639                                                   self : object
   640                                                       Returns self.
   641                                                   """
   642         1          119    119.0      0.0          if len(np.unique(y)) &lt; 2:
   643                                                       raise ValueError("The number of classes has to be greater than"
   644                                                               " one.")
   645
   646         1            4      4.0      0.0          if class_weight != None:
   647                                                       warnings.warn("'class_weight' is now an initialization parameter."
   648                                                               "Using it in the 'fit' method is deprecated.",
   649                                                               DeprecationWarning)
   650                                                       self.class_weight = class_weight
   651
   652         1         2873   2873.0      0.6          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   653         1           31     31.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   654         1           36     36.0      0.0          self._sparse = sp.isspmatrix(X)
   655
   656                                                   self.class_weight_, self.class_weight_label_ = \
   657         1           72     72.0      0.0                       _get_class_weight(self.class_weight, y)
   658
   659         1            6      6.0      0.0          if X.shape[0] != y.shape[0]:
   660                                                       raise ValueError("X and y have incompatible shapes.\n" +
   661                                                                        "X has %s samples, but y has %s." % \
   662                                                                        (X.shape[0], y.shape[0]))
   663
   664         1            5      5.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   665
   666         1            3      3.0      0.0          if self._sparse:
   667                                                       train = liblinear.csr_train_wrap
   668                                                   else:
   669         1            3      3.0      0.0              train = liblinear.train_wrap
   670
   671         1            3      3.0      0.0          if self.verbose:
   672                                                       print '[LibLinear]',
   673         1           30     30.0      0.0          self.raw_coef_, self.label_ = train(X, y, self._get_solver_type(),
   674         1            7      7.0      0.0                                              self.tol, self._get_bias(), self.C,
   675         1            3      3.0      0.0                                              self.class_weight_label_,
   676         1       471254 471254.0     99.3                                              self.class_weight_)
   677
   678         1            3      3.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: predict at line 680
Total time: 0.013569 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   680                                               def predict(self, X):
   681                                                   """Predict target values of X according to the fitted model.
   682
   683                                                   Parameters
   684                                                   ----------
   685                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   686
   687                                                   Returns
   688                                                   -------
   689                                                   C : array, shape = [n_samples]
   690                                                   """
   691         1         1768   1768.0     13.0          X = self._validate_for_predict(X)
   692
   693         1            1      1.0      0.0          C = 0.0  # C is not useful here
   694
   695         1            1      1.0      0.0          predict = liblinear.csr_predict_wrap if self._sparse \
   696         1            2      2.0      0.0                                               else liblinear.predict_wrap
   697         1           19     19.0      0.1          return predict(X, self.raw_coef_, self._get_solver_type(), self.tol,
   698         1            2      2.0      0.0                         C, self.class_weight_label_, self.class_weight_,
   699         1        11776  11776.0     86.8                         self.label_, self._get_bias())</pre>
</div>
</div>
</div>
<div class="section" id="logisticregression-madelon">
<h2>LogisticRegression-madelon<a class="headerlink" href="#logisticregression-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="mf">100000.0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/LogisticRegression-madelon-step0-timing.png" src="_images/LogisticRegression-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/LogisticRegression-madelon-step0-memory.png" src="_images/LogisticRegression-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         51 function calls in 10.053 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000   10.053   10.053 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000   10.053   10.053 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000   10.053   10.053 /tmp/vb_sklearn/sklearn/svm/base.py:621(fit)
     1   10.050   10.050   10.050   10.050 {sklearn.svm.liblinear.train_wrap}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:72(atleast2d_or_csr)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.003    0.003    0.003    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:16(_get_class_weight)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:588(_get_solver_type)
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     3    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {sklearn.svm.liblinear.set_verbosity_wrap}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:794(_get_bias)
     2    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     4    0.000    0.000    0.000    0.000 {len}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 621
Total time: 10.2502 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   621                                               def fit(self, X, y, class_weight=None):
   622                                                   """Fit the model according to the given training data.
   623
   624                                                   Parameters
   625                                                   ----------
   626                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   627                                                       Training vector, where n_samples in the number of samples and
   628                                                       n_features is the number of features.
   629
   630                                                   y : array-like, shape = [n_samples]
   631                                                       Target vector relative to X
   632
   633                                                   class_weight : {dict, 'auto'}, optional
   634                                                       Weights associated with classes. If not given, all classes
   635                                                       are supposed to have weight one.
   636
   637                                                   Returns
   638                                                   -------
   639                                                   self : object
   640                                                       Returns self.
   641                                                   """
   642         1          242    242.0      0.0          if len(np.unique(y)) &lt; 2:
   643                                                       raise ValueError("The number of classes has to be greater than"
   644                                                               " one.")
   645
   646         1            4      4.0      0.0          if class_weight != None:
   647                                                       warnings.warn("'class_weight' is now an initialization parameter."
   648                                                               "Using it in the 'fit' method is deprecated.",
   649                                                               DeprecationWarning)
   650                                                       self.class_weight = class_weight
   651
   652         1         3395   3395.0      0.0          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   653         1           40     40.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   654         1           38     38.0      0.0          self._sparse = sp.isspmatrix(X)
   655
   656                                                   self.class_weight_, self.class_weight_label_ = \
   657         1           73     73.0      0.0                       _get_class_weight(self.class_weight, y)
   658
   659         1            6      6.0      0.0          if X.shape[0] != y.shape[0]:
   660                                                       raise ValueError("X and y have incompatible shapes.\n" +
   661                                                                        "X has %s samples, but y has %s." % \
   662                                                                        (X.shape[0], y.shape[0]))
   663
   664         1            6      6.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   665
   666         1            3      3.0      0.0          if self._sparse:
   667                                                       train = liblinear.csr_train_wrap
   668                                                   else:
   669         1            3      3.0      0.0              train = liblinear.train_wrap
   670
   671         1            3      3.0      0.0          if self.verbose:
   672                                                       print '[LibLinear]',
   673         1           30     30.0      0.0          self.raw_coef_, self.label_ = train(X, y, self._get_solver_type(),
   674         1            8      8.0      0.0                                              self.tol, self._get_bias(), self.C,
   675         1            3      3.0      0.0                                              self.class_weight_label_,
   676         1     10246370 10246370.0    100.0                                              self.class_weight_)
   677
   678         1            5      5.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: predict at line 680
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   680                                               def predict(self, X):
   681                                                   """Predict target values of X according to the fitted model.
   682
   683                                                   Parameters
   684                                                   ----------
   685                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   686
   687                                                   Returns
   688                                                   -------
   689                                                   C : array, shape = [n_samples]
   690                                                   """
   691                                                   X = self._validate_for_predict(X)
   692
   693                                                   C = 0.0  # C is not useful here
   694
   695                                                   predict = liblinear.csr_predict_wrap if self._sparse \
   696                                                                                        else liblinear.predict_wrap
   697                                                   return predict(X, self.raw_coef_, self._get_solver_type(), self.tol,
   698                                                                  C, self.class_weight_label_, self.class_weight_,
   699                                                                  self.label_, self._get_bias())</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/LogisticRegression-madelon-step1-timing.png" src="_images/LogisticRegression-madelon-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/LogisticRegression-madelon-step1-memory.png" src="_images/LogisticRegression-madelon-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         39 function calls in 0.006 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.006    0.006 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.006    0.006 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/svm/base.py:680(predict)
     1    0.005    0.005    0.005    0.005 {sklearn.svm.liblinear.predict_wrap}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/svm/base.py:736(_validate_for_predict)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:72(atleast2d_or_csr)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:10(assert_all_finite)
     1    0.001    0.001    0.001    0.001 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:64(array2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:588(_get_solver_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:728(_check_n_features)
     3    0.000    0.000    0.000    0.000 {len}
     2    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:794(_get_bias)
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 621
Total time: 10.2502 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   621                                               def fit(self, X, y, class_weight=None):
   622                                                   """Fit the model according to the given training data.
   623
   624                                                   Parameters
   625                                                   ----------
   626                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   627                                                       Training vector, where n_samples in the number of samples and
   628                                                       n_features is the number of features.
   629
   630                                                   y : array-like, shape = [n_samples]
   631                                                       Target vector relative to X
   632
   633                                                   class_weight : {dict, 'auto'}, optional
   634                                                       Weights associated with classes. If not given, all classes
   635                                                       are supposed to have weight one.
   636
   637                                                   Returns
   638                                                   -------
   639                                                   self : object
   640                                                       Returns self.
   641                                                   """
   642         1          242    242.0      0.0          if len(np.unique(y)) &lt; 2:
   643                                                       raise ValueError("The number of classes has to be greater than"
   644                                                               " one.")
   645
   646         1            4      4.0      0.0          if class_weight != None:
   647                                                       warnings.warn("'class_weight' is now an initialization parameter."
   648                                                               "Using it in the 'fit' method is deprecated.",
   649                                                               DeprecationWarning)
   650                                                       self.class_weight = class_weight
   651
   652         1         3395   3395.0      0.0          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   653         1           40     40.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   654         1           38     38.0      0.0          self._sparse = sp.isspmatrix(X)
   655
   656                                                   self.class_weight_, self.class_weight_label_ = \
   657         1           73     73.0      0.0                       _get_class_weight(self.class_weight, y)
   658
   659         1            6      6.0      0.0          if X.shape[0] != y.shape[0]:
   660                                                       raise ValueError("X and y have incompatible shapes.\n" +
   661                                                                        "X has %s samples, but y has %s." % \
   662                                                                        (X.shape[0], y.shape[0]))
   663
   664         1            6      6.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   665
   666         1            3      3.0      0.0          if self._sparse:
   667                                                       train = liblinear.csr_train_wrap
   668                                                   else:
   669         1            3      3.0      0.0              train = liblinear.train_wrap
   670
   671         1            3      3.0      0.0          if self.verbose:
   672                                                       print '[LibLinear]',
   673         1           30     30.0      0.0          self.raw_coef_, self.label_ = train(X, y, self._get_solver_type(),
   674         1            8      8.0      0.0                                              self.tol, self._get_bias(), self.C,
   675         1            3      3.0      0.0                                              self.class_weight_label_,
   676         1     10246370 10246370.0    100.0                                              self.class_weight_)
   677
   678         1            5      5.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: predict at line 680
Total time: 0.005631 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   680                                               def predict(self, X):
   681                                                   """Predict target values of X according to the fitted model.
   682
   683                                                   Parameters
   684                                                   ----------
   685                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   686
   687                                                   Returns
   688                                                   -------
   689                                                   C : array, shape = [n_samples]
   690                                                   """
   691         1          992    992.0     17.6          X = self._validate_for_predict(X)
   692
   693         1            3      3.0      0.1          C = 0.0  # C is not useful here
   694
   695         1            2      2.0      0.0          predict = liblinear.csr_predict_wrap if self._sparse \
   696         1            2      2.0      0.0                                               else liblinear.predict_wrap
   697         1           26     26.0      0.5          return predict(X, self.raw_coef_, self._get_solver_type(), self.tol,
   698         1            4      4.0      0.1                         C, self.class_weight_label_, self.class_weight_,
   699         1         4602   4602.0     81.7                         self.label_, self._get_bias())</pre>
</div>
</div>
</div>
<div class="section" id="ardregression-minimadelon-oney">
<h2>ARDRegression-minimadelon-oney<a class="headerlink" href="#ardregression-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ARDRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ARDRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ARDRegression-minimadelon-oney-step0-timing.png" src="_images/ARDRegression-minimadelon-oney-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ARDRegression-minimadelon-oney-step0-memory.png" src="_images/ARDRegression-minimadelon-oney-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         1098 function calls in 0.079 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.079    0.079 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.079    0.079 &lt;f&gt;:1(&lt;module&gt;)
     1    0.027    0.027    0.079    0.079 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:339(fit)
    14    0.000    0.000    0.028    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:457(pinv)
    14    0.023    0.002    0.027    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:365(lstsq)
    85    0.021    0.000    0.021    0.000 {numpy.core._dotblas.dot}
    42    0.002    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    14    0.000    0.000    0.002    0.000 {map}
    84    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}
    14    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    72    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    85    0.001    0.000    0.001    0.000 {numpy.core.multiarray.array}
    27    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
    42    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    41    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/twodim_base.py:220(diag)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/twodim_base.py:169(eye)
    42    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1830(identity)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:96(check_arrays)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
    29    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
    28    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
    14    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.generic' objects}
    13    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
    33    0.000    0.000    0.000    0.000 {isinstance}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    28    0.000    0.000    0.000    0.000 {getattr}
    36    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    56    0.000    0.000    0.000    0.000 {issubclass}
    15    0.000    0.000    0.000    0.000 {range}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    14    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    71    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    44    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:89(_num_samples)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    28    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     3    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     4    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 339
Total time: 0.081119 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   339                                               def fit(self, X, y):
   340                                                   """Fit the ARDRegression model according to the given training data
   341                                                   and parameters.
   342
   343                                                   Iterative procedure to maximize the evidence
   344
   345                                                   Parameters
   346                                                   ----------
   347                                                   X : array-like, shape = [n_samples, n_features]
   348                                                       Training vector, where n_samples in the number of samples and
   349                                                       n_features is the number of features.
   350                                                   y : array, shape = [n_samples]
   351                                                       Target values (integers)
   352
   353                                                   Returns
   354                                                   -------
   355                                                   self : returns an instance of self.
   356                                                   """
   357         1            6      6.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   358         1          128    128.0      0.2                              dtype=np.float)
   359
   360         1            4      4.0      0.0          n_samples, n_features = X.shape
   361         1           13     13.0      0.0          coef_ = np.zeros(n_features)
   362
   363         1            5      5.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   364         1          351    351.0      0.4                  self.fit_intercept, self.normalize, self.copy_X)
   365
   366                                                   ### Launch the convergence loop
   367         1           18     18.0      0.0          keep_lambda = np.ones(n_features, dtype=bool)
   368
   369         1            5      5.0      0.0          lambda_1 = self.lambda_1
   370         1            4      4.0      0.0          lambda_2 = self.lambda_2
   371         1            5      5.0      0.0          alpha_1 = self.alpha_1
   372         1            4      4.0      0.0          alpha_2 = self.alpha_2
   373         1            4      4.0      0.0          verbose = self.verbose
   374
   375                                                   ### Initialization of the values of the parameters
   376         1           86     86.0      0.1          alpha_ = 1. / np.var(y)
   377         1           19     19.0      0.0          lambda_ = np.ones(n_features)
   378
   379         1            7      7.0      0.0          self.scores_ = list()
   380         1            3      3.0      0.0          coef_old_ = None
   381
   382                                                   ### Iterative procedure of ARDRegression
   383        14           72      5.1      0.1          for iter_ in range(self.n_iter):
   384                                                       ### Compute mu and sigma (using Woodbury matrix identity)
   385        14          698     49.9      0.9              sigma_ = linalg.pinv(np.eye(n_samples) / alpha_ +
   386        14         3552    253.7      4.4                            np.dot(X[:, keep_lambda] *
   387        14         1191     85.1      1.5                            np.reshape(1. / lambda_[keep_lambda], [1, -1]),
   388        14        36127   2580.5     44.5                            X[:, keep_lambda].T))
   389        14         3559    254.2      4.4              sigma_ = np.dot(sigma_, X[:, keep_lambda]
   390        14         4289    306.4      5.3                            * np.reshape(1. / lambda_[keep_lambda], [1, -1]))
   391        14          710     50.7      0.9              sigma_ = - np.dot(np.reshape(1. / lambda_[keep_lambda], [-1, 1])
   392        14        18956   1354.0     23.4                                                  * X[:, keep_lambda].T, sigma_)
   393        14          209     14.9      0.3              sigma_.flat[::(sigma_.shape[1] + 1)] += \
   394        14          658     47.0      0.8                            1. / lambda_[keep_lambda]
   395        14           68      4.9      0.1              coef_[keep_lambda] = alpha_ * np.dot(
   396        14         4983    355.9      6.1                                          sigma_, np.dot(X[:, keep_lambda].T, y))
   397
   398                                                       ### Update alpha and lambda
   399        14         1095     78.2      1.3              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   400        14         1017     72.6      1.3              gamma_ = 1. - lambda_[keep_lambda] * np.diag(sigma_)
   401        14          203     14.5      0.3              lambda_[keep_lambda] = (gamma_ + 2. * lambda_1) \
   402        14          772     55.1      1.0                              / ((coef_[keep_lambda]) ** 2 + 2. * lambda_2)
   403        14          355     25.4      0.4              alpha_ = (n_samples - gamma_.sum() + 2. * alpha_1) \
   404        14          119      8.5      0.1                              / (rmse_ + 2. * alpha_2)
   405
   406                                                       ### Prune the weights with a precision over a threshold
   407        14          229     16.4      0.3              keep_lambda = lambda_ &lt; self.threshold_lambda
   408        14          494     35.3      0.6              coef_[keep_lambda == False] = 0
   409
   410                                                       ### Compute the objective function
   411        14           60      4.3      0.1              if self.compute_score:
   412                                                           s = (lambda_1 * np.log(lambda_) - lambda_2 * lambda_).sum()
   413                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   414                                                           s += 0.5 * (fast_logdet(sigma_) + n_samples * log(alpha_)
   415                                                                                           + np.sum(np.log(lambda_)))
   416                                                           s -= 0.5 * (alpha_ * rmse_ + (lambda_ * coef_ ** 2).sum())
   417                                                           self.scores_.append(s)
   418
   419                                                       ### Check for convergence
   420        14          741     52.9      0.9              if iter_ &gt; 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   421         1            4      4.0      0.0                  if verbose:
   422                                                               print "Converged after %s iterations" % iter_
   423         1            9      9.0      0.0                  break
   424        13          233     17.9      0.3              coef_old_ = np.copy(coef_)
   425
   426         1            7      7.0      0.0          self.coef_ = coef_
   427         1            4      4.0      0.0          self.alpha_ = alpha_
   428         1            4      4.0      0.0          self.sigma_ = sigma_
   429
   430         1           36     36.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   431         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="ardregression-blobs">
<h2>ARDRegression-blobs<a class="headerlink" href="#ardregression-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ARDRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ARDRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ARDRegression-blobs-step0-timing.png" src="_images/ARDRegression-blobs-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ARDRegression-blobs-step0-memory.png" src="_images/ARDRegression-blobs-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         950 function calls in 3.332 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    3.332    3.332 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    3.332    3.332 &lt;f&gt;:1(&lt;module&gt;)
     1    0.064    0.064    3.332    3.332 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:339(fit)
    12    0.000    0.000    3.172    0.264 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:457(pinv)
    12    3.025    0.252    3.129    0.261 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:365(lstsq)
    36    0.133    0.004    0.144    0.004 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    12    0.000    0.000    0.102    0.009 {map}
    73    0.093    0.001    0.093    0.001 {numpy.core._dotblas.dot}
    72    0.010    0.000    0.010    0.000 {method 'any' of 'numpy.ndarray' objects}
    25    0.002    0.000    0.002    0.000 {numpy.core.multiarray.zeros}
    12    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/twodim_base.py:169(eye)
    12    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1830(identity)
    62    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    12    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    73    0.001    0.000    0.001    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
    23    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    36    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    35    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/twodim_base.py:220(diag)
    36    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:96(check_arrays)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.generic' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
    24    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    29    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    24    0.000    0.000    0.000    0.000 {getattr}
    32    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    48    0.000    0.000    0.000    0.000 {issubclass}
    24    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
    13    0.000    0.000    0.000    0.000 {range}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    12    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:89(_num_samples)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
    38    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    61    0.000    0.000    0.000    0.000 {len}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     6    0.000    0.000    0.000    0.000 {hasattr}
     3    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 339
Total time: 3.46973 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   339                                               def fit(self, X, y):
   340                                                   """Fit the ARDRegression model according to the given training data
   341                                                   and parameters.
   342
   343                                                   Iterative procedure to maximize the evidence
   344
   345                                                   Parameters
   346                                                   ----------
   347                                                   X : array-like, shape = [n_samples, n_features]
   348                                                       Training vector, where n_samples in the number of samples and
   349                                                       n_features is the number of features.
   350                                                   y : array, shape = [n_samples]
   351                                                       Target values (integers)
   352
   353                                                   Returns
   354                                                   -------
   355                                                   self : returns an instance of self.
   356                                                   """
   357         1            6      6.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   358         1          160    160.0      0.0                              dtype=np.float)
   359
   360         1            5      5.0      0.0          n_samples, n_features = X.shape
   361         1           11     11.0      0.0          coef_ = np.zeros(n_features)
   362
   363         1            5      5.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   364         1          378    378.0      0.0                  self.fit_intercept, self.normalize, self.copy_X)
   365
   366                                                   ### Launch the convergence loop
   367         1           19     19.0      0.0          keep_lambda = np.ones(n_features, dtype=bool)
   368
   369         1            5      5.0      0.0          lambda_1 = self.lambda_1
   370         1            4      4.0      0.0          lambda_2 = self.lambda_2
   371         1            4      4.0      0.0          alpha_1 = self.alpha_1
   372         1            4      4.0      0.0          alpha_2 = self.alpha_2
   373         1            4      4.0      0.0          verbose = self.verbose
   374
   375                                                   ### Initialization of the values of the parameters
   376         1           73     73.0      0.0          alpha_ = 1. / np.var(y)
   377         1           18     18.0      0.0          lambda_ = np.ones(n_features)
   378
   379         1            6      6.0      0.0          self.scores_ = list()
   380         1            4      4.0      0.0          coef_old_ = None
   381
   382                                                   ### Iterative procedure of ARDRegression
   383        12           72      6.0      0.0          for iter_ in range(self.n_iter):
   384                                                       ### Compute mu and sigma (using Woodbury matrix identity)
   385        12         8885    740.4      0.3              sigma_ = linalg.pinv(np.eye(n_samples) / alpha_ +
   386        12         8268    689.0      0.2                            np.dot(X[:, keep_lambda] *
   387        12         1447    120.6      0.0                            np.reshape(1. / lambda_[keep_lambda], [1, -1]),
   388        12      3369708 280809.0     97.1                            X[:, keep_lambda].T))
   389        12         8088    674.0      0.2              sigma_ = np.dot(sigma_, X[:, keep_lambda]
   390        12        42343   3528.6      1.2                            * np.reshape(1. / lambda_[keep_lambda], [1, -1]))
   391        12          642     53.5      0.0              sigma_ = - np.dot(np.reshape(1. / lambda_[keep_lambda], [-1, 1])
   392        12        15741   1311.8      0.5                                                  * X[:, keep_lambda].T, sigma_)
   393        12          168     14.0      0.0              sigma_.flat[::(sigma_.shape[1] + 1)] += \
   394        12          449     37.4      0.0                            1. / lambda_[keep_lambda]
   395        12           61      5.1      0.0              coef_[keep_lambda] = alpha_ * np.dot(
   396        12         8838    736.5      0.3                                          sigma_, np.dot(X[:, keep_lambda].T, y))
   397
   398                                                       ### Update alpha and lambda
   399        12         1149     95.8      0.0              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   400        12          811     67.6      0.0              gamma_ = 1. - lambda_[keep_lambda] * np.diag(sigma_)
   401        12          179     14.9      0.0              lambda_[keep_lambda] = (gamma_ + 2. * lambda_1) \
   402        12          460     38.3      0.0                              / ((coef_[keep_lambda]) ** 2 + 2. * lambda_2)
   403        12          312     26.0      0.0              alpha_ = (n_samples - gamma_.sum() + 2. * alpha_1) \
   404        12          115      9.6      0.0                              / (rmse_ + 2. * alpha_2)
   405
   406                                                       ### Prune the weights with a precision over a threshold
   407        12          205     17.1      0.0              keep_lambda = lambda_ &lt; self.threshold_lambda
   408        12          244     20.3      0.0              coef_[keep_lambda == False] = 0
   409
   410                                                       ### Compute the objective function
   411        12           67      5.6      0.0              if self.compute_score:
   412                                                           s = (lambda_1 * np.log(lambda_) - lambda_2 * lambda_).sum()
   413                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   414                                                           s += 0.5 * (fast_logdet(sigma_) + n_samples * log(alpha_)
   415                                                                                           + np.sum(np.log(lambda_)))
   416                                                           s -= 0.5 * (alpha_ * rmse_ + (lambda_ * coef_ ** 2).sum())
   417                                                           self.scores_.append(s)
   418
   419                                                       ### Check for convergence
   420        12          522     43.5      0.0              if iter_ &gt; 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   421         1            5      5.0      0.0                  if verbose:
   422                                                               print "Converged after %s iterations" % iter_
   423         1            9      9.0      0.0                  break
   424        11          181     16.5      0.0              coef_old_ = np.copy(coef_)
   425
   426         1            7      7.0      0.0          self.coef_ = coef_
   427         1            5      5.0      0.0          self.alpha_ = alpha_
   428         1            4      4.0      0.0          self.sigma_ = sigma_
   429
   430         1           32     32.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   431         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="bayesianridge-arcene">
<h2>BayesianRidge-arcene<a class="headerlink" href="#bayesianridge-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">BayesianRidge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/BayesianRidge-arcene-step0-timing.png" src="_images/BayesianRidge-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/BayesianRidge-arcene-step0-memory.png" src="_images/BayesianRidge-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         115 function calls in 1.041 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.041    1.041 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.041    1.041 &lt;f&gt;:1(&lt;module&gt;)
     1    0.001    0.001    1.041    1.041 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:126(fit)
     1    0.805    0.805    0.837    0.837 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp_svd.py:14(svd)
    10    0.191    0.019    0.191    0.019 {numpy.core._dotblas.dot}
     1    0.028    0.028    0.031    0.031 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.003    0.003    0.012    0.012 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     2    0.004    0.002    0.004    0.002 {method 'mean' of 'numpy.ndarray' objects}
     2    0.003    0.002    0.003    0.002 {method 'any' of 'numpy.ndarray' objects}
     7    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:96(check_arrays)
     7    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 {range}
    13    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:89(_num_samples)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     6    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 {getattr}
     4    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {issubclass}
     3    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 126
Total time: 1.13806 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                               def fit(self, X, y):
   127                                                   """Fit the model
   128
   129                                                   Parameters
   130                                                   ----------
   131                                                   X : numpy array of shape [n_samples,n_features]
   132                                                       Training data
   133                                                   y : numpy array of shape [n_samples]
   134                                                       Target values
   135
   136                                                   Returns
   137                                                   -------
   138                                                   self : returns an instance of self.
   139                                                   """
   140         1            4      4.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   141         1          125    125.0      0.0                              dtype=np.float)
   142         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   143         1         8296   8296.0      0.7                  self.fit_intercept, self.normalize, self.copy_X)
   144         1            5      5.0      0.0          n_samples, n_features = X.shape
   145
   146                                                   ### Initialization of the values of the parameters
   147         1           67     67.0      0.0          alpha_ = 1. / np.var(y)
   148         1            3      3.0      0.0          lambda_ = 1.
   149
   150         1            4      4.0      0.0          verbose = self.verbose
   151         1            6      6.0      0.0          lambda_1 = self.lambda_1
   152         1            4      4.0      0.0          lambda_2 = self.lambda_2
   153         1            4      4.0      0.0          alpha_1 = self.alpha_1
   154         1            4      4.0      0.0          alpha_2 = self.alpha_2
   155
   156         1            7      7.0      0.0          self.scores_ = list()
   157         1            3      3.0      0.0          coef_old_ = None
   158
   159         1         2075   2075.0      0.2          XT_y = np.dot(X.T, y)
   160         1       933675 933675.0     82.0          U, S, Vh = linalg.svd(X, full_matrices=False)
   161         1           39     39.0      0.0          eigen_vals_ = S ** 2
   162
   163                                                   ### Convergence loop of the bayesian ridge regression
   164         2           28     14.0      0.0          for iter_ in range(self.n_iter):
   165
   166                                                       ### Compute mu and sigma
   167                                                       # sigma_ = lambda_ / alpha_ * np.eye(n_features) + np.dot(X.T, X)
   168                                                       # coef_ = sigma_^-1 * XT * y
   169         2            8      4.0      0.0              if n_samples &gt; n_features:
   170                                                           coef_ = np.dot(Vh.T,
   171                                                                          Vh / (eigen_vals_ + lambda_ / alpha_)[:, None])
   172                                                           coef_ = np.dot(coef_, XT_y)
   173                                                           if self.compute_score:
   174                                                               logdet_sigma_ = - np.sum(
   175                                                                   np.log(lambda_ + alpha_ * eigen_vals_))
   176                                                       else:
   177         2           16      8.0      0.0                  coef_ = np.dot(X.T, np.dot(
   178         2       184926  92463.0     16.2                          U / (eigen_vals_ + lambda_ / alpha_)[None, :], U.T))
   179         2         3943   1971.5      0.3                  coef_ = np.dot(coef_, y)
   180         2           14      7.0      0.0                  if self.compute_score:
   181                                                               logdet_sigma_ = lambda_ * np.ones(n_features)
   182                                                               logdet_sigma_[:n_samples] += alpha_ * eigen_vals_
   183                                                               logdet_sigma_ = - np.sum(np.log(logdet_sigma_))
   184
   185                                                       ### Update alpha and lambda
   186         2         3945   1972.5      0.3              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   187         2           50     25.0      0.0              gamma_ = (np.sum((alpha_ * eigen_vals_)
   188         2           99     49.5      0.0                              / (lambda_ + alpha_ * eigen_vals_)))
   189         2           28     14.0      0.0              lambda_ = ((gamma_ + 2 * lambda_1)
   190         2          189     94.5      0.0                              / (np.sum(coef_ ** 2) + 2 * lambda_2))
   191         2           26     13.0      0.0              alpha_ = ((n_samples - gamma_ + 2 * alpha_1)
   192         2           15      7.5      0.0                              / (rmse_ + 2 * alpha_2))
   193
   194                                                       ### Compute the objective function
   195         2            9      4.5      0.0              if self.compute_score:
   196                                                           s = lambda_1 * log(lambda_) - lambda_2 * lambda_
   197                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   198                                                           s += 0.5 * (n_features * log(lambda_)
   199                                                                          + n_samples * log(alpha_)
   200                                                                          - alpha_ * rmse_
   201                                                                          - (lambda_ * np.sum(coef_ ** 2))
   202                                                                          - logdet_sigma_
   203                                                                          - n_samples * log(2 * np.pi))
   204                                                           self.scores_.append(s)
   205
   206                                                       ### Check for convergence
   207         2          251    125.5      0.0              if iter_ != 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   208         1            5      5.0      0.0                  if verbose:
   209                                                               print "Convergence after ", str(iter_), " iterations"
   210         1           10     10.0      0.0                  break
   211         1           34     34.0      0.0              coef_old_ = np.copy(coef_)
   212
   213         1            5      5.0      0.0          self.alpha_ = alpha_
   214         1            4      4.0      0.0          self.lambda_ = lambda_
   215         1            4      4.0      0.0          self.coef_ = coef_
   216
   217         1          125    125.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   218         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="bayesianridge-madelon">
<h2>BayesianRidge-madelon<a class="headerlink" href="#bayesianridge-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">BayesianRidge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/BayesianRidge-madelon-step0-timing.png" src="_images/BayesianRidge-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/BayesianRidge-madelon-step0-memory.png" src="_images/BayesianRidge-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         249 function calls in 3.307 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    3.307    3.307 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    3.307    3.307 &lt;f&gt;:1(&lt;module&gt;)
     1    0.063    0.063    3.307    3.307 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:126(fit)
     1    2.141    2.141    2.173    2.173 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/decomp_svd.py:14(svd)
    32    1.031    0.032    1.031    0.032 {numpy.core._dotblas.dot}
     1    0.004    0.004    0.039    0.039 /tmp/vb_sklearn/sklearn/linear_model/base.py:70(center_data)
     1    0.028    0.028    0.031    0.031 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     2    0.031    0.015    0.031    0.015 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:33(as_float_array)
     1    0.004    0.004    0.004    0.004 {method 'copy' of 'numpy.ndarray' objects}
     2    0.004    0.002    0.004    0.002 {method 'any' of 'numpy.ndarray' objects}
    39    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    39    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:96(check_arrays)
    45    0.000    0.000    0.000    0.000 {isinstance}
     9    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:138(_set_intercept)
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:89(_num_samples)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 {getattr}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     3    0.000    0.000    0.000    0.000 {len}
     4    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 126
Total time: 3.42883 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   126                                               def fit(self, X, y):
   127                                                   """Fit the model
   128
   129                                                   Parameters
   130                                                   ----------
   131                                                   X : numpy array of shape [n_samples,n_features]
   132                                                       Training data
   133                                                   y : numpy array of shape [n_samples]
   134                                                       Target values
   135
   136                                                   Returns
   137                                                   -------
   138                                                   self : returns an instance of self.
   139                                                   """
   140         1            5      5.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   141         1          185    185.0      0.0                              dtype=np.float)
   142         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   143         1        48989  48989.0      1.4                  self.fit_intercept, self.normalize, self.copy_X)
   144         1            6      6.0      0.0          n_samples, n_features = X.shape
   145
   146                                                   ### Initialization of the values of the parameters
   147         1           96     96.0      0.0          alpha_ = 1. / np.var(y)
   148         1            4      4.0      0.0          lambda_ = 1.
   149
   150         1            4      4.0      0.0          verbose = self.verbose
   151         1            6      6.0      0.0          lambda_1 = self.lambda_1
   152         1            4      4.0      0.0          lambda_2 = self.lambda_2
   153         1            5      5.0      0.0          alpha_1 = self.alpha_1
   154         1            4      4.0      0.0          alpha_2 = self.alpha_2
   155
   156         1            7      7.0      0.0          self.scores_ = list()
   157         1            3      3.0      0.0          coef_old_ = None
   158
   159         1         2384   2384.0      0.1          XT_y = np.dot(X.T, y)
   160         1      2247400 2247400.0     65.5          U, S, Vh = linalg.svd(X, full_matrices=False)
   161         1           41     41.0      0.0          eigen_vals_ = S ** 2
   162
   163                                                   ### Convergence loop of the bayesian ridge regression
   164        10           77      7.7      0.0          for iter_ in range(self.n_iter):
   165
   166                                                       ### Compute mu and sigma
   167                                                       # sigma_ = lambda_ / alpha_ * np.eye(n_features) + np.dot(X.T, X)
   168                                                       # coef_ = sigma_^-1 * XT * y
   169        10           40      4.0      0.0              if n_samples &gt; n_features:
   170        10           67      6.7      0.0                  coef_ = np.dot(Vh.T,
   171        10      1090635 109063.5     31.8                                 Vh / (eigen_vals_ + lambda_ / alpha_)[:, None])
   172        10         4681    468.1      0.1                  coef_ = np.dot(coef_, XT_y)
   173        10           57      5.7      0.0                  if self.compute_score:
   174                                                               logdet_sigma_ = - np.sum(
   175                                                                   np.log(lambda_ + alpha_ * eigen_vals_))
   176                                                       else:
   177                                                           coef_ = np.dot(X.T, np.dot(
   178                                                                   U / (eigen_vals_ + lambda_ / alpha_)[None, :], U.T))
   179                                                           coef_ = np.dot(coef_, y)
   180                                                           if self.compute_score:
   181                                                               logdet_sigma_ = lambda_ * np.ones(n_features)
   182                                                               logdet_sigma_[:n_samples] += alpha_ * eigen_vals_
   183                                                               logdet_sigma_ = - np.sum(np.log(logdet_sigma_))
   184
   185                                                       ### Update alpha and lambda
   186        10        31628   3162.8      0.9              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   187        10          297     29.7      0.0              gamma_ = (np.sum((alpha_ * eigen_vals_)
   188        10          634     63.4      0.0                              / (lambda_ + alpha_ * eigen_vals_)))
   189        10          139     13.9      0.0              lambda_ = ((gamma_ + 2 * lambda_1)
   190        10          365     36.5      0.0                              / (np.sum(coef_ ** 2) + 2 * lambda_2))
   191        10          123     12.3      0.0              alpha_ = ((n_samples - gamma_ + 2 * alpha_1)
   192        10          160     16.0      0.0                              / (rmse_ + 2 * alpha_2))
   193
   194                                                       ### Compute the objective function
   195        10           49      4.9      0.0              if self.compute_score:
   196                                                           s = lambda_1 * log(lambda_) - lambda_2 * lambda_
   197                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   198                                                           s += 0.5 * (n_features * log(lambda_)
   199                                                                          + n_samples * log(alpha_)
   200                                                                          - alpha_ * rmse_
   201                                                                          - (lambda_ * np.sum(coef_ ** 2))
   202                                                                          - logdet_sigma_
   203                                                                          - n_samples * log(2 * np.pi))
   204                                                           self.scores_.append(s)
   205
   206                                                       ### Check for convergence
   207        10          474     47.4      0.0              if iter_ != 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   208         1            4      4.0      0.0                  if verbose:
   209                                                               print "Convergence after ", str(iter_), " iterations"
   210         1           10     10.0      0.0                  break
   211         9          186     20.7      0.0              coef_old_ = np.copy(coef_)
   212
   213         1            4      4.0      0.0          self.alpha_ = alpha_
   214         1            4      4.0      0.0          self.lambda_ = lambda_
   215         1            4      4.0      0.0          self.coef_ = coef_
   216
   217         1           40     40.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   218         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>

        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; .
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/vb_linear_model.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="vb_gaussian_process.html">
        Previous
      </a>  
    </div>
    <div class="buttonNext">
      <a href="vb_manifold.html">
        Next
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>