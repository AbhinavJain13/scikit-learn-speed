
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Benchmarks for linear_model &mdash; Vbench performance benchmarks for scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.12-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Vbench performance benchmarks for scikit-learn" href="index.html" />
    <link rel="next" title="Benchmarks for manifold" href="vb_manifold.html" />
    <link rel="prev" title="Benchmarks for gaussian_process" href="vb_gaussian_process.html" />

  <!-- Reference the theme's stylesheet on the Google CDN -->
  <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/excite-bike/jquery-ui.css"
        type="text/css" rel="Stylesheet" />
 
  <!-- Reference jQuery and jQuery UI from the CDN. Remember
       that the order of these two elements is important -->
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js"></script>

<script type="text/javascript">
      $(function(){
        $(".profiler-output").accordion({collapsible: true, header: "p", active: false} );
      });
    </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="http://scikit-learn.org/">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="quick_start.html">Speed Quick Start</a></li>
            <li><a href="http://scikit-learn.org/dev/user_guide.html">User's Guide</a></li>
            <li><a href="http://scikit-learn.org/dev/developers/performance.html">Performance</a></li>
            <li><a href="http://github.com/scikit-learn/scikit-learn">Github</a></li>
            <li><a href="http://github.com/vene/scikit-learn-speed">Speed Github</a></li>
       </ul>
</div>
<!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
          <h3>Table Of Contents</h3>
          
          <!--
	   <div class="rel rellarge">
	     
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  --
	<div class="rellink">
	<a href="vb_gaussian_process.html" title="Benchmarks for gaussian_process"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Benchmarks for g...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for gaussian_process
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="vb_manifold.html" title="Benchmarks for manifold"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Benchmarks for m...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for manifold
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page --
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.12-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Benchmarks for linear_model</a><ul>
<li><a class="reference internal" href="#ridge-arcene">Ridge-arcene</a></li>
<li><a class="reference internal" href="#ridge-madelon">Ridge-madelon</a></li>
<li><a class="reference internal" href="#lars-minimadelon-oney">Lars-minimadelon-oney</a></li>
<li><a class="reference internal" href="#lars-madelon">Lars-madelon</a></li>
<li><a class="reference internal" href="#lassolars-minimadelon-oney">LassoLars-minimadelon-oney</a></li>
<li><a class="reference internal" href="#lassolars-madelon">LassoLars-madelon</a></li>
<li><a class="reference internal" href="#lasso-minimadelon-oney">Lasso-minimadelon-oney</a></li>
<li><a class="reference internal" href="#lasso-madelon">Lasso-madelon</a></li>
<li><a class="reference internal" href="#elasticnet-minimadelon-oney">ElasticNet-minimadelon-oney</a></li>
<li><a class="reference internal" href="#orthogonalmatchingpursuit-minimadelon">OrthogonalMatchingPursuit-minimadelon</a></li>
<li><a class="reference internal" href="#orthogonalmatchingpursuit-madelon">OrthogonalMatchingPursuit-madelon</a></li>
<li><a class="reference internal" href="#sgdclassifier-madelon">SGDClassifier-madelon</a></li>
<li><a class="reference internal" href="#sgdclassifier-newsgroups">SGDClassifier-newsgroups</a></li>
<li><a class="reference internal" href="#logisticregression-arcene">LogisticRegression-arcene</a></li>
<li><a class="reference internal" href="#logisticregression-madelon">LogisticRegression-madelon</a></li>
<li><a class="reference internal" href="#ardregression-minimadelon-oney">ARDRegression-minimadelon-oney</a></li>
<li><a class="reference internal" href="#ardregression-blobs">ARDRegression-blobs</a></li>
<li><a class="reference internal" href="#bayesianridge-arcene">BayesianRidge-arcene</a></li>
<li><a class="reference internal" href="#bayesianridge-madelon">BayesianRidge-madelon</a></li>
</ul>
</li>
</ul>

    
  -->
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="benchmarks-for-linear-model">
<h1>Benchmarks for linear_model<a class="headerlink" href="#benchmarks-for-linear-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="ridge-arcene">
<h2>Ridge-arcene<a class="headerlink" href="#ridge-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/Ridge-arcene-step0-timing.png"><img alt="_images/Ridge-arcene-step0-timing.png" src="_images/Ridge-arcene-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/Ridge-arcene-step0-memory.png"><img alt="_images/Ridge-arcene-step0-memory.png" src="_images/Ridge-arcene-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         192 function calls in 0.086 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.086    0.086 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.086    0.086 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.086    0.086 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:431(fit)
     1    0.000    0.000    0.086    0.086 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:325(fit)
     1    0.000    0.000    0.071    0.071 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:167(ridge_regression)
     2    0.000    0.000    0.069    0.034 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     2    0.048    0.024    0.069    0.034 /tmp/vb_sklearn/sklearn/utils/extmath.py:73(_fast_dot)
     4    0.000    0.000    0.020    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     4    0.020    0.005    0.020    0.005 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.018    0.009 /tmp/vb_sklearn/sklearn/utils/extmath.py:63(_impose_f_order)
     2    0.000    0.000    0.018    0.009 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.003    0.003    0.013    0.013 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     2    0.004    0.002    0.004    0.002 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.003    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:50(safe_asarray)
     2    0.000    0.000    0.003    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:39(assert_all_finite)
     2    0.002    0.001    0.002    0.001 {numpy.core._dotblas.dot}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:111(_solve_dense_cholesky_kernel)
     1    0.001    0.001    0.001    0.001 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/basic.py:19(solve)
     1    0.000    0.000    0.000    0.000 {map}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     4    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1938(array_equal)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    11    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    18    0.000    0.000    0.000    0.000 {isinstance}
     7    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
    26    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/abc.py:128(__instancecheck__)
     2    0.000    0.000    0.000    0.000 {any}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {_warnings.warn}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     6    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:102(&lt;genexpr&gt;)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/_weakrefset.py:68(__contains__)
     3    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}
     9    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {min}
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     4    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/ridge.py
Function: fit at line 431
Total time: 0.079014 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   431                                               def fit(self, X, y, sample_weight=1.0):
   432                                                   """Fit Ridge regression model
   433
   434                                                   Parameters
   435                                                   ----------
   436                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   437                                                       Training data
   438
   439                                                   y : array-like, shape = [n_samples] or [n_samples, n_targets]
   440                                                       Target values
   441
   442                                                   sample_weight : float or numpy array of shape [n_samples]
   443                                                       Individual weights for each sample
   444
   445                                                   Returns
   446                                                   -------
   447                                                   self : returns an instance of self.
   448                                                   """
   449         1        79014  79014.0    100.0          return super(Ridge, self).fit(X, y, sample_weight=sample_weight)</pre>
</div>
</div>
</div>
<div class="section" id="ridge-madelon">
<h2>Ridge-madelon<a class="headerlink" href="#ridge-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/Ridge-madelon-step0-timing.png"><img alt="_images/Ridge-madelon-step0-timing.png" src="_images/Ridge-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/Ridge-madelon-step0-memory.png"><img alt="_images/Ridge-madelon-step0-memory.png" src="_images/Ridge-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         192 function calls in 0.279 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.279    0.279 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.279    0.279 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.279    0.279 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:431(fit)
     1    0.000    0.000    0.279    0.279 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:325(fit)
     1    0.000    0.000    0.254    0.254 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:167(ridge_regression)
     1    0.000    0.000    0.254    0.254 /tmp/vb_sklearn/sklearn/linear_model/ridge.py:87(_solve_dense_cholesky)
     2    0.000    0.000    0.237    0.118 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     2    0.194    0.097    0.236    0.118 /tmp/vb_sklearn/sklearn/utils/extmath.py:73(_fast_dot)
     4    0.000    0.000    0.043    0.011 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     4    0.042    0.011    0.042    0.011 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.041    0.020 /tmp/vb_sklearn/sklearn/utils/extmath.py:63(_impose_f_order)
     2    0.000    0.000    0.041    0.020 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.002    0.002    0.023    0.023 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     1    0.013    0.013    0.017    0.017 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/basic.py:19(solve)
     2    0.017    0.008    0.017    0.008 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.004    0.004 {map}
     2    0.003    0.001    0.004    0.002 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     1    0.003    0.003    0.003    0.003 {method 'copy' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.002    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:50(safe_asarray)
     2    0.000    0.000    0.002    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:39(assert_all_finite)
     2    0.002    0.001    0.002    0.001 {numpy.core._dotblas.dot}
     4    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1938(array_equal)
    11    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     7    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    17    0.000    0.000    0.000    0.000 {isinstance}
    26    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/abc.py:128(__instancecheck__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     1    0.000    0.000    0.000    0.000 {_warnings.warn}
     2    0.000    0.000    0.000    0.000 {any}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/_weakrefset.py:68(__contains__)
     6    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:102(&lt;genexpr&gt;)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     4    0.000    0.000    0.000    0.000 {getattr}
     3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}
     4    0.000    0.000    0.000    0.000 {min}
     9    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     4    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/ridge.py
Function: fit at line 431
Total time: 0.423805 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   431                                               def fit(self, X, y, sample_weight=1.0):
   432                                                   """Fit Ridge regression model
   433
   434                                                   Parameters
   435                                                   ----------
   436                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   437                                                       Training data
   438
   439                                                   y : array-like, shape = [n_samples] or [n_samples, n_targets]
   440                                                       Target values
   441
   442                                                   sample_weight : float or numpy array of shape [n_samples]
   443                                                       Individual weights for each sample
   444
   445                                                   Returns
   446                                                   -------
   447                                                   self : returns an instance of self.
   448                                                   """
   449         1       423805 423805.0    100.0          return super(Ridge, self).fit(X, y, sample_weight=sample_weight)</pre>
</div>
</div>
</div>
<div class="section" id="lars-minimadelon-oney">
<h2>Lars-minimadelon-oney<a class="headerlink" href="#lars-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/Lars-minimadelon-oney-step0-timing.png"><img alt="_images/Lars-minimadelon-oney-step0-timing.png" src="_images/Lars-minimadelon-oney-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/Lars-minimadelon-oney-step0-memory.png"><img alt="_images/Lars-minimadelon-oney-step0-memory.png" src="_images/Lars-minimadelon-oney-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7523 function calls in 0.610 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.610    0.610 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.610    0.610 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.610    0.610 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:521(fit)
     1    0.498    0.498    0.609    0.609 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:29(lars_path)
  1708    0.058    0.000    0.058    0.000 {numpy.core._dotblas.dot}
   353    0.021    0.000    0.021    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
   500    0.002    0.000    0.010    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
  1500    0.010    0.000    0.010    0.000 {sklearn.utils.arrayfuncs.min_pos}
   501    0.006    0.000    0.006    0.000 {method 'sum' of 'numpy.ndarray' objects}
   506    0.001    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   501    0.004    0.000    0.004    0.000 {min}
   506    0.003    0.000    0.003    0.000 {method 'argmax' of 'numpy.ndarray' objects}
   506    0.002    0.000    0.002    0.000 {isinstance}
   153    0.001    0.000    0.001    0.000 {numpy.core.multiarray.where}
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
   355    0.001    0.000    0.001    0.000 {max}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
   357    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     5    0.000    0.000    0.000    0.000 {_warnings.warn}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     6    0.000    0.000    0.000    0.000 {getattr}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:510(_get_gram)
     3    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 {issubclass}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 521
Total time: 0.832293 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   521                                               def fit(self, X, y, Xy=None):
   522                                                   """Fit the model using X, y as training data.
   523
   524                                                   parameters
   525                                                   ----------
   526                                                   X : array-like, shape (n_samples, n_features)
   527                                                       Training data.
   528
   529                                                   y : array-like, shape (n_samples,) or (n_samples, n_targets)
   530                                                       Target values.
   531
   532                                                   Xy : array-like, shape (n_samples,) or (n_samples, n_targets), \
   533                                                           optional
   534                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   535                                                       only when the Gram matrix is precomputed.
   536
   537                                                   returns
   538                                                   -------
   539                                                   self : object
   540                                                       returns an instance of self.
   541                                                   """
   542         1          158    158.0      0.0          X = array2d(X)
   543         1           12     12.0      0.0          y = np.asarray(y)
   544         1            5      5.0      0.0          n_features = X.shape[1]
   545
   546         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   547         1            3      3.0      0.0                                                          self.fit_intercept,
   548         1            4      4.0      0.0                                                          self.normalize,
   549         1          366    366.0      0.0                                                          self.copy_X)
   550
   551         1            5      5.0      0.0          if y.ndim == 1:
   552         1           10     10.0      0.0              y = y[:, np.newaxis]
   553
   554         1            4      4.0      0.0          n_targets = y.shape[1]
   555
   556         1           10     10.0      0.0          alpha = getattr(self, 'alpha', 0.)
   557         1            5      5.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   558         1            4      4.0      0.0              alpha = 0.  # n_nonzero_coefs parametrization takes priority
   559         1            3      3.0      0.0              max_iter = self.n_nonzero_coefs
   560                                                   else:
   561                                                       max_iter = self.max_iter
   562
   563         1            4      4.0      0.0          precompute = self.precompute
   564         1            6      6.0      0.0          if not hasattr(precompute, '__array__') and (
   565         1            4      4.0      0.0                  precompute is True or
   566         1            6      6.0      0.0                  (precompute == 'auto' and X.shape[0] &gt; X.shape[1]) or
   567         1            4      4.0      0.0                  (precompute == 'auto' and y.shape[1] &gt; 1)):
   568                                                       Gram = np.dot(X.T, X)
   569                                                   else:
   570         1           12     12.0      0.0              Gram = self._get_gram()
   571
   572         1            4      4.0      0.0          self.alphas_ = []
   573
   574         1            4      4.0      0.0          if self.fit_path:
   575         1            4      4.0      0.0              self.coef_ = []
   576         1            3      3.0      0.0              self.active_ = []
   577         1            4      4.0      0.0              self.coef_path_ = []
   578         2            9      4.5      0.0              for k in xrange(n_targets):
   579         1            4      4.0      0.0                  this_Xy = None if Xy is None else Xy[:, k]
   580         1            3      3.0      0.0                  alphas, active, coef_path = lars_path(
   581         1            9      9.0      0.0                      X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   582         1            4      4.0      0.0                      copy_Gram=True, alpha_min=alpha, method=self.method,
   583         1            6      6.0      0.0                      verbose=max(0, self.verbose - 1), max_iter=max_iter,
   584         1       831537 831537.0     99.9                      eps=self.eps, return_path=True)
   585         1            5      5.0      0.0                  self.alphas_.append(alphas)
   586         1            3      3.0      0.0                  self.active_.append(active)
   587         1            3      3.0      0.0                  self.coef_path_.append(coef_path)
   588         1            5      5.0      0.0                  self.coef_.append(coef_path[:, -1])
   589
   590         1            2      2.0      0.0              if n_targets == 1:
   591                                                           self.alphas_, self.active_, self.coef_path_, self.coef_ = [
   592         1            3      3.0      0.0                      a[0] for a in (self.alphas_, self.active_, self.coef_path_,
   593         5           13      2.6      0.0                                     self.coef_)]
   594                                                   else:
   595                                                       self.coef_ = np.empty((n_targets, n_features))
   596                                                       for k in xrange(n_targets):
   597                                                           this_Xy = None if Xy is None else Xy[:, k]
   598                                                           alphas, _, self.coef_[k] = lars_path(
   599                                                               X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   600                                                               copy_Gram=True, alpha_min=alpha, method=self.method,
   601                                                               verbose=max(0, self.verbose - 1), max_iter=max_iter,
   602                                                               eps=self.eps, return_path=False)
   603                                                           self.alphas_.append(alphas)
   604                                                       if n_targets == 1:
   605                                                           self.alphas_ = self.alphas_[0]
   606         1           37     37.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   607         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lars-madelon">
<h2>Lars-madelon<a class="headerlink" href="#lars-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/Lars-madelon-step0-timing.png"><img alt="_images/Lars-madelon-step0-timing.png" src="_images/Lars-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/Lars-madelon-step0-memory.png"><img alt="_images/Lars-madelon-step0-memory.png" src="_images/Lars-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7032 function calls in 1.368 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.368    1.368 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.368    1.368 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.368    1.368 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:521(fit)
     1    0.733    0.733    0.955    0.955 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:29(lars_path)
   982    0.514    0.001    0.514    0.001 {numpy.core._dotblas.dot}
   479    0.048    0.000    0.048    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
     1    0.004    0.004    0.040    0.040 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     2    0.030    0.015    0.030    0.015 {method 'mean' of 'numpy.ndarray' objects}
   500    0.002    0.000    0.011    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   501    0.009    0.000    0.009    0.000 {method 'sum' of 'numpy.ndarray' objects}
  1500    0.008    0.000    0.008    0.000 {sklearn.utils.arrayfuncs.min_pos}
     2    0.006    0.003    0.006    0.003 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
   501    0.002    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   501    0.004    0.000    0.004    0.000 {min}
   501    0.003    0.000    0.003    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
   506    0.002    0.000    0.002    0.000 {isinstance}
   481    0.001    0.000    0.001    0.000 {max}
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
   488    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    21    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     6    0.000    0.000    0.000    0.000 {getattr}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     2    0.000    0.000    0.000    0.000 {hasattr}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 521
Total time: 1.51138 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   521                                               def fit(self, X, y, Xy=None):
   522                                                   """Fit the model using X, y as training data.
   523
   524                                                   parameters
   525                                                   ----------
   526                                                   X : array-like, shape (n_samples, n_features)
   527                                                       Training data.
   528
   529                                                   y : array-like, shape (n_samples,) or (n_samples, n_targets)
   530                                                       Target values.
   531
   532                                                   Xy : array-like, shape (n_samples,) or (n_samples, n_targets), \
   533                                                           optional
   534                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   535                                                       only when the Gram matrix is precomputed.
   536
   537                                                   returns
   538                                                   -------
   539                                                   self : object
   540                                                       returns an instance of self.
   541                                                   """
   542         1         2818   2818.0      0.2          X = array2d(X)
   543         1           18     18.0      0.0          y = np.asarray(y)
   544         1            7      7.0      0.0          n_features = X.shape[1]
   545
   546         1            5      5.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   547         1            4      4.0      0.0                                                          self.fit_intercept,
   548         1            4      4.0      0.0                                                          self.normalize,
   549         1        36951  36951.0      2.4                                                          self.copy_X)
   550
   551         1            7      7.0      0.0          if y.ndim == 1:
   552         1           14     14.0      0.0              y = y[:, np.newaxis]
   553
   554         1            4      4.0      0.0          n_targets = y.shape[1]
   555
   556         1           13     13.0      0.0          alpha = getattr(self, 'alpha', 0.)
   557         1            5      5.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   558         1            3      3.0      0.0              alpha = 0.  # n_nonzero_coefs parametrization takes priority
   559         1            4      4.0      0.0              max_iter = self.n_nonzero_coefs
   560                                                   else:
   561                                                       max_iter = self.max_iter
   562
   563         1            4      4.0      0.0          precompute = self.precompute
   564         1            8      8.0      0.0          if not hasattr(precompute, '__array__') and (
   565         1            4      4.0      0.0                  precompute is True or
   566         1            6      6.0      0.0                  (precompute == 'auto' and X.shape[0] &gt; X.shape[1]) or
   567                                                           (precompute == 'auto' and y.shape[1] &gt; 1)):
   568         1       399019 399019.0     26.4              Gram = np.dot(X.T, X)
   569                                                   else:
   570                                                       Gram = self._get_gram()
   571
   572         1           10     10.0      0.0          self.alphas_ = []
   573
   574         1            5      5.0      0.0          if self.fit_path:
   575         1            5      5.0      0.0              self.coef_ = []
   576         1            5      5.0      0.0              self.active_ = []
   577         1            4      4.0      0.0              self.coef_path_ = []
   578         2           18      9.0      0.0              for k in xrange(n_targets):
   579         1            4      4.0      0.0                  this_Xy = None if Xy is None else Xy[:, k]
   580         1            4      4.0      0.0                  alphas, active, coef_path = lars_path(
   581         1           20     20.0      0.0                      X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   582         1            5      5.0      0.0                      copy_Gram=True, alpha_min=alpha, method=self.method,
   583         1           10     10.0      0.0                      verbose=max(0, self.verbose - 1), max_iter=max_iter,
   584         1      1072220 1072220.0     70.9                      eps=self.eps, return_path=True)
   585         1            8      8.0      0.0                  self.alphas_.append(alphas)
   586         1            5      5.0      0.0                  self.active_.append(active)
   587         1            5      5.0      0.0                  self.coef_path_.append(coef_path)
   588         1            9      9.0      0.0                  self.coef_.append(coef_path[:, -1])
   589
   590         1            4      4.0      0.0              if n_targets == 1:
   591                                                           self.alphas_, self.active_, self.coef_path_, self.coef_ = [
   592         1            5      5.0      0.0                      a[0] for a in (self.alphas_, self.active_, self.coef_path_,
   593         5           26      5.2      0.0                                     self.coef_)]
   594                                                   else:
   595                                                       self.coef_ = np.empty((n_targets, n_features))
   596                                                       for k in xrange(n_targets):
   597                                                           this_Xy = None if Xy is None else Xy[:, k]
   598                                                           alphas, _, self.coef_[k] = lars_path(
   599                                                               X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   600                                                               copy_Gram=True, alpha_min=alpha, method=self.method,
   601                                                               verbose=max(0, self.verbose - 1), max_iter=max_iter,
   602                                                               eps=self.eps, return_path=False)
   603                                                           self.alphas_.append(alphas)
   604                                                       if n_targets == 1:
   605                                                           self.alphas_ = self.alphas_[0]
   606         1          104    104.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   607         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lassolars-minimadelon-oney">
<h2>LassoLars-minimadelon-oney<a class="headerlink" href="#lassolars-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoLars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LassoLars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/LassoLars-minimadelon-oney-step0-timing.png"><img alt="_images/LassoLars-minimadelon-oney-step0-timing.png" src="_images/LassoLars-minimadelon-oney-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/LassoLars-minimadelon-oney-step0-memory.png"><img alt="_images/LassoLars-minimadelon-oney-step0-memory.png" src="_images/LassoLars-minimadelon-oney-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         645 function calls in 0.021 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.021    0.021 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.021    0.021 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.021    0.021 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:521(fit)
     1    0.012    0.012    0.020    0.020 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:29(lars_path)
    98    0.003    0.000    0.003    0.000 {numpy.core._dotblas.dot}
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
     3    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:3267(delete)
     3    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:376(setdiff1d)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
    23    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:281(in1d)
    69    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.min_pos}
    18    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
    24    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/index_tricks.py:237(__getitem__)
    26    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
    26    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}
    24    0.000    0.000    0.000    0.000 {min}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}
    47    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
    22    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:3525(append)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    21    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numerictypes.py:961(find_common_type)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    24    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     6    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {_warnings.warn}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     6    0.000    0.000    0.000    0.000 {getattr}
     3    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.cholesky_delete}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    44    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/index_tricks.py:217(_retval)
     7    0.000    0.000    0.000    0.000 {range}
     3    0.000    0.000    0.000    0.000 {hasattr}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}
     3    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numerictypes.py:946(_can_coerce_all)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
     6    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:510(_get_gram)
    16    0.000    0.000    0.000    0.000 {len}
     3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 521
Total time: 0.025285 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   521                                               def fit(self, X, y, Xy=None):
   522                                                   """Fit the model using X, y as training data.
   523
   524                                                   parameters
   525                                                   ----------
   526                                                   X : array-like, shape (n_samples, n_features)
   527                                                       Training data.
   528
   529                                                   y : array-like, shape (n_samples,) or (n_samples, n_targets)
   530                                                       Target values.
   531
   532                                                   Xy : array-like, shape (n_samples,) or (n_samples, n_targets), \
   533                                                           optional
   534                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   535                                                       only when the Gram matrix is precomputed.
   536
   537                                                   returns
   538                                                   -------
   539                                                   self : object
   540                                                       returns an instance of self.
   541                                                   """
   542         1          150    150.0      0.6          X = array2d(X)
   543         1           12     12.0      0.0          y = np.asarray(y)
   544         1            5      5.0      0.0          n_features = X.shape[1]
   545
   546         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   547         1            4      4.0      0.0                                                          self.fit_intercept,
   548         1            3      3.0      0.0                                                          self.normalize,
   549         1          344    344.0      1.4                                                          self.copy_X)
   550
   551         1            5      5.0      0.0          if y.ndim == 1:
   552         1           10     10.0      0.0              y = y[:, np.newaxis]
   553
   554         1            4      4.0      0.0          n_targets = y.shape[1]
   555
   556         1            5      5.0      0.0          alpha = getattr(self, 'alpha', 0.)
   557         1            9      9.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   558                                                       alpha = 0.  # n_nonzero_coefs parametrization takes priority
   559                                                       max_iter = self.n_nonzero_coefs
   560                                                   else:
   561         1            3      3.0      0.0              max_iter = self.max_iter
   562
   563         1            4      4.0      0.0          precompute = self.precompute
   564         1            7      7.0      0.0          if not hasattr(precompute, '__array__') and (
   565         1            3      3.0      0.0                  precompute is True or
   566         1            6      6.0      0.0                  (precompute == 'auto' and X.shape[0] &gt; X.shape[1]) or
   567         1            5      5.0      0.0                  (precompute == 'auto' and y.shape[1] &gt; 1)):
   568                                                       Gram = np.dot(X.T, X)
   569                                                   else:
   570         1           24     24.0      0.1              Gram = self._get_gram()
   571
   572         1            5      5.0      0.0          self.alphas_ = []
   573
   574         1            4      4.0      0.0          if self.fit_path:
   575         1            4      4.0      0.0              self.coef_ = []
   576         1            4      4.0      0.0              self.active_ = []
   577         1            3      3.0      0.0              self.coef_path_ = []
   578         2           12      6.0      0.0              for k in xrange(n_targets):
   579         1            4      4.0      0.0                  this_Xy = None if Xy is None else Xy[:, k]
   580         1            3      3.0      0.0                  alphas, active, coef_path = lars_path(
   581         1            9      9.0      0.0                      X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   582         1            4      4.0      0.0                      copy_Gram=True, alpha_min=alpha, method=self.method,
   583         1            7      7.0      0.0                      verbose=max(0, self.verbose - 1), max_iter=max_iter,
   584         1        24515  24515.0     97.0                      eps=self.eps, return_path=True)
   585         1            7      7.0      0.0                  self.alphas_.append(alphas)
   586         1            4      4.0      0.0                  self.active_.append(active)
   587         1            5      5.0      0.0                  self.coef_path_.append(coef_path)
   588         1           11     11.0      0.0                  self.coef_.append(coef_path[:, -1])
   589
   590         1            4      4.0      0.0              if n_targets == 1:
   591                                                           self.alphas_, self.active_, self.coef_path_, self.coef_ = [
   592         1            4      4.0      0.0                      a[0] for a in (self.alphas_, self.active_, self.coef_path_,
   593         5           22      4.4      0.1                                     self.coef_)]
   594                                                   else:
   595                                                       self.coef_ = np.empty((n_targets, n_features))
   596                                                       for k in xrange(n_targets):
   597                                                           this_Xy = None if Xy is None else Xy[:, k]
   598                                                           alphas, _, self.coef_[k] = lars_path(
   599                                                               X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   600                                                               copy_Gram=True, alpha_min=alpha, method=self.method,
   601                                                               verbose=max(0, self.verbose - 1), max_iter=max_iter,
   602                                                               eps=self.eps, return_path=False)
   603                                                           self.alphas_.append(alphas)
   604                                                       if n_targets == 1:
   605                                                           self.alphas_ = self.alphas_[0]
   606         1           44     44.0      0.2          self._set_intercept(X_mean, y_mean, X_std)
   607         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lassolars-madelon">
<h2>LassoLars-madelon<a class="headerlink" href="#lassolars-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoLars</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LassoLars</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/LassoLars-madelon-step0-timing.png"><img alt="_images/LassoLars-madelon-step0-timing.png" src="_images/LassoLars-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/LassoLars-madelon-step0-memory.png"><img alt="_images/LassoLars-madelon-step0-memory.png" src="_images/LassoLars-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         5378 function calls in 1.006 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.006    1.006 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.006    1.006 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.006    1.006 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:521(fit)
     1    0.445    0.445    0.607    0.607 /tmp/vb_sklearn/sklearn/linear_model/least_angle.py:29(lars_path)
   722    0.479    0.001    0.479    0.001 {numpy.core._dotblas.dot}
     1    0.003    0.003    0.036    0.036 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     2    0.027    0.014    0.027    0.014 {method 'mean' of 'numpy.ndarray' objects}
   352    0.020    0.000    0.020    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
   357    0.001    0.000    0.007    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   358    0.007    0.000    0.007    0.000 {method 'sum' of 'numpy.ndarray' objects}
     2    0.006    0.003    0.006    0.003 {method 'copy' of 'numpy.ndarray' objects}
  1071    0.005    0.000    0.005    0.000 {sklearn.utils.arrayfuncs.min_pos}
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
   358    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
   358    0.003    0.000    0.003    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
   358    0.002    0.000    0.002    0.000 {min}
     5    0.000    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:3267(delete)
     5    0.000    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:376(setdiff1d)
   393    0.001    0.000    0.001    0.000 {isinstance}
     2    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
   354    0.001    0.000    0.001    0.000 {max}
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     5    0.001    0.000    0.001    0.000 {sklearn.utils.arrayfuncs.cholesky_delete}
     5    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/index_tricks.py:237(__getitem__)
    30    0.001    0.000    0.001    0.000 {numpy.core.multiarray.concatenate}
     5    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:281(in1d)
   386    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    10    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:3525(append)
    33    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numerictypes.py:961(find_common_type)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
    17    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
    10    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
    11    0.000    0.000    0.000    0.000 {range}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
    10    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.where}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/index_tricks.py:217(_retval)
     5    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {getattr}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     5    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numerictypes.py:946(_can_coerce_all)
    24    0.000    0.000    0.000    0.000 {len}
    10    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {hasattr}
     5    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/least_angle.py
Function: fit at line 521
Total time: 1.21141 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   521                                               def fit(self, X, y, Xy=None):
   522                                                   """Fit the model using X, y as training data.
   523
   524                                                   parameters
   525                                                   ----------
   526                                                   X : array-like, shape (n_samples, n_features)
   527                                                       Training data.
   528
   529                                                   y : array-like, shape (n_samples,) or (n_samples, n_targets)
   530                                                       Target values.
   531
   532                                                   Xy : array-like, shape (n_samples,) or (n_samples, n_targets), \
   533                                                           optional
   534                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   535                                                       only when the Gram matrix is precomputed.
   536
   537                                                   returns
   538                                                   -------
   539                                                   self : object
   540                                                       returns an instance of self.
   541                                                   """
   542         1         2843   2843.0      0.2          X = array2d(X)
   543         1           19     19.0      0.0          y = np.asarray(y)
   544         1            7      7.0      0.0          n_features = X.shape[1]
   545
   546         1            5      5.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(X, y,
   547         1            3      3.0      0.0                                                          self.fit_intercept,
   548         1            4      4.0      0.0                                                          self.normalize,
   549         1        48516  48516.0      4.0                                                          self.copy_X)
   550
   551         1            7      7.0      0.0          if y.ndim == 1:
   552         1           13     13.0      0.0              y = y[:, np.newaxis]
   553
   554         1            4      4.0      0.0          n_targets = y.shape[1]
   555
   556         1            6      6.0      0.0          alpha = getattr(self, 'alpha', 0.)
   557         1           14     14.0      0.0          if hasattr(self, 'n_nonzero_coefs'):
   558                                                       alpha = 0.  # n_nonzero_coefs parametrization takes priority
   559                                                       max_iter = self.n_nonzero_coefs
   560                                                   else:
   561         1            4      4.0      0.0              max_iter = self.max_iter
   562
   563         1            4      4.0      0.0          precompute = self.precompute
   564         1            7      7.0      0.0          if not hasattr(precompute, '__array__') and (
   565         1            4      4.0      0.0                  precompute is True or
   566         1            6      6.0      0.0                  (precompute == 'auto' and X.shape[0] &gt; X.shape[1]) or
   567                                                           (precompute == 'auto' and y.shape[1] &gt; 1)):
   568         1       436676 436676.0     36.0              Gram = np.dot(X.T, X)
   569                                                   else:
   570                                                       Gram = self._get_gram()
   571
   572         1            9      9.0      0.0          self.alphas_ = []
   573
   574         1            5      5.0      0.0          if self.fit_path:
   575         1            5      5.0      0.0              self.coef_ = []
   576         1            4      4.0      0.0              self.active_ = []
   577         1            5      5.0      0.0              self.coef_path_ = []
   578         2           18      9.0      0.0              for k in xrange(n_targets):
   579         1            4      4.0      0.0                  this_Xy = None if Xy is None else Xy[:, k]
   580         1            4      4.0      0.0                  alphas, active, coef_path = lars_path(
   581         1           19     19.0      0.0                      X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   582         1            4      4.0      0.0                      copy_Gram=True, alpha_min=alpha, method=self.method,
   583         1           10     10.0      0.0                      verbose=max(0, self.verbose - 1), max_iter=max_iter,
   584         1       723080 723080.0     59.7                      eps=self.eps, return_path=True)
   585         1            7      7.0      0.0                  self.alphas_.append(alphas)
   586         1            4      4.0      0.0                  self.active_.append(active)
   587         1            4      4.0      0.0                  self.coef_path_.append(coef_path)
   588         1           11     11.0      0.0                  self.coef_.append(coef_path[:, -1])
   589
   590         1            4      4.0      0.0              if n_targets == 1:
   591                                                           self.alphas_, self.active_, self.coef_path_, self.coef_ = [
   592         1            4      4.0      0.0                      a[0] for a in (self.alphas_, self.active_, self.coef_path_,
   593         5           22      4.4      0.0                                     self.coef_)]
   594                                                   else:
   595                                                       self.coef_ = np.empty((n_targets, n_features))
   596                                                       for k in xrange(n_targets):
   597                                                           this_Xy = None if Xy is None else Xy[:, k]
   598                                                           alphas, _, self.coef_[k] = lars_path(
   599                                                               X, y[:, k], Gram=Gram, Xy=this_Xy, copy_X=self.copy_X,
   600                                                               copy_Gram=True, alpha_min=alpha, method=self.method,
   601                                                               verbose=max(0, self.verbose - 1), max_iter=max_iter,
   602                                                               eps=self.eps, return_path=False)
   603                                                           self.alphas_.append(alphas)
   604                                                       if n_targets == 1:
   605                                                           self.alphas_ = self.alphas_[0]
   606         1           43     43.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   607         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="lasso-minimadelon-oney">
<h2>Lasso-minimadelon-oney<a class="headerlink" href="#lasso-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/Lasso-minimadelon-oney-step0-timing.png"><img alt="_images/Lasso-minimadelon-oney-step0-timing.png" src="_images/Lasso-minimadelon-oney-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/Lasso-minimadelon-oney-step0-memory.png"><img alt="_images/Lasso-minimadelon-oney-step0-memory.png" src="_images/Lasso-minimadelon-oney-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         152 function calls in 0.005 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.005    0.005 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:565(fit)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:232(enet_path)
     1    0.003    0.003    0.003    0.003 {sklearn.linear_model.cd_fast.enet_coordinate_descent}
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:128(atleast2d_or_csc)
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     4    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:388(_pre_fit)
     5    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     8    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/linalg/linalg.py:1840(norm)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:490(sort)
    22    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     2    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     2    0.000    0.000    0.000    0.000 {abs}
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    15    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {map}
     6    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     3    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     7    0.000    0.000    0.000    0.000 {len}
     2    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 565
Total time: 0.004419 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   565                                               def fit(self, X, y, Xy=None, coef_init=None):
   566                                                   """Fit model with coordinate descent.
   567
   568                                                   Parameters
   569                                                   -----------
   570                                                   X : ndarray or scipy.sparse matrix, (n_samples, n_features)
   571                                                       Data
   572
   573                                                   y : ndarray, shape = (n_samples,) or (n_samples, n_targets)
   574                                                       Target
   575
   576                                                   Xy : array-like, optional
   577                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   578                                                       only when the Gram matrix is precomputed.
   579                                                       WARNING : ignored and will be deprecated in 0.15
   580
   581                                                   coef_init : ndarray of shape n_features or (n_targets, n_features)
   582                                                       The initial coeffients to warm-start the optimization
   583                                                       WARNING : ignored and will be deprecated in 0.15
   584
   585                                                   Notes
   586                                                   -----
   587
   588                                                   Coordinate descent is an algorithm that considers each column of
   589                                                   data at a time hence it will automatically convert the X input
   590                                                   as a Fortran-contiguous numpy array if necessary.
   591
   592                                                   To avoid memory re-allocation it is advised to allocate the
   593                                                   initial data in memory directly using that format.
   594                                                   """
   595         1            5      5.0      0.1          if Xy is not None:
   596                                                       warnings.warn("Xy param is now ignored and will be removed in "
   597                                                                     "0.15. See enet_path function.",
   598                                                                     DeprecationWarning, stacklevel=2)
   599
   600         1            4      4.0      0.1          if coef_init is not None:
   601                                                       warnings.warn("coef_init is now ignored and will be removed in "
   602                                                                     "0.15. See enet_path function.",
   603                                                                     DeprecationWarning, stacklevel=2)
   604
   605         1            4      4.0      0.1          if self.alpha == 0:
   606                                                       warnings.warn("With alpha=0, this algorithm does not converge "
   607                                                                     "well. You are advised to use the LinearRegression "
   608                                                                     "estimator", stacklevel=2)
   609         1            4      4.0      0.1          X = atleast2d_or_csc(X, dtype=np.float64, order='F',
   610         1          404    404.0      9.1                               copy=self.copy_X and self.fit_intercept)
   611                                                   # From now on X can be touched inplace
   612         1           12     12.0      0.3          y = np.asarray(y, dtype=np.float64)
   613
   614                                                   X, y, X_mean, y_mean, X_std, precompute, Xy = \
   615         1            4      4.0      0.1              _pre_fit(X, y, Xy, self.precompute, self.normalize,
   616         1          354    354.0      8.0                       self.fit_intercept, copy=True)
   617
   618         1            4      4.0      0.1          if y.ndim == 1:
   619         1            9      9.0      0.2              y = y[:, np.newaxis]
   620         1            3      3.0      0.1          if Xy is not None and Xy.ndim == 1:
   621                                                       Xy = Xy[:, np.newaxis]
   622
   623         1            3      3.0      0.1          n_samples, n_features = X.shape
   624         1            4      4.0      0.1          n_targets = y.shape[1]
   625
   626         1           11     11.0      0.2          coef_ = np.zeros((n_targets, n_features), dtype=np.float64)
   627         1            9      9.0      0.2          dual_gaps_ = np.zeros(n_targets, dtype=np.float64)
   628
   629         2            9      4.5      0.2          for k in xrange(n_targets):
   630         1            3      3.0      0.1              if Xy is not None:
   631                                                           this_Xy = Xy[:, k]
   632                                                       else:
   633         1            3      3.0      0.1                  this_Xy = None
   634                                                       _, this_coef, this_dual_gap = \
   635         1            7      7.0      0.2                  self.path(X, y[:, k],
   636         1            4      4.0      0.1                            l1_ratio=self.l1_ratio, eps=None,
   637         1            4      4.0      0.1                            n_alphas=None, alphas=[self.alpha],
   638         1            3      3.0      0.1                            precompute=precompute, Xy=this_Xy,
   639         1            4      4.0      0.1                            fit_intercept=False, normalize=False, copy_X=True,
   640         1            4      4.0      0.1                            verbose=False, tol=self.tol, positive=self.positive,
   641         1         3459   3459.0     78.3                            return_models=False, X_mean=X_mean, X_std=X_std)
   642         1           11     11.0      0.2              coef_[k] = this_coef[:, 0]
   643         1            5      5.0      0.1              dual_gaps_[k] = this_dual_gap[0]
   644
   645         1           28     28.0      0.6          self.coef_, self.dual_gap_ = map(np.squeeze, [coef_, dual_gaps_])
   646         1           38     38.0      0.9          self._set_intercept(X_mean, y_mean, X_std)
   647
   648                                                   # return self for chaining fit and predict calls
   649         1            3      3.0      0.1          return self</pre>
</div>
</div>
</div>
<div class="section" id="lasso-madelon">
<h2>Lasso-madelon<a class="headerlink" href="#lasso-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;normalize&#39;</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span> <span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/Lasso-madelon-step0-timing.png"><img alt="_images/Lasso-madelon-step0-timing.png" src="_images/Lasso-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/Lasso-madelon-step0-memory.png"><img alt="_images/Lasso-madelon-step0-memory.png" src="_images/Lasso-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         170 function calls in 3.222 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    3.222    3.222 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    3.222    3.222 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    3.222    3.222 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:565(fit)
     1    0.000    0.000    2.813    2.813 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:232(enet_path)
     1    2.786    2.786    2.786    2.786 {sklearn.linear_model.cd_fast.enet_coordinate_descent}
     2    0.000    0.000    0.363    0.181 /tmp/vb_sklearn/sklearn/linear_model/base.py:388(_pre_fit)
     3    0.353    0.118    0.353    0.118 {numpy.core._dotblas.dot}
     2    0.000    0.000    0.073    0.037 /tmp/vb_sklearn/sklearn/utils/validation.py:128(atleast2d_or_csc)
     2    0.000    0.000    0.073    0.037 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     4    0.000    0.000    0.058    0.015 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     5    0.058    0.012    0.058    0.012 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.046    0.023 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
    10    0.015    0.001    0.015    0.001 {numpy.core.multiarray.array}
     5    0.000    0.000    0.015    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.004    0.002    0.010    0.005 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     2    0.003    0.001    0.003    0.001 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.002    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     2    0.002    0.001    0.002    0.001 {method 'copy' of 'numpy.ndarray' objects}
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1862(allclose)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/linalg/linalg.py:1840(norm)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    22    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1508(any)
     4    0.000    0.000    0.000    0.000 {abs}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:490(sort)
     5    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     4    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
    15    0.000    0.000    0.000    0.000 {isinstance}
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {map}
     2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1579(all)
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
     7    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     3    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 565
Total time: 3.31217 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   565                                               def fit(self, X, y, Xy=None, coef_init=None):
   566                                                   """Fit model with coordinate descent.
   567
   568                                                   Parameters
   569                                                   -----------
   570                                                   X : ndarray or scipy.sparse matrix, (n_samples, n_features)
   571                                                       Data
   572
   573                                                   y : ndarray, shape = (n_samples,) or (n_samples, n_targets)
   574                                                       Target
   575
   576                                                   Xy : array-like, optional
   577                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   578                                                       only when the Gram matrix is precomputed.
   579                                                       WARNING : ignored and will be deprecated in 0.15
   580
   581                                                   coef_init : ndarray of shape n_features or (n_targets, n_features)
   582                                                       The initial coeffients to warm-start the optimization
   583                                                       WARNING : ignored and will be deprecated in 0.15
   584
   585                                                   Notes
   586                                                   -----
   587
   588                                                   Coordinate descent is an algorithm that considers each column of
   589                                                   data at a time hence it will automatically convert the X input
   590                                                   as a Fortran-contiguous numpy array if necessary.
   591
   592                                                   To avoid memory re-allocation it is advised to allocate the
   593                                                   initial data in memory directly using that format.
   594                                                   """
   595         1            6      6.0      0.0          if Xy is not None:
   596                                                       warnings.warn("Xy param is now ignored and will be removed in "
   597                                                                     "0.15. See enet_path function.",
   598                                                                     DeprecationWarning, stacklevel=2)
   599
   600         1            3      3.0      0.0          if coef_init is not None:
   601                                                       warnings.warn("coef_init is now ignored and will be removed in "
   602                                                                     "0.15. See enet_path function.",
   603                                                                     DeprecationWarning, stacklevel=2)
   604
   605         1            5      5.0      0.0          if self.alpha == 0:
   606                                                       warnings.warn("With alpha=0, this algorithm does not converge "
   607                                                                     "well. You are advised to use the LinearRegression "
   608                                                                     "estimator", stacklevel=2)
   609         1            5      5.0      0.0          X = atleast2d_or_csc(X, dtype=np.float64, order='F',
   610         1        37782  37782.0      1.1                               copy=self.copy_X and self.fit_intercept)
   611                                                   # From now on X can be touched inplace
   612         1           35     35.0      0.0          y = np.asarray(y, dtype=np.float64)
   613
   614                                                   X, y, X_mean, y_mean, X_std, precompute, Xy = \
   615         1            5      5.0      0.0              _pre_fit(X, y, Xy, self.precompute, self.normalize,
   616         1       431224 431224.0     13.0                       self.fit_intercept, copy=True)
   617
   618         1            7      7.0      0.0          if y.ndim == 1:
   619         1           21     21.0      0.0              y = y[:, np.newaxis]
   620         1            4      4.0      0.0          if Xy is not None and Xy.ndim == 1:
   621         1            8      8.0      0.0              Xy = Xy[:, np.newaxis]
   622
   623         1            5      5.0      0.0          n_samples, n_features = X.shape
   624         1            5      5.0      0.0          n_targets = y.shape[1]
   625
   626         1           20     20.0      0.0          coef_ = np.zeros((n_targets, n_features), dtype=np.float64)
   627         1           15     15.0      0.0          dual_gaps_ = np.zeros(n_targets, dtype=np.float64)
   628
   629         2           13      6.5      0.0          for k in xrange(n_targets):
   630         1            4      4.0      0.0              if Xy is not None:
   631         1            8      8.0      0.0                  this_Xy = Xy[:, k]
   632                                                       else:
   633                                                           this_Xy = None
   634                                                       _, this_coef, this_dual_gap = \
   635         1            8      8.0      0.0                  self.path(X, y[:, k],
   636         1            4      4.0      0.0                            l1_ratio=self.l1_ratio, eps=None,
   637         1            5      5.0      0.0                            n_alphas=None, alphas=[self.alpha],
   638         1            4      4.0      0.0                            precompute=precompute, Xy=this_Xy,
   639         1            4      4.0      0.0                            fit_intercept=False, normalize=False, copy_X=True,
   640         1            4      4.0      0.0                            verbose=False, tol=self.tol, positive=self.positive,
   641         1      2842872 2842872.0     85.8                            return_models=False, X_mean=X_mean, X_std=X_std)
   642         1           14     14.0      0.0              coef_[k] = this_coef[:, 0]
   643         1            6      6.0      0.0              dual_gaps_[k] = this_dual_gap[0]
   644
   645         1           26     26.0      0.0          self.coef_, self.dual_gap_ = map(np.squeeze, [coef_, dual_gaps_])
   646         1           48     48.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   647
   648                                                   # return self for chaining fit and predict calls
   649         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="elasticnet-minimadelon-oney">
<h2>ElasticNet-minimadelon-oney<a class="headerlink" href="#elasticnet-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s">&#39;rho&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ElasticNet</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/ElasticNet-minimadelon-oney-step0-timing.png"><img alt="_images/ElasticNet-minimadelon-oney-step0-timing.png" src="_images/ElasticNet-minimadelon-oney-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/ElasticNet-minimadelon-oney-step0-memory.png"><img alt="_images/ElasticNet-minimadelon-oney-step0-memory.png" src="_images/ElasticNet-minimadelon-oney-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         152 function calls in 0.026 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.026    0.026 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.026    0.026 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.026    0.026 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:565(fit)
     1    0.000    0.000    0.025    0.025 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:232(enet_path)
     1    0.024    0.024    0.024    0.024 {sklearn.linear_model.cd_fast.enet_coordinate_descent}
     2    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:128(atleast2d_or_csc)
     2    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     4    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:388(_pre_fit)
     5    0.001    0.000    0.001    0.000 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     8    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/linalg/linalg.py:1840(norm)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:490(sort)
    22    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     2    0.000    0.000    0.000    0.000 {abs}
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {map}
    15    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
     2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     2    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     7    0.000    0.000    0.000    0.000 {len}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 146
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   146                                               def predict(self, X):
   147                                                   """Predict using the linear model
   148
   149                                                   Parameters
   150                                                   ----------
   151                                                   X : {array-like, sparse matrix}, shape = (n_samples, n_features)
   152                                                       Samples.
   153
   154                                                   Returns
   155                                                   -------
   156                                                   C : array, shape = (n_samples,)
   157                                                       Returns predicted values.
   158                                                   """
   159                                                   return self.decision_function(X)

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 565
Total time: 0.025678 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   565                                               def fit(self, X, y, Xy=None, coef_init=None):
   566                                                   """Fit model with coordinate descent.
   567
   568                                                   Parameters
   569                                                   -----------
   570                                                   X : ndarray or scipy.sparse matrix, (n_samples, n_features)
   571                                                       Data
   572
   573                                                   y : ndarray, shape = (n_samples,) or (n_samples, n_targets)
   574                                                       Target
   575
   576                                                   Xy : array-like, optional
   577                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   578                                                       only when the Gram matrix is precomputed.
   579                                                       WARNING : ignored and will be deprecated in 0.15
   580
   581                                                   coef_init : ndarray of shape n_features or (n_targets, n_features)
   582                                                       The initial coeffients to warm-start the optimization
   583                                                       WARNING : ignored and will be deprecated in 0.15
   584
   585                                                   Notes
   586                                                   -----
   587
   588                                                   Coordinate descent is an algorithm that considers each column of
   589                                                   data at a time hence it will automatically convert the X input
   590                                                   as a Fortran-contiguous numpy array if necessary.
   591
   592                                                   To avoid memory re-allocation it is advised to allocate the
   593                                                   initial data in memory directly using that format.
   594                                                   """
   595         1            6      6.0      0.0          if Xy is not None:
   596                                                       warnings.warn("Xy param is now ignored and will be removed in "
   597                                                                     "0.15. See enet_path function.",
   598                                                                     DeprecationWarning, stacklevel=2)
   599
   600         1            4      4.0      0.0          if coef_init is not None:
   601                                                       warnings.warn("coef_init is now ignored and will be removed in "
   602                                                                     "0.15. See enet_path function.",
   603                                                                     DeprecationWarning, stacklevel=2)
   604
   605         1            5      5.0      0.0          if self.alpha == 0:
   606                                                       warnings.warn("With alpha=0, this algorithm does not converge "
   607                                                                     "well. You are advised to use the LinearRegression "
   608                                                                     "estimator", stacklevel=2)
   609         1            5      5.0      0.0          X = atleast2d_or_csc(X, dtype=np.float64, order='F',
   610         1          513    513.0      2.0                               copy=self.copy_X and self.fit_intercept)
   611                                                   # From now on X can be touched inplace
   612         1           14     14.0      0.1          y = np.asarray(y, dtype=np.float64)
   613
   614                                                   X, y, X_mean, y_mean, X_std, precompute, Xy = \
   615         1            4      4.0      0.0              _pre_fit(X, y, Xy, self.precompute, self.normalize,
   616         1          421    421.0      1.6                       self.fit_intercept, copy=True)
   617
   618         1            5      5.0      0.0          if y.ndim == 1:
   619         1           10     10.0      0.0              y = y[:, np.newaxis]
   620         1            3      3.0      0.0          if Xy is not None and Xy.ndim == 1:
   621                                                       Xy = Xy[:, np.newaxis]
   622
   623         1            4      4.0      0.0          n_samples, n_features = X.shape
   624         1            4      4.0      0.0          n_targets = y.shape[1]
   625
   626         1           12     12.0      0.0          coef_ = np.zeros((n_targets, n_features), dtype=np.float64)
   627         1           10     10.0      0.0          dual_gaps_ = np.zeros(n_targets, dtype=np.float64)
   628
   629         2           11      5.5      0.0          for k in xrange(n_targets):
   630         1            3      3.0      0.0              if Xy is not None:
   631                                                           this_Xy = Xy[:, k]
   632                                                       else:
   633         1            3      3.0      0.0                  this_Xy = None
   634                                                       _, this_coef, this_dual_gap = \
   635         1            9      9.0      0.0                  self.path(X, y[:, k],
   636         1            4      4.0      0.0                            l1_ratio=self.l1_ratio, eps=None,
   637         1            4      4.0      0.0                            n_alphas=None, alphas=[self.alpha],
   638         1            3      3.0      0.0                            precompute=precompute, Xy=this_Xy,
   639         1            4      4.0      0.0                            fit_intercept=False, normalize=False, copy_X=True,
   640         1            4      4.0      0.0                            verbose=False, tol=self.tol, positive=self.positive,
   641         1        24524  24524.0     95.5                            return_models=False, X_mean=X_mean, X_std=X_std)
   642         1           12     12.0      0.0              coef_[k] = this_coef[:, 0]
   643         1            5      5.0      0.0              dual_gaps_[k] = this_dual_gap[0]
   644
   645         1           26     26.0      0.1          self.coef_, self.dual_gap_ = map(np.squeeze, [coef_, dual_gaps_])
   646         1           42     42.0      0.2          self._set_intercept(X_mean, y_mean, X_std)
   647
   648                                                   # return self for chaining fit and predict calls
   649         1            4      4.0      0.0          return self</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/ElasticNet-minimadelon-oney-step1-timing.png"><img alt="_images/ElasticNet-minimadelon-oney-step1-timing.png" src="_images/ElasticNet-minimadelon-oney-step1-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/ElasticNet-minimadelon-oney-step1-memory.png"><img alt="_images/ElasticNet-minimadelon-oney-step1-memory.png" src="_images/ElasticNet-minimadelon-oney-step1-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         46 function calls in 0.000 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.000    0.000 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:146(predict)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py:656(decision_function)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:129(decision_function)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:50(safe_asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:39(assert_all_finite)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:73(_fast_dot)
     1    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     1    0.000    0.000    0.000    0.000 {_warnings.warn}
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {any}
     5    0.000    0.000    0.000    0.000 {isinstance}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:102(&lt;genexpr&gt;)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     2    0.000    0.000    0.000    0.000 {min}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 146
Total time: 0.000301 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   146                                               def predict(self, X):
   147                                                   """Predict using the linear model
   148
   149                                                   Parameters
   150                                                   ----------
   151                                                   X : {array-like, sparse matrix}, shape = (n_samples, n_features)
   152                                                       Samples.
   153
   154                                                   Returns
   155                                                   -------
   156                                                   C : array, shape = (n_samples,)
   157                                                       Returns predicted values.
   158                                                   """
   159         1          301    301.0    100.0          return self.decision_function(X)

File: /tmp/vb_sklearn/sklearn/linear_model/coordinate_descent.py
Function: fit at line 565
Total time: 0.025678 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   565                                               def fit(self, X, y, Xy=None, coef_init=None):
   566                                                   """Fit model with coordinate descent.
   567
   568                                                   Parameters
   569                                                   -----------
   570                                                   X : ndarray or scipy.sparse matrix, (n_samples, n_features)
   571                                                       Data
   572
   573                                                   y : ndarray, shape = (n_samples,) or (n_samples, n_targets)
   574                                                       Target
   575
   576                                                   Xy : array-like, optional
   577                                                       Xy = np.dot(X.T, y) that can be precomputed. It is useful
   578                                                       only when the Gram matrix is precomputed.
   579                                                       WARNING : ignored and will be deprecated in 0.15
   580
   581                                                   coef_init : ndarray of shape n_features or (n_targets, n_features)
   582                                                       The initial coeffients to warm-start the optimization
   583                                                       WARNING : ignored and will be deprecated in 0.15
   584
   585                                                   Notes
   586                                                   -----
   587
   588                                                   Coordinate descent is an algorithm that considers each column of
   589                                                   data at a time hence it will automatically convert the X input
   590                                                   as a Fortran-contiguous numpy array if necessary.
   591
   592                                                   To avoid memory re-allocation it is advised to allocate the
   593                                                   initial data in memory directly using that format.
   594                                                   """
   595         1            6      6.0      0.0          if Xy is not None:
   596                                                       warnings.warn("Xy param is now ignored and will be removed in "
   597                                                                     "0.15. See enet_path function.",
   598                                                                     DeprecationWarning, stacklevel=2)
   599
   600         1            4      4.0      0.0          if coef_init is not None:
   601                                                       warnings.warn("coef_init is now ignored and will be removed in "
   602                                                                     "0.15. See enet_path function.",
   603                                                                     DeprecationWarning, stacklevel=2)
   604
   605         1            5      5.0      0.0          if self.alpha == 0:
   606                                                       warnings.warn("With alpha=0, this algorithm does not converge "
   607                                                                     "well. You are advised to use the LinearRegression "
   608                                                                     "estimator", stacklevel=2)
   609         1            5      5.0      0.0          X = atleast2d_or_csc(X, dtype=np.float64, order='F',
   610         1          513    513.0      2.0                               copy=self.copy_X and self.fit_intercept)
   611                                                   # From now on X can be touched inplace
   612         1           14     14.0      0.1          y = np.asarray(y, dtype=np.float64)
   613
   614                                                   X, y, X_mean, y_mean, X_std, precompute, Xy = \
   615         1            4      4.0      0.0              _pre_fit(X, y, Xy, self.precompute, self.normalize,
   616         1          421    421.0      1.6                       self.fit_intercept, copy=True)
   617
   618         1            5      5.0      0.0          if y.ndim == 1:
   619         1           10     10.0      0.0              y = y[:, np.newaxis]
   620         1            3      3.0      0.0          if Xy is not None and Xy.ndim == 1:
   621                                                       Xy = Xy[:, np.newaxis]
   622
   623         1            4      4.0      0.0          n_samples, n_features = X.shape
   624         1            4      4.0      0.0          n_targets = y.shape[1]
   625
   626         1           12     12.0      0.0          coef_ = np.zeros((n_targets, n_features), dtype=np.float64)
   627         1           10     10.0      0.0          dual_gaps_ = np.zeros(n_targets, dtype=np.float64)
   628
   629         2           11      5.5      0.0          for k in xrange(n_targets):
   630         1            3      3.0      0.0              if Xy is not None:
   631                                                           this_Xy = Xy[:, k]
   632                                                       else:
   633         1            3      3.0      0.0                  this_Xy = None
   634                                                       _, this_coef, this_dual_gap = \
   635         1            9      9.0      0.0                  self.path(X, y[:, k],
   636         1            4      4.0      0.0                            l1_ratio=self.l1_ratio, eps=None,
   637         1            4      4.0      0.0                            n_alphas=None, alphas=[self.alpha],
   638         1            3      3.0      0.0                            precompute=precompute, Xy=this_Xy,
   639         1            4      4.0      0.0                            fit_intercept=False, normalize=False, copy_X=True,
   640         1            4      4.0      0.0                            verbose=False, tol=self.tol, positive=self.positive,
   641         1        24524  24524.0     95.5                            return_models=False, X_mean=X_mean, X_std=X_std)
   642         1           12     12.0      0.0              coef_[k] = this_coef[:, 0]
   643         1            5      5.0      0.0              dual_gaps_[k] = this_dual_gap[0]
   644
   645         1           26     26.0      0.1          self.coef_, self.dual_gap_ = map(np.squeeze, [coef_, dual_gaps_])
   646         1           42     42.0      0.2          self._set_intercept(X_mean, y_mean, X_std)
   647
   648                                                   # return self for chaining fit and predict calls
   649         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="orthogonalmatchingpursuit-minimadelon">
<h2>OrthogonalMatchingPursuit-minimadelon<a class="headerlink" href="#orthogonalmatchingpursuit-minimadelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">OrthogonalMatchingPursuit</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;n_nonzero_coefs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">OrthogonalMatchingPursuit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/OrthogonalMatchingPursuit-minimadelon-step0-timing.png"><img alt="_images/OrthogonalMatchingPursuit-minimadelon-step0-timing.png" src="_images/OrthogonalMatchingPursuit-minimadelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/OrthogonalMatchingPursuit-minimadelon-step0-memory.png"><img alt="_images/OrthogonalMatchingPursuit-minimadelon-step0-memory.png" src="_images/OrthogonalMatchingPursuit-minimadelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         978 function calls in 0.025 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.025    0.025 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.025    0.025 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.025    0.025 /tmp/vb_sklearn/sklearn/linear_model/omp.py:567(fit)
     1    0.000    0.000    0.024    0.024 /tmp/vb_sklearn/sklearn/linear_model/omp.py:239(orthogonal_mp)
    10    0.016    0.002    0.023    0.002 /tmp/vb_sklearn/sklearn/linear_model/omp.py:26(_cholesky_omp)
   301    0.005    0.000    0.005    0.000 {numpy.core._dotblas.dot}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:388(_pre_fit)
     1    0.001    0.001    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
   100    0.001    0.000    0.001    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
    90    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
    11    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
    20    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    40    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    10    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
    30    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    30    0.000    0.000    0.000    0.000 {getattr}
    18    0.000    0.000    0.000    0.000 {isinstance}
    11    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    20    0.000    0.000    0.000    0.000 {issubclass}
    42    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    10    0.000    0.000    0.000    0.000 {max}
    10    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    16    0.000    0.000    0.000    0.000 {len}
     3    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/omp.py
Function: fit at line 567
Total time: 0.029841 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   567                                               def fit(self, X, y, Gram=None, Xy=None):
   568                                                   """Fit the model using X, y as training data.
   569
   570                                                   Parameters
   571                                                   ----------
   572                                                   X : array-like, shape (n_samples, n_features)
   573                                                       Training data.
   574
   575                                                   y : array-like, shape (n_samples,) or (n_samples, n_targets)
   576                                                       Target values.
   577
   578                                                   Gram : array-like, shape (n_features, n_features) (optional)
   579                                                       Gram matrix of the input data: X.T * X
   580                                                       WARNING : will be deprecated in 0.15
   581
   582                                                   Xy : array-like, shape (n_features,) or (n_features, n_targets)
   583                                                       (optional)
   584                                                       Input targets multiplied by X: X.T * y
   585                                                       WARNING : will be deprecated in 0.15
   586
   587
   588                                                   Returns
   589                                                   -------
   590                                                   self: object
   591                                                       returns an instance of self.
   592                                                   """
   593         1          160    160.0      0.5          X = array2d(X)
   594         1           13     13.0      0.0          y = np.asarray(y)
   595         1            5      5.0      0.0          n_features = X.shape[1]
   596
   597         1            4      4.0      0.0          if self.precompute_gram is not None:
   598                                                       warnings.warn("precompute_gram will be removed in 0.15."
   599                                                                     " Use the precompute parameter.",
   600                                                                     DeprecationWarning, stacklevel=2)
   601                                                       precompute = self.precompute_gram
   602                                                   else:
   603         1            4      4.0      0.0              precompute = self.precompute
   604
   605         1            3      3.0      0.0          if self.copy_Gram is not None:
   606                                                       warnings.warn("copy_Gram will be removed in 0.15."
   607                                                                     " Use the orthogonal_mp function for"
   608                                                                     " low level memory control.",
   609                                                                     DeprecationWarning, stacklevel=2)
   610                                                       copy_Gram = self.copy_Gram
   611                                                   else:
   612         1            4      4.0      0.0              copy_Gram = True
   613
   614         1            3      3.0      0.0          if self.copy_Xy is not None:
   615                                                       warnings.warn("copy_Xy will be removed in 0.15."
   616                                                                     " Use the orthogonal_mp function for"
   617                                                                     " low level memory control.",
   618                                                                     DeprecationWarning, stacklevel=2)
   619                                                       copy_Xy = self.copy_Xy
   620                                                   else:
   621         1            4      4.0      0.0              copy_Xy = True
   622
   623         1            4      4.0      0.0          if self.copy_X is not None:
   624                                                       warnings.warn("copy_X will be removed in 0.15."
   625                                                                     " Use the orthogonal_mp function for"
   626                                                                     " low level memory control.",
   627                                                                     DeprecationWarning, stacklevel=2)
   628                                                       copy_X = self.copy_X
   629                                                   else:
   630         1            3      3.0      0.0              copy_X = True
   631
   632         1            4      4.0      0.0          if Gram is not None:
   633                                                       warnings.warn("Gram will be removed in 0.15."
   634                                                                     " Use the orthogonal_mp function for"
   635                                                                     " low level memory control.",
   636                                                                     DeprecationWarning, stacklevel=2)
   637
   638         1            4      4.0      0.0          if Xy is not None:
   639                                                       warnings.warn("Xy will be removed in 0.15."
   640                                                                     " Use the orthogonal_mp function for"
   641                                                                     " low level memory control.",
   642                                                                     DeprecationWarning, stacklevel=2)
   643
   644         1            4      4.0      0.0          if (Gram is not None or Xy is not None) and (self.fit_intercept
   645                                                                                                or self.normalize):
   646                                                       warnings.warn('Mean subtraction (fit_intercept) and normalization '
   647                                                                     'cannot be applied on precomputed Gram and Xy '
   648                                                                     'matrices. Your precomputed values are ignored and '
   649                                                                     'recomputed. To avoid this, do the scaling yourself '
   650                                                                     'and call with fit_intercept and normalize set to '
   651                                                                     'False.', RuntimeWarning, stacklevel=2)
   652                                                       Gram, Xy = None, None
   653
   654         1            4      4.0      0.0          if Gram is not None:
   655                                                       precompute = Gram
   656                                                       if Xy is not None and copy_Xy:
   657                                                           Xy = Xy.copy()
   658
   659                                                   X, y, X_mean, y_mean, X_std, Gram, Xy = \
   660         1            4      4.0      0.0              _pre_fit(X, y, Xy, precompute, self.normalize, self.fit_intercept,
   661         1          903    903.0      3.0                       copy=copy_X)
   662
   663         1            6      6.0      0.0          if y.ndim == 1:
   664                                                       y = y[:, np.newaxis]
   665
   666         1            4      4.0      0.0          if self.n_nonzero_coefs is None and self.tol is None:
   667                                                       # default for n_nonzero_coefs is 0.1 * n_features
   668                                                       # but at least one.
   669                                                       self.n_nonzero_coefs_ = max(int(0.1 * n_features), 1)
   670                                                   else:
   671         1            5      5.0      0.0              self.n_nonzero_coefs_ = self.n_nonzero_coefs
   672
   673         1            4      4.0      0.0          if Gram is False:
   674         1            5      5.0      0.0              self.coef_ = orthogonal_mp(X, y, self.n_nonzero_coefs_, self.tol,
   675         1        28563  28563.0     95.7                                         precompute=False, copy_X=copy_X).T
   676                                                   else:
   677                                                       norms_sq = np.sum(y ** 2, axis=0) if self.tol is not None else None
   678                                                       self.coef_ = orthogonal_mp_gram(Gram, Xy, self.n_nonzero_coefs_,
   679                                                                                       self.tol, norms_sq,
   680                                                                                       copy_Gram, True).T
   681
   682         1          120    120.0      0.4          self._set_intercept(X_mean, y_mean, X_std)
   683         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="orthogonalmatchingpursuit-madelon">
<h2>OrthogonalMatchingPursuit-madelon<a class="headerlink" href="#orthogonalmatchingpursuit-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">OrthogonalMatchingPursuit</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;n_nonzero_coefs&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">OrthogonalMatchingPursuit</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/OrthogonalMatchingPursuit-madelon-step0-timing.png"><img alt="_images/OrthogonalMatchingPursuit-madelon-step0-timing.png" src="_images/OrthogonalMatchingPursuit-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/OrthogonalMatchingPursuit-madelon-step0-memory.png"><img alt="_images/OrthogonalMatchingPursuit-madelon-step0-memory.png" src="_images/OrthogonalMatchingPursuit-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         154 function calls in 0.507 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.507    0.507 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.507    0.507 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.507    0.507 /tmp/vb_sklearn/sklearn/linear_model/omp.py:567(fit)
     1    0.000    0.000    0.496    0.496 /tmp/vb_sklearn/sklearn/linear_model/base.py:388(_pre_fit)
    13    0.441    0.034    0.441    0.034 {numpy.core._dotblas.dot}
     1    0.017    0.017    0.055    0.055 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     3    0.022    0.007    0.022    0.007 {method 'sum' of 'numpy.ndarray' objects}
     2    0.017    0.009    0.017    0.009 {method 'mean' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.017    0.017 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.010    0.010 /tmp/vb_sklearn/sklearn/linear_model/omp.py:368(orthogonal_mp_gram)
     2    0.000    0.000    0.008    0.004 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     2    0.000    0.000    0.005    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     3    0.004    0.001    0.004    0.001 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.004    0.004 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     1    0.002    0.002    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/omp.py:125(_gram_omp)
     4    0.000    0.000    0.003    0.001 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     6    0.003    0.000    0.003    0.000 {numpy.core.multiarray.array}
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:683(argmax)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/blas.py:30(get_blas_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    10    0.000    0.000    0.000    0.000 {method 'argmax' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     9    0.000    0.000    0.000    0.000 {sklearn.utils.arrayfuncs.solve_triangular}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
     9    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
    12    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     3    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.arange}
     3    0.000    0.000    0.000    0.000 {hasattr}
     4    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:871(squeeze)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    10    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     2    0.000    0.000    0.000    0.000 {range}
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/omp.py
Function: fit at line 567
Total time: 0.551207 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   567                                               def fit(self, X, y, Gram=None, Xy=None):
   568                                                   """Fit the model using X, y as training data.
   569
   570                                                   Parameters
   571                                                   ----------
   572                                                   X : array-like, shape (n_samples, n_features)
   573                                                       Training data.
   574
   575                                                   y : array-like, shape (n_samples,) or (n_samples, n_targets)
   576                                                       Target values.
   577
   578                                                   Gram : array-like, shape (n_features, n_features) (optional)
   579                                                       Gram matrix of the input data: X.T * X
   580                                                       WARNING : will be deprecated in 0.15
   581
   582                                                   Xy : array-like, shape (n_features,) or (n_features, n_targets)
   583                                                       (optional)
   584                                                       Input targets multiplied by X: X.T * y
   585                                                       WARNING : will be deprecated in 0.15
   586
   587
   588                                                   Returns
   589                                                   -------
   590                                                   self: object
   591                                                       returns an instance of self.
   592                                                   """
   593         1         2802   2802.0      0.5          X = array2d(X)
   594         1           18     18.0      0.0          y = np.asarray(y)
   595         1            7      7.0      0.0          n_features = X.shape[1]
   596
   597         1            4      4.0      0.0          if self.precompute_gram is not None:
   598                                                       warnings.warn("precompute_gram will be removed in 0.15."
   599                                                                     " Use the precompute parameter.",
   600                                                                     DeprecationWarning, stacklevel=2)
   601                                                       precompute = self.precompute_gram
   602                                                   else:
   603         1            4      4.0      0.0              precompute = self.precompute
   604
   605         1            4      4.0      0.0          if self.copy_Gram is not None:
   606                                                       warnings.warn("copy_Gram will be removed in 0.15."
   607                                                                     " Use the orthogonal_mp function for"
   608                                                                     " low level memory control.",
   609                                                                     DeprecationWarning, stacklevel=2)
   610                                                       copy_Gram = self.copy_Gram
   611                                                   else:
   612         1            4      4.0      0.0              copy_Gram = True
   613
   614         1            4      4.0      0.0          if self.copy_Xy is not None:
   615                                                       warnings.warn("copy_Xy will be removed in 0.15."
   616                                                                     " Use the orthogonal_mp function for"
   617                                                                     " low level memory control.",
   618                                                                     DeprecationWarning, stacklevel=2)
   619                                                       copy_Xy = self.copy_Xy
   620                                                   else:
   621         1            4      4.0      0.0              copy_Xy = True
   622
   623         1            3      3.0      0.0          if self.copy_X is not None:
   624                                                       warnings.warn("copy_X will be removed in 0.15."
   625                                                                     " Use the orthogonal_mp function for"
   626                                                                     " low level memory control.",
   627                                                                     DeprecationWarning, stacklevel=2)
   628                                                       copy_X = self.copy_X
   629                                                   else:
   630         1            4      4.0      0.0              copy_X = True
   631
   632         1            4      4.0      0.0          if Gram is not None:
   633                                                       warnings.warn("Gram will be removed in 0.15."
   634                                                                     " Use the orthogonal_mp function for"
   635                                                                     " low level memory control.",
   636                                                                     DeprecationWarning, stacklevel=2)
   637
   638         1            4      4.0      0.0          if Xy is not None:
   639                                                       warnings.warn("Xy will be removed in 0.15."
   640                                                                     " Use the orthogonal_mp function for"
   641                                                                     " low level memory control.",
   642                                                                     DeprecationWarning, stacklevel=2)
   643
   644         1            4      4.0      0.0          if (Gram is not None or Xy is not None) and (self.fit_intercept
   645                                                                                                or self.normalize):
   646                                                       warnings.warn('Mean subtraction (fit_intercept) and normalization '
   647                                                                     'cannot be applied on precomputed Gram and Xy '
   648                                                                     'matrices. Your precomputed values are ignored and '
   649                                                                     'recomputed. To avoid this, do the scaling yourself '
   650                                                                     'and call with fit_intercept and normalize set to '
   651                                                                     'False.', RuntimeWarning, stacklevel=2)
   652                                                       Gram, Xy = None, None
   653
   654         1            4      4.0      0.0          if Gram is not None:
   655                                                       precompute = Gram
   656                                                       if Xy is not None and copy_Xy:
   657                                                           Xy = Xy.copy()
   658
   659                                                   X, y, X_mean, y_mean, X_std, Gram, Xy = \
   660         1            5      5.0      0.0              _pre_fit(X, y, Xy, precompute, self.normalize, self.fit_intercept,
   661         1       540800 540800.0     98.1                       copy=copy_X)
   662
   663         1            8      8.0      0.0          if y.ndim == 1:
   664         1           20     20.0      0.0              y = y[:, np.newaxis]
   665
   666         1            5      5.0      0.0          if self.n_nonzero_coefs is None and self.tol is None:
   667                                                       # default for n_nonzero_coefs is 0.1 * n_features
   668                                                       # but at least one.
   669                                                       self.n_nonzero_coefs_ = max(int(0.1 * n_features), 1)
   670                                                   else:
   671         1            6      6.0      0.0              self.n_nonzero_coefs_ = self.n_nonzero_coefs
   672
   673         1            4      4.0      0.0          if Gram is False:
   674                                                       self.coef_ = orthogonal_mp(X, y, self.n_nonzero_coefs_, self.tol,
   675                                                                                  precompute=False, copy_X=copy_X).T
   676                                                   else:
   677         1            5      5.0      0.0              norms_sq = np.sum(y ** 2, axis=0) if self.tol is not None else None
   678         1            4      4.0      0.0              self.coef_ = orthogonal_mp_gram(Gram, Xy, self.n_nonzero_coefs_,
   679         1            4      4.0      0.0                                              self.tol, norms_sq,
   680         1         7419   7419.0      1.3                                              copy_Gram, True).T
   681
   682         1           49     49.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   683         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="sgdclassifier-madelon">
<h2>SGDClassifier-madelon<a class="headerlink" href="#sgdclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-madelon-step0-timing.png"><img alt="_images/SGDClassifier-madelon-step0-timing.png" src="_images/SGDClassifier-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-madelon-step0-memory.png"><img alt="_images/SGDClassifier-madelon-step0-memory.png" src="_images/SGDClassifier-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         204 function calls in 0.049 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.049    0.049 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.049    0.049 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.049    0.049 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:484(fit)
     1    0.000    0.000    0.049    0.049 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:379(_fit)
     1    0.000    0.000    0.042    0.042 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:332(_partial_fit)
     1    0.000    0.000    0.036    0.036 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:421(_fit_binary)
     1    0.000    0.000    0.036    0.036 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:261(fit_binary)
     1    0.035    0.035    0.035    0.035 {sklearn.linear_model.sgd_fast.plain_sgd}
     2    0.000    0.000    0.011    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     2    0.000    0.000    0.011    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     5    0.000    0.000    0.011    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     5    0.011    0.002    0.011    0.002 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.006    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:313(_check_partial_fit_first_call)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:40(unique_labels)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:80(&lt;genexpr&gt;)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:222(type_of_target)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1508(any)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
    10    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:164(_set_coef)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:243(_prepare_fit_binary)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:228(_make_dataset)
    11    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
    14    0.000    0.000    0.000    0.000 {isinstance}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:100(&lt;genexpr&gt;)
     3    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:111(_init_t)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:17(_unique_multiclass)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:151(is_sequence_of_sequences)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:253(column_or_1d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/class_weight.py:9(compute_class_weight)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/abc.py:128(__instancecheck__)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    12    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:90(_validate_params)
     3    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:151(_validate_sample_weight)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:173(_allocate_parameter_mem)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     3    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/_weakrefset.py:68(__contains__)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:144(_get_penalty_type)
     2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:125(_get_loss_function)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
    16    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {sorted}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:103(&lt;genexpr&gt;)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:113(is_label_indicator_matrix)
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:221(_check_fit_data)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1211(shape)
     4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     3    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {max}
     2    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'dloss' of 'sklearn.linear_model.sgd_fast.Hinge' objects}
     1    0.000    0.000    0.000    0.000 {built-in method from_iterable}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:137(_get_learning_rate_type)
     1    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223                                                   scores = self.decision_function(X)
   224                                                   if len(scores.shape) == 1:
   225                                                       indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228                                                   return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 484
Total time: 0.047757 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   485                                                       class_weight=None, sample_weight=None):
   486                                                   """Fit linear model with Stochastic Gradient Descent.
   487
   488                                                   Parameters
   489                                                   ----------
   490                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   491                                                       Training data
   492
   493                                                   y : numpy array of shape [n_samples]
   494                                                       Target values
   495
   496                                                   coef_init : array, shape = [n_classes,n_features]
   497                                                       The initial coefficients to warm-start the optimization.
   498
   499                                                   intercept_init : array, shape = [n_classes]
   500                                                       The initial intercept to warm-start the optimization.
   501
   502                                                   sample_weight : array-like, shape = [n_samples], optional
   503                                                       Weights applied to individual samples.
   504                                                       If not provided, uniform weights are assumed.
   505
   506                                                   Returns
   507                                                   -------
   508                                                   self : returns an instance of self.
   509                                                   """
   510         1            4      4.0      0.0          return self._fit(X, y, alpha=self.alpha, C=1.0,
   511         1            2      2.0      0.0                           loss=self.loss, learning_rate=self.learning_rate,
   512         1            2      2.0      0.0                           coef_init=coef_init, intercept_init=intercept_init,
   513         1            2      2.0      0.0                           class_weight=class_weight,
   514         1        47747  47747.0    100.0                           sample_weight=sample_weight)</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-madelon-step1-timing.png"><img alt="_images/SGDClassifier-madelon-step1-timing.png" src="_images/SGDClassifier-madelon-step1-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-madelon-step1-memory.png"><img alt="_images/SGDClassifier-madelon-step1-memory.png" src="_images/SGDClassifier-madelon-step1-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         54 function calls in 0.003 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.003    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.003    0.003 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/base.py:210(predict)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/linear_model/base.py:181(decision_function)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.002    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.002    0.001    0.002    0.001 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/extmath.py:73(_fast_dot)
     1    0.001    0.001    0.001    0.001 {numpy.core._dotblas.dot}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 {_warnings.warn}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {any}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:102(&lt;genexpr&gt;)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 {min}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0.002554 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223         1         2490   2490.0     97.5          scores = self.decision_function(X)
   224         1            5      5.0      0.2          if len(scores.shape) == 1:
   225         1           31     31.0      1.2              indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228         1           28     28.0      1.1          return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 484
Total time: 0.047757 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   485                                                       class_weight=None, sample_weight=None):
   486                                                   """Fit linear model with Stochastic Gradient Descent.
   487
   488                                                   Parameters
   489                                                   ----------
   490                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   491                                                       Training data
   492
   493                                                   y : numpy array of shape [n_samples]
   494                                                       Target values
   495
   496                                                   coef_init : array, shape = [n_classes,n_features]
   497                                                       The initial coefficients to warm-start the optimization.
   498
   499                                                   intercept_init : array, shape = [n_classes]
   500                                                       The initial intercept to warm-start the optimization.
   501
   502                                                   sample_weight : array-like, shape = [n_samples], optional
   503                                                       Weights applied to individual samples.
   504                                                       If not provided, uniform weights are assumed.
   505
   506                                                   Returns
   507                                                   -------
   508                                                   self : returns an instance of self.
   509                                                   """
   510         1            4      4.0      0.0          return self._fit(X, y, alpha=self.alpha, C=1.0,
   511         1            2      2.0      0.0                           loss=self.loss, learning_rate=self.learning_rate,
   512         1            2      2.0      0.0                           coef_init=coef_init, intercept_init=intercept_init,
   513         1            2      2.0      0.0                           class_weight=class_weight,
   514         1        47747  47747.0    100.0                           sample_weight=sample_weight)</pre>
</div>
</div>
</div>
<div class="section" id="sgdclassifier-newsgroups">
<h2>SGDClassifier-newsgroups<a class="headerlink" href="#sgdclassifier-newsgroups" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;newsgroups&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-newsgroups-step0-timing.png"><img alt="_images/SGDClassifier-newsgroups-step0-timing.png" src="_images/SGDClassifier-newsgroups-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-newsgroups-step0-memory.png"><img alt="_images/SGDClassifier-newsgroups-step0-memory.png" src="_images/SGDClassifier-newsgroups-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         1528 function calls in 1.882 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.882    1.882 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.882    1.882 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.882    1.882 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:484(fit)
     1    0.000    0.000    1.882    1.882 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:379(_fit)
     1    0.000    0.000    1.740    1.740 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:332(_partial_fit)
     1    0.000    0.000    1.719    1.719 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:434(_fit_multiclass)
     1    0.000    0.000    1.718    1.718 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:455(__call__)
    20    0.000    0.000    1.716    0.086 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:308(dispatch)
    20    0.000    0.000    1.715    0.086 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:133(__init__)
    20    0.001    0.000    1.715    0.086 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:261(fit_binary)
    20    1.655    0.083    1.704    0.085 {sklearn.linear_model.sgd_fast.plain_sgd}
     1    0.000    0.000    0.080    0.080 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:164(_set_coef)
    15    0.074    0.005    0.074    0.005 {numpy.core.multiarray.array}
     1    0.000    0.000    0.074    0.074 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     2    0.000    0.000    0.065    0.033 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     2    0.000    0.000    0.065    0.033 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     1    0.000    0.000    0.055    0.055 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/coo.py:281(tocsr)
   200    0.001    0.000    0.048    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1508(any)
   200    0.047    0.000    0.047    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.040    0.040 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/coo.py:75(coo_tocsr)
     1    0.040    0.040    0.040    0.040 {_coo.coo_tocsr}
     3    0.000    0.000    0.016    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     3    0.016    0.005    0.016    0.005 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.015    0.015 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:173(_allocate_parameter_mem)
     2    0.015    0.007    0.015    0.007 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.014    0.014 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:567(sum_duplicates)
     1    0.000    0.000    0.009    0.009 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:567(csr_sum_duplicates)
     1    0.009    0.009    0.009    0.009 {_csr.csr_sum_duplicates}
    20    0.008    0.000    0.009    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:243(_prepare_fit_binary)
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:613(sort_indices)
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:581(__get_sorted)
     1    0.000    0.000    0.005    0.005 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:85(csr_has_sorted_indices)
     1    0.005    0.005    0.005    0.005 {_csr.csr_has_sorted_indices}
    21    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:443(&lt;genexpr&gt;)
    20    0.001    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:228(_make_dataset)
    20    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:113(delayed)
     3    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     1    0.001    0.001    0.001    0.001 {method 'searchsorted' of 'numpy.ndarray' objects}
    20    0.001    0.000    0.001    0.000 {cPickle.dumps}
     3    0.001    0.000    0.001    0.000 {method 'sort' of 'numpy.ndarray' objects}
    24    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    22    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    24    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/multiclass.py:313(_check_partial_fit_first_call)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/multiclass.py:40(unique_labels)
    22    0.001    0.000    0.001    0.000 {method 'fill' of 'numpy.ndarray' objects}
    20    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.4/lib/python2.7/functools.py:17(update_wrapper)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:20(__init__)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:80(&lt;genexpr&gt;)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:222(type_of_target)
    25    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:101(check_format)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:408(retrieve)
    52    0.000    0.000    0.000    0.000 {isinstance}
    48    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:622(prune)
    21    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:144(_get_penalty_type)
    20    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.4/lib/python2.7/functools.py:39(wraps)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
   106    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:151(_validate_sample_weight)
    43    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:100(&lt;genexpr&gt;)
     3    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
    60    0.000    0.000    0.000    0.000 {setattr}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:17(_unique_multiclass)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:18(upcast)
    76    0.000    0.000    0.000    0.000 {len}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/abc.py:128(__instancecheck__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:151(is_sequence_of_sequences)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:111(_init_t)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/coo.py:194(getnnz)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:253(column_or_1d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/class_weight.py:9(compute_class_weight)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:90(_validate_params)
    21    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:103(&lt;genexpr&gt;)
    20    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
    41    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/_weakrefset.py:68(__contains__)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    20    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:61(_verbosity_filter)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:39(short_format_time)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:96(isshape)
    21    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:137(_get_learning_rate_type)
    21    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/data.py:17(__init__)
    20    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {sorted}
     8    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:85(getnnz)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:50(to_native)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/csr.py:180(_swap)
    20    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:120(delayed_function)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:125(_get_loss_function)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:59(set_shape)
    15    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2116(rank)
    20    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:138(get)
     9    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:81(get_shape)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:23(_squeeze_time)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    10    0.000    0.000    0.000    0.000 {numpy.core.multiarray.can_cast}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/data.py:20(_get_dtype)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:51(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:370(__getattr__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:295(__init__)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py:221(_check_fit_data)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/multiclass.py:113(is_label_indicator_matrix)
     1    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1211(shape)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:54(getdtype)
     1    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.dtype' objects}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {time.time}
     1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/csr.py:129(tocsr)
     1    0.000    0.000    0.000    0.000 {method 'dloss' of 'sklearn.linear_model.sgd_fast.Hinge' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:355(_print)
     1    0.000    0.000    0.000    0.000 {built-in method from_iterable}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     1    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223                                                   scores = self.decision_function(X)
   224                                                   if len(scores.shape) == 1:
   225                                                       indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228                                                   return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 484
Total time: 2.015 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   485                                                       class_weight=None, sample_weight=None):
   486                                                   """Fit linear model with Stochastic Gradient Descent.
   487
   488                                                   Parameters
   489                                                   ----------
   490                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   491                                                       Training data
   492
   493                                                   y : numpy array of shape [n_samples]
   494                                                       Target values
   495
   496                                                   coef_init : array, shape = [n_classes,n_features]
   497                                                       The initial coefficients to warm-start the optimization.
   498
   499                                                   intercept_init : array, shape = [n_classes]
   500                                                       The initial intercept to warm-start the optimization.
   501
   502                                                   sample_weight : array-like, shape = [n_samples], optional
   503                                                       Weights applied to individual samples.
   504                                                       If not provided, uniform weights are assumed.
   505
   506                                                   Returns
   507                                                   -------
   508                                                   self : returns an instance of self.
   509                                                   """
   510         1            5      5.0      0.0          return self._fit(X, y, alpha=self.alpha, C=1.0,
   511         1            3      3.0      0.0                           loss=self.loss, learning_rate=self.learning_rate,
   512         1            2      2.0      0.0                           coef_init=coef_init, intercept_init=intercept_init,
   513         1            2      2.0      0.0                           class_weight=class_weight,
   514         1      2014991 2014991.0    100.0                           sample_weight=sample_weight)</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-newsgroups-step1-timing.png"><img alt="_images/SGDClassifier-newsgroups-step1-timing.png" src="_images/SGDClassifier-newsgroups-step1-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/SGDClassifier-newsgroups-step1-memory.png"><img alt="_images/SGDClassifier-newsgroups-step1-memory.png" src="_images/SGDClassifier-newsgroups-step1-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         187 function calls in 0.147 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.147    0.147 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.147    0.147 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.147    0.147 /tmp/vb_sklearn/sklearn/linear_model/base.py:210(predict)
     1    0.001    0.001    0.146    0.146 /tmp/vb_sklearn/sklearn/linear_model/base.py:181(decision_function)
     1    0.000    0.000    0.112    0.112 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     1    0.000    0.000    0.112    0.112 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:229(__mul__)
     1    0.000    0.000    0.112    0.112 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:263(_mul_multivector)
     1    0.000    0.000    0.111    0.111 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:320(csr_matvecs)
     1    0.111    0.111    0.111    0.111 {_csr.csr_matvecs}
     1    0.000    0.000    0.033    0.033 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     1    0.000    0.000    0.032    0.032 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     1    0.000    0.000    0.029    0.029 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/coo.py:281(tocsr)
     1    0.000    0.000    0.020    0.020 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/coo.py:75(coo_tocsr)
     1    0.020    0.020    0.020    0.020 {_coo.coo_tocsr}
     1    0.000    0.000    0.009    0.009 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:567(sum_duplicates)
     1    0.000    0.000    0.006    0.006 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:567(csr_sum_duplicates)
     1    0.006    0.006    0.006    0.006 {_csr.csr_sum_duplicates}
     1    0.000    0.000    0.003    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:613(sort_indices)
     1    0.000    0.000    0.003    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:581(__get_sorted)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     1    0.000    0.000    0.003    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sparsetools/csr.py:85(csr_has_sorted_indices)
     1    0.003    0.003    0.003    0.003 {_csr.csr_has_sorted_indices}
     1    0.003    0.003    0.003    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.002    0.002    0.002    0.002 {method 'argmax' of 'numpy.ndarray' objects}
     1    0.001    0.001    0.001    0.001 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:20(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:101(check_format)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:18(upcast)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:622(prune)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/coo.py:194(getnnz)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:77(isscalarlike)
     2    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:96(isshape)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    20    0.000    0.000    0.000    0.000 {numpy.core.multiarray.can_cast}
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    27    0.000    0.000    0.000    0.000 {len}
     8    0.000    0.000    0.000    0.000 {isinstance}
    15    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2116(rank)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/data.py:17(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:124(isdense)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:50(to_native)
     8    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/compressed.py:85(getnnz)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1574(isscalar)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:370(__getattr__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:59(set_shape)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:81(get_shape)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:51(__init__)
     5    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/csr.py:180(_swap)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/data.py:20(_get_dtype)
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:54(getdtype)
     1    0.000    0.000    0.000    0.000 {method 'newbyteorder' of 'numpy.dtype' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0.157789 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223         1       156039 156039.0     98.9          scores = self.decision_function(X)
   224         1            6      6.0      0.0          if len(scores.shape) == 1:
   225                                                       indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227         1         1600   1600.0      1.0              indices = scores.argmax(axis=1)
   228         1          144    144.0      0.1          return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/linear_model/stochastic_gradient.py
Function: fit at line 484
Total time: 2.015 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   484                                               def fit(self, X, y, coef_init=None, intercept_init=None,
   485                                                       class_weight=None, sample_weight=None):
   486                                                   """Fit linear model with Stochastic Gradient Descent.
   487
   488                                                   Parameters
   489                                                   ----------
   490                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   491                                                       Training data
   492
   493                                                   y : numpy array of shape [n_samples]
   494                                                       Target values
   495
   496                                                   coef_init : array, shape = [n_classes,n_features]
   497                                                       The initial coefficients to warm-start the optimization.
   498
   499                                                   intercept_init : array, shape = [n_classes]
   500                                                       The initial intercept to warm-start the optimization.
   501
   502                                                   sample_weight : array-like, shape = [n_samples], optional
   503                                                       Weights applied to individual samples.
   504                                                       If not provided, uniform weights are assumed.
   505
   506                                                   Returns
   507                                                   -------
   508                                                   self : returns an instance of self.
   509                                                   """
   510         1            5      5.0      0.0          return self._fit(X, y, alpha=self.alpha, C=1.0,
   511         1            3      3.0      0.0                           loss=self.loss, learning_rate=self.learning_rate,
   512         1            2      2.0      0.0                           coef_init=coef_init, intercept_init=intercept_init,
   513         1            2      2.0      0.0                           class_weight=class_weight,
   514         1      2014991 2014991.0    100.0                           sample_weight=sample_weight)</pre>
</div>
</div>
</div>
<div class="section" id="logisticregression-arcene">
<h2>LogisticRegression-arcene<a class="headerlink" href="#logisticregression-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="mf">100000.0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-arcene-step0-timing.png"><img alt="_images/LogisticRegression-arcene-step0-timing.png" src="_images/LogisticRegression-arcene-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-arcene-step0-memory.png"><img alt="_images/LogisticRegression-arcene-step0-memory.png" src="_images/LogisticRegression-arcene-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         70 function calls in 0.534 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.534    0.534 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.534    0.534 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.534    0.534 /tmp/vb_sklearn/sklearn/svm/base.py:639(fit)
     1    0.528    0.528    0.528    0.528 {sklearn.svm.liblinear.train_wrap}
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.006    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.005    0.003    0.005    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/preprocessing/label.py:87(fit_transform)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:253(column_or_1d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/class_weight.py:9(compute_class_weight)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1643(cumsum)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     1    0.000    0.000    0.000    0.000 {method 'cumsum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:606(_get_solver_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:234(__init__)
     2    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:294(check_random_state)
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     3    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1211(shape)
     1    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
     1    0.000    0.000    0.000    0.000 {sklearn.svm.liblinear.set_verbosity_wrap}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:259(max)
     5    0.000    0.000    0.000    0.000 {len}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:707(classes_)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:711(_get_bias)
     2    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223                                                   scores = self.decision_function(X)
   224                                                   if len(scores.shape) == 1:
   225                                                       indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228                                                   return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 639
Total time: 0.436163 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   639                                               def fit(self, X, y):
   640                                                   """Fit the model according to the given training data.
   641
   642                                                   Parameters
   643                                                   ----------
   644                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   645                                                       Training vector, where n_samples in the number of samples and
   646                                                       n_features is the number of features.
   647
   648                                                   y : array-like, shape = [n_samples]
   649                                                       Target vector relative to X
   650
   651                                                   Returns
   652                                                   -------
   653                                                   self : object
   654                                                       Returns self.
   655                                                   """
   656         1            7      7.0      0.0          self._enc = LabelEncoder()
   657         1          249    249.0      0.1          y = self._enc.fit_transform(y)
   658         1           10     10.0      0.0          if len(self.classes_) &lt; 2:
   659                                                       raise ValueError("The number of classes has to be greater than"
   660                                                                        " one.")
   661
   662         1         5661   5661.0      1.3          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   663
   664         1            6      6.0      0.0          self.class_weight_ = compute_class_weight(self.class_weight,
   665         1           59     59.0      0.0                                                    self.classes_, y)
   666
   667         1            6      6.0      0.0          if X.shape[0] != y.shape[0]:
   668                                                       raise ValueError("X and y have incompatible shapes.\n"
   669                                                                        "X has %s samples, but y has %s." %
   670                                                                        (X.shape[0], y.shape[0]))
   671
   672         1            7      7.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   673
   674         1           14     14.0      0.0          rnd = check_random_state(self.random_state)
   675         1            4      4.0      0.0          if self.verbose:
   676                                                       print('[LibLinear]', end='')
   677
   678                                                   # LibLinear wants targets as doubles, even for classification
   679         1           29     29.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   680         1            5      5.0      0.0          self.raw_coef_ = liblinear.train_wrap(X, y,
   681         1           37     37.0      0.0                                                sp.isspmatrix(X),
   682         1           33     33.0      0.0                                                self._get_solver_type(),
   683         1            8      8.0      0.0                                                self.tol, self._get_bias(),
   684         1            3      3.0      0.0                                                self.C,
   685         1            3      3.0      0.0                                                self.class_weight_,
   686         1       429967 429967.0     98.6                                                rnd.randint(np.iinfo('i').max))
   687                                                   # Regarding rnd.randint(..) in the above signature:
   688                                                   # seed for srand in range [0..INT_MAX); due to limitations in Numpy
   689                                                   # on 32-bit platforms, we can't get to the UINT_MAX limit that
   690                                                   # srand supports
   691
   692         1            3      3.0      0.0          if self.fit_intercept:
   693         1           11     11.0      0.0              self.coef_ = self.raw_coef_[:, :-1]
   694         1           35     35.0      0.0              self.intercept_ = self.intercept_scaling * self.raw_coef_[:, -1]
   695                                                   else:
   696                                                       self.coef_ = self.raw_coef_
   697                                                       self.intercept_ = 0.
   698
   699         1            3      3.0      0.0          if self.multi_class == "crammer_singer" and len(self.classes_) == 2:
   700                                                       self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)
   701                                                       if self.fit_intercept:
   702                                                           intercept = self.intercept_[1] - self.intercept_[0]
   703                                                           self.intercept_ = np.array([intercept])
   704
   705         1            3      3.0      0.0          return self</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-arcene-step1-timing.png"><img alt="_images/LogisticRegression-arcene-step1-timing.png" src="_images/LogisticRegression-arcene-step1-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-arcene-step1-memory.png"><img alt="_images/LogisticRegression-arcene-step1-memory.png" src="_images/LogisticRegression-arcene-step1-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         55 function calls in 0.008 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.008    0.008 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.008    0.008 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.008    0.008 /tmp/vb_sklearn/sklearn/linear_model/base.py:210(predict)
     1    0.000    0.000    0.008    0.008 /tmp/vb_sklearn/sklearn/linear_model/base.py:181(decision_function)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.005    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.005    0.003    0.005    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/extmath.py:73(_fast_dot)
     1    0.002    0.002    0.002    0.002 {numpy.core._dotblas.dot}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 {_warnings.warn}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {any}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:102(&lt;genexpr&gt;)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {min}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:707(classes_)
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0.00474 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223         1         4698   4698.0     99.1          scores = self.decision_function(X)
   224         1            3      3.0      0.1          if len(scores.shape) == 1:
   225         1           23     23.0      0.5              indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228         1           16     16.0      0.3          return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 639
Total time: 0.436163 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   639                                               def fit(self, X, y):
   640                                                   """Fit the model according to the given training data.
   641
   642                                                   Parameters
   643                                                   ----------
   644                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   645                                                       Training vector, where n_samples in the number of samples and
   646                                                       n_features is the number of features.
   647
   648                                                   y : array-like, shape = [n_samples]
   649                                                       Target vector relative to X
   650
   651                                                   Returns
   652                                                   -------
   653                                                   self : object
   654                                                       Returns self.
   655                                                   """
   656         1            7      7.0      0.0          self._enc = LabelEncoder()
   657         1          249    249.0      0.1          y = self._enc.fit_transform(y)
   658         1           10     10.0      0.0          if len(self.classes_) &lt; 2:
   659                                                       raise ValueError("The number of classes has to be greater than"
   660                                                                        " one.")
   661
   662         1         5661   5661.0      1.3          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   663
   664         1            6      6.0      0.0          self.class_weight_ = compute_class_weight(self.class_weight,
   665         1           59     59.0      0.0                                                    self.classes_, y)
   666
   667         1            6      6.0      0.0          if X.shape[0] != y.shape[0]:
   668                                                       raise ValueError("X and y have incompatible shapes.\n"
   669                                                                        "X has %s samples, but y has %s." %
   670                                                                        (X.shape[0], y.shape[0]))
   671
   672         1            7      7.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   673
   674         1           14     14.0      0.0          rnd = check_random_state(self.random_state)
   675         1            4      4.0      0.0          if self.verbose:
   676                                                       print('[LibLinear]', end='')
   677
   678                                                   # LibLinear wants targets as doubles, even for classification
   679         1           29     29.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   680         1            5      5.0      0.0          self.raw_coef_ = liblinear.train_wrap(X, y,
   681         1           37     37.0      0.0                                                sp.isspmatrix(X),
   682         1           33     33.0      0.0                                                self._get_solver_type(),
   683         1            8      8.0      0.0                                                self.tol, self._get_bias(),
   684         1            3      3.0      0.0                                                self.C,
   685         1            3      3.0      0.0                                                self.class_weight_,
   686         1       429967 429967.0     98.6                                                rnd.randint(np.iinfo('i').max))
   687                                                   # Regarding rnd.randint(..) in the above signature:
   688                                                   # seed for srand in range [0..INT_MAX); due to limitations in Numpy
   689                                                   # on 32-bit platforms, we can't get to the UINT_MAX limit that
   690                                                   # srand supports
   691
   692         1            3      3.0      0.0          if self.fit_intercept:
   693         1           11     11.0      0.0              self.coef_ = self.raw_coef_[:, :-1]
   694         1           35     35.0      0.0              self.intercept_ = self.intercept_scaling * self.raw_coef_[:, -1]
   695                                                   else:
   696                                                       self.coef_ = self.raw_coef_
   697                                                       self.intercept_ = 0.
   698
   699         1            3      3.0      0.0          if self.multi_class == "crammer_singer" and len(self.classes_) == 2:
   700                                                       self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)
   701                                                       if self.fit_intercept:
   702                                                           intercept = self.intercept_[1] - self.intercept_[0]
   703                                                           self.intercept_ = np.array([intercept])
   704
   705         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="logisticregression-madelon">
<h2>LogisticRegression-madelon<a class="headerlink" href="#logisticregression-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="mf">100000.0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-madelon-step0-timing.png"><img alt="_images/LogisticRegression-madelon-step0-timing.png" src="_images/LogisticRegression-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-madelon-step0-memory.png"><img alt="_images/LogisticRegression-madelon-step0-memory.png" src="_images/LogisticRegression-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         70 function calls in 10.086 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000   10.086   10.086 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000   10.086   10.086 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000   10.086   10.086 /tmp/vb_sklearn/sklearn/svm/base.py:639(fit)
     1   10.079   10.079   10.079   10.079 {sklearn.svm.liblinear.train_wrap}
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     1    0.000    0.000    0.006    0.006 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.005    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.005    0.003    0.005    0.003 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/preprocessing/label.py:87(fit_transform)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     2    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1643(cumsum)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:253(column_or_1d)
     1    0.000    0.000    0.000    0.000 {method 'cumsum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/class_weight.py:9(compute_class_weight)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:606(_get_solver_type)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:234(__init__)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:294(check_random_state)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {sklearn.svm.liblinear.set_verbosity_wrap}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1211(shape)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:259(max)
     1    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
     5    0.000    0.000    0.000    0.000 {len}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:707(classes_)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:711(_get_bias)
     2    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223                                                   scores = self.decision_function(X)
   224                                                   if len(scores.shape) == 1:
   225                                                       indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228                                                   return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 639
Total time: 10.3532 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   639                                               def fit(self, X, y):
   640                                                   """Fit the model according to the given training data.
   641
   642                                                   Parameters
   643                                                   ----------
   644                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   645                                                       Training vector, where n_samples in the number of samples and
   646                                                       n_features is the number of features.
   647
   648                                                   y : array-like, shape = [n_samples]
   649                                                       Target vector relative to X
   650
   651                                                   Returns
   652                                                   -------
   653                                                   self : object
   654                                                       Returns self.
   655                                                   """
   656         1            7      7.0      0.0          self._enc = LabelEncoder()
   657         1          617    617.0      0.0          y = self._enc.fit_transform(y)
   658         1           10     10.0      0.0          if len(self.classes_) &lt; 2:
   659                                                       raise ValueError("The number of classes has to be greater than"
   660                                                                        " one.")
   661
   662         1         5481   5481.0      0.1          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   663
   664         1            5      5.0      0.0          self.class_weight_ = compute_class_weight(self.class_weight,
   665         1           52     52.0      0.0                                                    self.classes_, y)
   666
   667         1            5      5.0      0.0          if X.shape[0] != y.shape[0]:
   668                                                       raise ValueError("X and y have incompatible shapes.\n"
   669                                                                        "X has %s samples, but y has %s." %
   670                                                                        (X.shape[0], y.shape[0]))
   671
   672         1            6      6.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   673
   674         1           10     10.0      0.0          rnd = check_random_state(self.random_state)
   675         1            4      4.0      0.0          if self.verbose:
   676                                                       print('[LibLinear]', end='')
   677
   678                                                   # LibLinear wants targets as doubles, even for classification
   679         1           45     45.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   680         1            4      4.0      0.0          self.raw_coef_ = liblinear.train_wrap(X, y,
   681         1           34     34.0      0.0                                                sp.isspmatrix(X),
   682         1           32     32.0      0.0                                                self._get_solver_type(),
   683         1            8      8.0      0.0                                                self.tol, self._get_bias(),
   684         1            4      4.0      0.0                                                self.C,
   685         1            4      4.0      0.0                                                self.class_weight_,
   686         1     10346803 10346803.0     99.9                                                rnd.randint(np.iinfo('i').max))
   687                                                   # Regarding rnd.randint(..) in the above signature:
   688                                                   # seed for srand in range [0..INT_MAX); due to limitations in Numpy
   689                                                   # on 32-bit platforms, we can't get to the UINT_MAX limit that
   690                                                   # srand supports
   691
   692         1            6      6.0      0.0          if self.fit_intercept:
   693         1           18     18.0      0.0              self.coef_ = self.raw_coef_[:, :-1]
   694         1           50     50.0      0.0              self.intercept_ = self.intercept_scaling * self.raw_coef_[:, -1]
   695                                                   else:
   696                                                       self.coef_ = self.raw_coef_
   697                                                       self.intercept_ = 0.
   698
   699         1            5      5.0      0.0          if self.multi_class == "crammer_singer" and len(self.classes_) == 2:
   700                                                       self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)
   701                                                       if self.fit_intercept:
   702                                                           intercept = self.intercept_[1] - self.intercept_[0]
   703                                                           self.intercept_ = np.array([intercept])
   704
   705         1            4      4.0      0.0          return self</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_t</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-madelon-step1-timing.png"><img alt="_images/LogisticRegression-madelon-step1-timing.png" src="_images/LogisticRegression-madelon-step1-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/LogisticRegression-madelon-step1-memory.png"><img alt="_images/LogisticRegression-madelon-step1-memory.png" src="_images/LogisticRegression-madelon-step1-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         55 function calls in 0.003 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.003    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.003    0.003 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/base.py:210(predict)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/linear_model/base.py:181(decision_function)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:138(atleast2d_or_csr)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:110(_atleast2d_or_sparse)
     2    0.000    0.000    0.002    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     2    0.002    0.001    0.002    0.001 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:97(array2d)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/extmath.py:146(safe_sparse_dot)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/extmath.py:73(_fast_dot)
     1    0.001    0.001    0.001    0.001 {numpy.core._dotblas.dot}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 {_warnings.warn}
     8    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {any}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/extmath.py:102(&lt;genexpr&gt;)
     1    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 {min}
     4    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/svm/base.py:707(classes_)
     1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/base.py
Function: predict at line 210
Total time: 0.002529 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                               def predict(self, X):
   211                                                   """Predict class labels for samples in X.
   212
   213                                                   Parameters
   214                                                   ----------
   215                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   216                                                       Samples.
   217
   218                                                   Returns
   219                                                   -------
   220                                                   C : array, shape = [n_samples]
   221                                                       Predicted class label per sample.
   222                                                   """
   223         1         2470   2470.0     97.7          scores = self.decision_function(X)
   224         1            4      4.0      0.2          if len(scores.shape) == 1:
   225         1           28     28.0      1.1              indices = (scores &gt; 0).astype(np.int)
   226                                                   else:
   227                                                       indices = scores.argmax(axis=1)
   228         1           27     27.0      1.1          return self.classes_[indices]

File: /tmp/vb_sklearn/sklearn/svm/base.py
Function: fit at line 639
Total time: 10.3532 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   639                                               def fit(self, X, y):
   640                                                   """Fit the model according to the given training data.
   641
   642                                                   Parameters
   643                                                   ----------
   644                                                   X : {array-like, sparse matrix}, shape = [n_samples, n_features]
   645                                                       Training vector, where n_samples in the number of samples and
   646                                                       n_features is the number of features.
   647
   648                                                   y : array-like, shape = [n_samples]
   649                                                       Target vector relative to X
   650
   651                                                   Returns
   652                                                   -------
   653                                                   self : object
   654                                                       Returns self.
   655                                                   """
   656         1            7      7.0      0.0          self._enc = LabelEncoder()
   657         1          617    617.0      0.0          y = self._enc.fit_transform(y)
   658         1           10     10.0      0.0          if len(self.classes_) &lt; 2:
   659                                                       raise ValueError("The number of classes has to be greater than"
   660                                                                        " one.")
   661
   662         1         5481   5481.0      0.1          X = atleast2d_or_csr(X, dtype=np.float64, order="C")
   663
   664         1            5      5.0      0.0          self.class_weight_ = compute_class_weight(self.class_weight,
   665         1           52     52.0      0.0                                                    self.classes_, y)
   666
   667         1            5      5.0      0.0          if X.shape[0] != y.shape[0]:
   668                                                       raise ValueError("X and y have incompatible shapes.\n"
   669                                                                        "X has %s samples, but y has %s." %
   670                                                                        (X.shape[0], y.shape[0]))
   671
   672         1            6      6.0      0.0          liblinear.set_verbosity_wrap(self.verbose)
   673
   674         1           10     10.0      0.0          rnd = check_random_state(self.random_state)
   675         1            4      4.0      0.0          if self.verbose:
   676                                                       print('[LibLinear]', end='')
   677
   678                                                   # LibLinear wants targets as doubles, even for classification
   679         1           45     45.0      0.0          y = np.asarray(y, dtype=np.float64).ravel()
   680         1            4      4.0      0.0          self.raw_coef_ = liblinear.train_wrap(X, y,
   681         1           34     34.0      0.0                                                sp.isspmatrix(X),
   682         1           32     32.0      0.0                                                self._get_solver_type(),
   683         1            8      8.0      0.0                                                self.tol, self._get_bias(),
   684         1            4      4.0      0.0                                                self.C,
   685         1            4      4.0      0.0                                                self.class_weight_,
   686         1     10346803 10346803.0     99.9                                                rnd.randint(np.iinfo('i').max))
   687                                                   # Regarding rnd.randint(..) in the above signature:
   688                                                   # seed for srand in range [0..INT_MAX); due to limitations in Numpy
   689                                                   # on 32-bit platforms, we can't get to the UINT_MAX limit that
   690                                                   # srand supports
   691
   692         1            6      6.0      0.0          if self.fit_intercept:
   693         1           18     18.0      0.0              self.coef_ = self.raw_coef_[:, :-1]
   694         1           50     50.0      0.0              self.intercept_ = self.intercept_scaling * self.raw_coef_[:, -1]
   695                                                   else:
   696                                                       self.coef_ = self.raw_coef_
   697                                                       self.intercept_ = 0.
   698
   699         1            5      5.0      0.0          if self.multi_class == "crammer_singer" and len(self.classes_) == 2:
   700                                                       self.coef_ = (self.coef_[1] - self.coef_[0]).reshape(1, -1)
   701                                                       if self.fit_intercept:
   702                                                           intercept = self.intercept_[1] - self.intercept_[0]
   703                                                           self.intercept_ = np.array([intercept])
   704
   705         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="ardregression-minimadelon-oney">
<h2>ARDRegression-minimadelon-oney<a class="headerlink" href="#ardregression-minimadelon-oney" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ARDRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon-oney&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ARDRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/ARDRegression-minimadelon-oney-step0-timing.png"><img alt="_images/ARDRegression-minimadelon-oney-step0-timing.png" src="_images/ARDRegression-minimadelon-oney-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/ARDRegression-minimadelon-oney-step0-memory.png"><img alt="_images/ARDRegression-minimadelon-oney-step0-memory.png" src="_images/ARDRegression-minimadelon-oney-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         1075 function calls in 0.070 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.070    0.070 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.070    0.070 &lt;f&gt;:1(&lt;module&gt;)
     1    0.028    0.028    0.070    0.070 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:328(fit)
    99    0.022    0.000    0.022    0.000 {numpy.core._dotblas.dot}
    14    0.002    0.000    0.016    0.001 /tmp/vb_sklearn/sklearn/utils/extmath.py:403(pinvh)
    14    0.010    0.001    0.012    0.001 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/decomp.py:196(eigh)
    28    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    42    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    14    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
    56    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}
    27    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    43    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
    58    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/twodim_base.py:220(diag)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:155(check_arrays)
    71    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    28    0.000    0.000    0.000    0.000 {abs}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/twodim_base.py:169(eye)
    42    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:65(zeros_like)
    14    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/type_check.py:235(iscomplexobj)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
    13    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    33    0.000    0.000    0.000    0.000 {isinstance}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    14    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    15    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    17    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
    28    0.000    0.000    0.000    0.000 {getattr}
    14    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty_like}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    36    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    15    0.000    0.000    0.000    0.000 {range}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    42    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
    57    0.000    0.000    0.000    0.000 {len}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:148(_num_samples)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    14    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    14    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
    30    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    14    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     6    0.000    0.000    0.000    0.000 {hasattr}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 328
Total time: 0.068044 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   328                                               def fit(self, X, y):
   329                                                   """Fit the ARDRegression model according to the given training data
   330                                                   and parameters.
   331
   332                                                   Iterative procedure to maximize the evidence
   333
   334                                                   Parameters
   335                                                   ----------
   336                                                   X : array-like, shape = [n_samples, n_features]
   337                                                       Training vector, where n_samples in the number of samples and
   338                                                       n_features is the number of features.
   339                                                   y : array, shape = [n_samples]
   340                                                       Target values (integers)
   341
   342                                                   Returns
   343                                                   -------
   344                                                   self : returns an instance of self.
   345                                                   """
   346         1            5      5.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   347         1          256    256.0      0.4                              dtype=np.float)
   348
   349         1            6      6.0      0.0          n_samples, n_features = X.shape
   350         1           12     12.0      0.0          coef_ = np.zeros(n_features)
   351
   352         1            4      4.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(
   353         1          340    340.0      0.5              X, y, self.fit_intercept, self.normalize, self.copy_X)
   354
   355                                                   ### Launch the convergence loop
   356         1           21     21.0      0.0          keep_lambda = np.ones(n_features, dtype=bool)
   357
   358         1            5      5.0      0.0          lambda_1 = self.lambda_1
   359         1            4      4.0      0.0          lambda_2 = self.lambda_2
   360         1            4      4.0      0.0          alpha_1 = self.alpha_1
   361         1            4      4.0      0.0          alpha_2 = self.alpha_2
   362         1            4      4.0      0.0          verbose = self.verbose
   363
   364                                                   ### Initialization of the values of the parameters
   365         1          115    115.0      0.2          alpha_ = 1. / np.var(y)
   366         1           21     21.0      0.0          lambda_ = np.ones(n_features)
   367
   368         1            7      7.0      0.0          self.scores_ = list()
   369         1            4      4.0      0.0          coef_old_ = None
   370
   371                                                   ### Iterative procedure of ARDRegression
   372        14           73      5.2      0.1          for iter_ in range(self.n_iter):
   373                                                       ### Compute mu and sigma (using Woodbury matrix identity)
   374        14          715     51.1      1.1              sigma_ = pinvh(np.eye(n_samples) / alpha_ +
   375        14         3499    249.9      5.1                             np.dot(X[:, keep_lambda] *
   376        14         1213     86.6      1.8                             np.reshape(1. / lambda_[keep_lambda], [1, -1]),
   377        14        23066   1647.6     33.9                             X[:, keep_lambda].T))
   378        14         3566    254.7      5.2              sigma_ = np.dot(sigma_, X[:, keep_lambda]
   379        14         4056    289.7      6.0                              * np.reshape(1. / lambda_[keep_lambda], [1, -1]))
   380        14          727     51.9      1.1              sigma_ = - np.dot(np.reshape(1. / lambda_[keep_lambda], [-1, 1])
   381        14        18849   1346.4     27.7                                * X[:, keep_lambda].T, sigma_)
   382        14          855     61.1      1.3              sigma_.flat[::(sigma_.shape[1] + 1)] += 1. / lambda_[keep_lambda]
   383        14           76      5.4      0.1              coef_[keep_lambda] = alpha_ * np.dot(
   384        14         5124    366.0      7.5                  sigma_, np.dot(X[:, keep_lambda].T, y))
   385
   386                                                       ### Update alpha and lambda
   387        14         1112     79.4      1.6              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   388        14         1076     76.9      1.6              gamma_ = 1. - lambda_[keep_lambda] * np.diag(sigma_)
   389        14          210     15.0      0.3              lambda_[keep_lambda] = ((gamma_ + 2. * lambda_1)
   390        14          334     23.9      0.5                                      / ((coef_[keep_lambda]) ** 2
   391        14          476     34.0      0.7                                         + 2. * lambda_2))
   392        14          372     26.6      0.5              alpha_ = ((n_samples - gamma_.sum() + 2. * alpha_1)
   393        14          128      9.1      0.2                        / (rmse_ + 2. * alpha_2))
   394
   395                                                       ### Prune the weights with a precision over a threshold
   396        14          250     17.9      0.4              keep_lambda = lambda_ &lt; self.threshold_lambda
   397        14          443     31.6      0.7              coef_[~keep_lambda] = 0
   398
   399                                                       ### Compute the objective function
   400        14           64      4.6      0.1              if self.compute_score:
   401                                                           s = (lambda_1 * np.log(lambda_) - lambda_2 * lambda_).sum()
   402                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   403                                                           s += 0.5 * (fast_logdet(sigma_) + n_samples * log(alpha_)
   404                                                                                           + np.sum(np.log(lambda_)))
   405                                                           s -= 0.5 * (alpha_ * rmse_ + (lambda_ * coef_ ** 2).sum())
   406                                                           self.scores_.append(s)
   407
   408                                                       ### Check for convergence
   409        14          647     46.2      1.0              if iter_ &gt; 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   410         1            4      4.0      0.0                  if verbose:
   411                                                               print("Converged after %s iterations" % iter_)
   412         1            9      9.0      0.0                  break
   413        13          227     17.5      0.3              coef_old_ = np.copy(coef_)
   414
   415         1            7      7.0      0.0          self.coef_ = coef_
   416         1            5      5.0      0.0          self.alpha_ = alpha_
   417         1            4      4.0      0.0          self.sigma_ = sigma_
   418         1            4      4.0      0.0          self.lambda_ = lambda_
   419         1           38     38.0      0.1          self._set_intercept(X_mean, y_mean, X_std)
   420         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="ardregression-blobs">
<h2>ARDRegression-blobs<a class="headerlink" href="#ardregression-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ARDRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ARDRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/ARDRegression-blobs-step0-timing.png"><img alt="_images/ARDRegression-blobs-step0-timing.png" src="_images/ARDRegression-blobs-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/ARDRegression-blobs-step0-memory.png"><img alt="_images/ARDRegression-blobs-step0-memory.png" src="_images/ARDRegression-blobs-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         931 function calls in 1.473 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.473    1.473 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.473    1.473 &lt;f&gt;:1(&lt;module&gt;)
     1    0.070    0.070    1.473    1.473 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:328(fit)
    12    0.009    0.001    1.308    0.109 /tmp/vb_sklearn/sklearn/utils/extmath.py:403(pinvh)
    12    0.975    0.081    1.002    0.084 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/decomp.py:196(eigh)
    85    0.349    0.004    0.349    0.004 {numpy.core._dotblas.dot}
    24    0.056    0.002    0.064    0.003 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
    48    0.008    0.000    0.008    0.000 {method 'any' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/twodim_base.py:169(eye)
    13    0.002    0.000    0.002    0.000 {numpy.core.multiarray.zeros}
    12    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
    23    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    36    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    37    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:155(check_arrays)
    50    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/twodim_base.py:220(diag)
    24    0.000    0.000    0.000    0.000 {abs}
    61    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
    36    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:65(zeros_like)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/type_check.py:235(iscomplexobj)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    29    0.000    0.000    0.000    0.000 {isinstance}
    12    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    24    0.000    0.000    0.000    0.000 {getattr}
    15    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
    32    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    13    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty_like}
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
    36    0.000    0.000    0.000    0.000 {issubclass}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:148(_num_samples)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
    49    0.000    0.000    0.000    0.000 {len}
    26    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    12    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    12    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     6    0.000    0.000    0.000    0.000 {hasattr}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 328
Total time: 1.51951 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   328                                               def fit(self, X, y):
   329                                                   """Fit the ARDRegression model according to the given training data
   330                                                   and parameters.
   331
   332                                                   Iterative procedure to maximize the evidence
   333
   334                                                   Parameters
   335                                                   ----------
   336                                                   X : array-like, shape = [n_samples, n_features]
   337                                                       Training vector, where n_samples in the number of samples and
   338                                                       n_features is the number of features.
   339                                                   y : array, shape = [n_samples]
   340                                                       Target values (integers)
   341
   342                                                   Returns
   343                                                   -------
   344                                                   self : returns an instance of self.
   345                                                   """
   346         1            6      6.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   347         1          295    295.0      0.0                              dtype=np.float)
   348
   349         1            5      5.0      0.0          n_samples, n_features = X.shape
   350         1           12     12.0      0.0          coef_ = np.zeros(n_features)
   351
   352         1            5      5.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(
   353         1          325    325.0      0.0              X, y, self.fit_intercept, self.normalize, self.copy_X)
   354
   355                                                   ### Launch the convergence loop
   356         1           20     20.0      0.0          keep_lambda = np.ones(n_features, dtype=bool)
   357
   358         1            5      5.0      0.0          lambda_1 = self.lambda_1
   359         1            5      5.0      0.0          lambda_2 = self.lambda_2
   360         1            4      4.0      0.0          alpha_1 = self.alpha_1
   361         1            4      4.0      0.0          alpha_2 = self.alpha_2
   362         1            4      4.0      0.0          verbose = self.verbose
   363
   364                                                   ### Initialization of the values of the parameters
   365         1           74     74.0      0.0          alpha_ = 1. / np.var(y)
   366         1           18     18.0      0.0          lambda_ = np.ones(n_features)
   367
   368         1           10     10.0      0.0          self.scores_ = list()
   369         1            4      4.0      0.0          coef_old_ = None
   370
   371                                                   ### Iterative procedure of ARDRegression
   372        12           69      5.8      0.0          for iter_ in range(self.n_iter):
   373                                                       ### Compute mu and sigma (using Woodbury matrix identity)
   374        12        21250   1770.8      1.4              sigma_ = pinvh(np.eye(n_samples) / alpha_ +
   375        12         7883    656.9      0.5                             np.dot(X[:, keep_lambda] *
   376        12         1474    122.8      0.1                             np.reshape(1. / lambda_[keep_lambda], [1, -1]),
   377        12      1400919 116743.2     92.2                             X[:, keep_lambda].T))
   378        12         7993    666.1      0.5              sigma_ = np.dot(sigma_, X[:, keep_lambda]
   379        12        49769   4147.4      3.3                              * np.reshape(1. / lambda_[keep_lambda], [1, -1]))
   380        12          632     52.7      0.0              sigma_ = - np.dot(np.reshape(1. / lambda_[keep_lambda], [-1, 1])
   381        12        15230   1269.2      1.0                                * X[:, keep_lambda].T, sigma_)
   382        12          549     45.8      0.0              sigma_.flat[::(sigma_.shape[1] + 1)] += 1. / lambda_[keep_lambda]
   383        12           62      5.2      0.0              coef_[keep_lambda] = alpha_ * np.dot(
   384        12         8665    722.1      0.6                  sigma_, np.dot(X[:, keep_lambda].T, y))
   385
   386                                                       ### Update alpha and lambda
   387        12         1056     88.0      0.1              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   388        12          821     68.4      0.1              gamma_ = 1. - lambda_[keep_lambda] * np.diag(sigma_)
   389        12          178     14.8      0.0              lambda_[keep_lambda] = ((gamma_ + 2. * lambda_1)
   390        12          216     18.0      0.0                                      / ((coef_[keep_lambda]) ** 2
   391        12          311     25.9      0.0                                         + 2. * lambda_2))
   392        12          329     27.4      0.0              alpha_ = ((n_samples - gamma_.sum() + 2. * alpha_1)
   393        12          115      9.6      0.0                        / (rmse_ + 2. * alpha_2))
   394
   395                                                       ### Prune the weights with a precision over a threshold
   396        12          191     15.9      0.0              keep_lambda = lambda_ &lt; self.threshold_lambda
   397        12          203     16.9      0.0              coef_[~keep_lambda] = 0
   398
   399                                                       ### Compute the objective function
   400        12           57      4.8      0.0              if self.compute_score:
   401                                                           s = (lambda_1 * np.log(lambda_) - lambda_2 * lambda_).sum()
   402                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   403                                                           s += 0.5 * (fast_logdet(sigma_) + n_samples * log(alpha_)
   404                                                                                           + np.sum(np.log(lambda_)))
   405                                                           s -= 0.5 * (alpha_ * rmse_ + (lambda_ * coef_ ** 2).sum())
   406                                                           self.scores_.append(s)
   407
   408                                                       ### Check for convergence
   409        12          487     40.6      0.0              if iter_ &gt; 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   410         1            5      5.0      0.0                  if verbose:
   411                                                               print("Converged after %s iterations" % iter_)
   412         1           10     10.0      0.0                  break
   413        11          184     16.7      0.0              coef_old_ = np.copy(coef_)
   414
   415         1            5      5.0      0.0          self.coef_ = coef_
   416         1            4      4.0      0.0          self.alpha_ = alpha_
   417         1            7      7.0      0.0          self.sigma_ = sigma_
   418         1            5      5.0      0.0          self.lambda_ = lambda_
   419         1           33     33.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   420         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="bayesianridge-arcene">
<h2>BayesianRidge-arcene<a class="headerlink" href="#bayesianridge-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">BayesianRidge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/BayesianRidge-arcene-step0-timing.png"><img alt="_images/BayesianRidge-arcene-step0-timing.png" src="_images/BayesianRidge-arcene-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/BayesianRidge-arcene-step0-memory.png"><img alt="_images/BayesianRidge-arcene-step0-memory.png" src="_images/BayesianRidge-arcene-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         120 function calls in 1.034 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.034    1.034 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.034    1.034 &lt;f&gt;:1(&lt;module&gt;)
     1    0.001    0.001    1.034    1.034 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:121(fit)
     1    0.807    0.807    0.832    0.832 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/decomp_svd.py:14(svd)
    10    0.186    0.019    0.186    0.019 {numpy.core._dotblas.dot}
     1    0.021    0.021    0.024    0.024 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.003    0.003    0.012    0.012 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     2    0.004    0.002    0.004    0.002 {method 'mean' of 'numpy.ndarray' objects}
     2    0.003    0.002    0.003    0.002 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:155(check_arrays)
     9    0.003    0.000    0.003    0.000 {method 'sum' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.003    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
     7    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
    13    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     4    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 {range}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:148(_num_samples)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     2    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 {issubclass}
     3    0.000    0.000    0.000    0.000 {len}
     4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 121
Total time: 1.1362 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   121                                               def fit(self, X, y):
   122                                                   """Fit the model
   123
   124                                                   Parameters
   125                                                   ----------
   126                                                   X : numpy array of shape [n_samples,n_features]
   127                                                       Training data
   128                                                   y : numpy array of shape [n_samples]
   129                                                       Target values
   130
   131                                                   Returns
   132                                                   -------
   133                                                   self : returns an instance of self.
   134                                                   """
   135         1            5      5.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   136         1        14820  14820.0      1.3                              dtype=np.float)
   137         1            6      6.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(
   138         1         9078   9078.0      0.8              X, y, self.fit_intercept, self.normalize, self.copy_X)
   139         1            6      6.0      0.0          n_samples, n_features = X.shape
   140
   141                                                   ### Initialization of the values of the parameters
   142         1           80     80.0      0.0          alpha_ = 1. / np.var(y)
   143         1            4      4.0      0.0          lambda_ = 1.
   144
   145         1            5      5.0      0.0          verbose = self.verbose
   146         1           11     11.0      0.0          lambda_1 = self.lambda_1
   147         1            5      5.0      0.0          lambda_2 = self.lambda_2
   148         1            4      4.0      0.0          alpha_1 = self.alpha_1
   149         1            5      5.0      0.0          alpha_2 = self.alpha_2
   150
   151         1            9      9.0      0.0          self.scores_ = list()
   152         1            4      4.0      0.0          coef_old_ = None
   153
   154         1         2248   2248.0      0.2          XT_y = np.dot(X.T, y)
   155         1       928098 928098.0     81.7          U, S, Vh = linalg.svd(X, full_matrices=False)
   156         1           40     40.0      0.0          eigen_vals_ = S ** 2
   157
   158                                                   ### Convergence loop of the bayesian ridge regression
   159         2           31     15.5      0.0          for iter_ in range(self.n_iter):
   160
   161                                                       ### Compute mu and sigma
   162                                                       # sigma_ = lambda_ / alpha_ * np.eye(n_features) + np.dot(X.T, X)
   163                                                       # coef_ = sigma_^-1 * XT * y
   164         2            8      4.0      0.0              if n_samples &gt; n_features:
   165                                                           coef_ = np.dot(Vh.T,
   166                                                                          Vh / (eigen_vals_ + lambda_ / alpha_)[:, None])
   167                                                           coef_ = np.dot(coef_, XT_y)
   168                                                           if self.compute_score:
   169                                                               logdet_sigma_ = - np.sum(
   170                                                                   np.log(lambda_ + alpha_ * eigen_vals_))
   171                                                       else:
   172         2           16      8.0      0.0                  coef_ = np.dot(X.T, np.dot(
   173         2       172933  86466.5     15.2                      U / (eigen_vals_ + lambda_ / alpha_)[None, :], U.T))
   174         2         3897   1948.5      0.3                  coef_ = np.dot(coef_, y)
   175         2           14      7.0      0.0                  if self.compute_score:
   176                                                               logdet_sigma_ = lambda_ * np.ones(n_features)
   177                                                               logdet_sigma_[:n_samples] += alpha_ * eigen_vals_
   178                                                               logdet_sigma_ = - np.sum(np.log(logdet_sigma_))
   179
   180                                                       ### Update alpha and lambda
   181         2         3979   1989.5      0.4              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   182         2           49     24.5      0.0              gamma_ = (np.sum((alpha_ * eigen_vals_)
   183         2          118     59.0      0.0                        / (lambda_ + alpha_ * eigen_vals_)))
   184         2           32     16.0      0.0              lambda_ = ((gamma_ + 2 * lambda_1)
   185         2          191     95.5      0.0                         / (np.sum(coef_ ** 2) + 2 * lambda_2))
   186         2           29     14.5      0.0              alpha_ = ((n_samples - gamma_ + 2 * alpha_1)
   187         2           16      8.0      0.0                        / (rmse_ + 2 * alpha_2))
   188
   189                                                       ### Compute the objective function
   190         2            9      4.5      0.0              if self.compute_score:
   191                                                           s = lambda_1 * log(lambda_) - lambda_2 * lambda_
   192                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   193                                                           s += 0.5 * (n_features * log(lambda_)
   194                                                                       + n_samples * log(alpha_)
   195                                                                       - alpha_ * rmse_
   196                                                                       - (lambda_ * np.sum(coef_ ** 2))
   197                                                                       - logdet_sigma_
   198                                                                       - n_samples * log(2 * np.pi))
   199                                                           self.scores_.append(s)
   200
   201                                                       ### Check for convergence
   202         2          254    127.0      0.0              if iter_ != 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   203         1            5      5.0      0.0                  if verbose:
   204                                                               print("Convergence after ", str(iter_), " iterations")
   205         1           11     11.0      0.0                  break
   206         1           34     34.0      0.0              coef_old_ = np.copy(coef_)
   207
   208         1            5      5.0      0.0          self.alpha_ = alpha_
   209         1            7      7.0      0.0          self.lambda_ = lambda_
   210         1            4      4.0      0.0          self.coef_ = coef_
   211
   212         1          126    126.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   213         1            3      3.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="bayesianridge-madelon">
<h2>BayesianRidge-madelon<a class="headerlink" href="#bayesianridge-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">BayesianRidge</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<a class="reference internal image-reference" href="_images/BayesianRidge-madelon-step0-timing.png"><img alt="_images/BayesianRidge-madelon-step0-timing.png" src="_images/BayesianRidge-madelon-step0-timing.png" style="width: 6in;" /></a>
<p><strong>Memory usage</strong></p>
<a class="reference internal image-reference" href="_images/BayesianRidge-madelon-step0-memory.png"><img alt="_images/BayesianRidge-madelon-step0-memory.png" src="_images/BayesianRidge-madelon-step0-memory.png" style="width: 6in;" /></a>
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         254 function calls in 3.332 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    3.332    3.332 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    3.332    3.332 &lt;f&gt;:1(&lt;module&gt;)
     1    0.063    0.063    3.332    3.332 /tmp/vb_sklearn/sklearn/linear_model/bayes.py:121(fit)
     1    2.172    2.172    2.196    2.196 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/decomp_svd.py:14(svd)
    32    1.029    0.032    1.029    0.032 {numpy.core._dotblas.dot}
     1    0.004    0.004    0.040    0.040 /tmp/vb_sklearn/sklearn/linear_model/base.py:74(center_data)
     2    0.031    0.015    0.031    0.015 {method 'mean' of 'numpy.ndarray' objects}
     1    0.021    0.021    0.024    0.024 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:66(as_float_array)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     2    0.004    0.002    0.004    0.002 {method 'any' of 'numpy.ndarray' objects}
    41    0.003    0.000    0.003    0.000 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:155(check_arrays)
     2    0.000    0.000    0.003    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:32(_assert_all_finite)
    39    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    45    0.000    0.000    0.000    0.000 {isinstance}
     9    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2470(var)
     1    0.000    0.000    0.000    0.000 {method 'var' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 {range}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:148(_num_samples)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/linear_model/base.py:163(_set_intercept)
    10    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     2    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     3    0.000    0.000    0.000    0.000 {len}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/linear_model/bayes.py
Function: fit at line 121
Total time: 3.39176 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   121                                               def fit(self, X, y):
   122                                                   """Fit the model
   123
   124                                                   Parameters
   125                                                   ----------
   126                                                   X : numpy array of shape [n_samples,n_features]
   127                                                       Training data
   128                                                   y : numpy array of shape [n_samples]
   129                                                       Target values
   130
   131                                                   Returns
   132                                                   -------
   133                                                   self : returns an instance of self.
   134                                                   """
   135         1            6      6.0      0.0          X, y = check_arrays(X, y, sparse_format='dense',
   136         1         2993   2993.0      0.1                              dtype=np.float)
   137         1            6      6.0      0.0          X, y, X_mean, y_mean, X_std = self._center_data(
   138         1        36516  36516.0      1.1              X, y, self.fit_intercept, self.normalize, self.copy_X)
   139         1            6      6.0      0.0          n_samples, n_features = X.shape
   140
   141                                                   ### Initialization of the values of the parameters
   142         1          106    106.0      0.0          alpha_ = 1. / np.var(y)
   143         1            4      4.0      0.0          lambda_ = 1.
   144
   145         1            4      4.0      0.0          verbose = self.verbose
   146         1            6      6.0      0.0          lambda_1 = self.lambda_1
   147         1            4      4.0      0.0          lambda_2 = self.lambda_2
   148         1            4      4.0      0.0          alpha_1 = self.alpha_1
   149         1            4      4.0      0.0          alpha_2 = self.alpha_2
   150
   151         1            8      8.0      0.0          self.scores_ = list()
   152         1            3      3.0      0.0          coef_old_ = None
   153
   154         1         2379   2379.0      0.1          XT_y = np.dot(X.T, y)
   155         1      2255132 2255132.0     66.5          U, S, Vh = linalg.svd(X, full_matrices=False)
   156         1           42     42.0      0.0          eigen_vals_ = S ** 2
   157
   158                                                   ### Convergence loop of the bayesian ridge regression
   159        10           75      7.5      0.0          for iter_ in range(self.n_iter):
   160
   161                                                       ### Compute mu and sigma
   162                                                       # sigma_ = lambda_ / alpha_ * np.eye(n_features) + np.dot(X.T, X)
   163                                                       # coef_ = sigma_^-1 * XT * y
   164        10           41      4.1      0.0              if n_samples &gt; n_features:
   165        10           71      7.1      0.0                  coef_ = np.dot(Vh.T,
   166        10      1042420 104242.0     30.7                                 Vh / (eigen_vals_ + lambda_ / alpha_)[:, None])
   167        10         4656    465.6      0.1                  coef_ = np.dot(coef_, XT_y)
   168        10           60      6.0      0.0                  if self.compute_score:
   169                                                               logdet_sigma_ = - np.sum(
   170                                                                   np.log(lambda_ + alpha_ * eigen_vals_))
   171                                                       else:
   172                                                           coef_ = np.dot(X.T, np.dot(
   173                                                               U / (eigen_vals_ + lambda_ / alpha_)[None, :], U.T))
   174                                                           coef_ = np.dot(coef_, y)
   175                                                           if self.compute_score:
   176                                                               logdet_sigma_ = lambda_ * np.ones(n_features)
   177                                                               logdet_sigma_[:n_samples] += alpha_ * eigen_vals_
   178                                                               logdet_sigma_ = - np.sum(np.log(logdet_sigma_))
   179
   180                                                       ### Update alpha and lambda
   181        10        34490   3449.0      1.0              rmse_ = np.sum((y - np.dot(X, coef_)) ** 2)
   182        10          291     29.1      0.0              gamma_ = (np.sum((alpha_ * eigen_vals_)
   183        10          642     64.2      0.0                        / (lambda_ + alpha_ * eigen_vals_)))
   184        10          163     16.3      0.0              lambda_ = ((gamma_ + 2 * lambda_1)
   185        10          391     39.1      0.0                         / (np.sum(coef_ ** 2) + 2 * lambda_2))
   186        10          136     13.6      0.0              alpha_ = ((n_samples - gamma_ + 2 * alpha_1)
   187        10           76      7.6      0.0                        / (rmse_ + 2 * alpha_2))
   188
   189                                                       ### Compute the objective function
   190        10           47      4.7      0.0              if self.compute_score:
   191                                                           s = lambda_1 * log(lambda_) - lambda_2 * lambda_
   192                                                           s += alpha_1 * log(alpha_) - alpha_2 * alpha_
   193                                                           s += 0.5 * (n_features * log(lambda_)
   194                                                                       + n_samples * log(alpha_)
   195                                                                       - alpha_ * rmse_
   196                                                                       - (lambda_ * np.sum(coef_ ** 2))
   197                                                                       - logdet_sigma_
   198                                                                       - n_samples * log(2 * np.pi))
   199                                                           self.scores_.append(s)
   200
   201                                                       ### Check for convergence
   202        10          478     47.8      0.0              if iter_ != 0 and np.sum(np.abs(coef_old_ - coef_)) &lt; self.tol:
   203         1            4      4.0      0.0                  if verbose:
   204                                                               print("Convergence after ", str(iter_), " iterations")
   205         1           10     10.0      0.0                  break
   206         9        10417   1157.4      0.3              coef_old_ = np.copy(coef_)
   207
   208         1            6      6.0      0.0          self.alpha_ = alpha_
   209         1            7      7.0      0.0          self.lambda_ = lambda_
   210         1            4      4.0      0.0          self.coef_ = coef_
   211
   212         1           46     46.0      0.0          self._set_intercept(X_mean, y_mean, X_std)
   213         1            4      4.0      0.0          return self</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>

        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; .
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2b1. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/vb_linear_model.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="vb_gaussian_process.html">
        Previous
      </a>  
    </div>
    <div class="buttonNext">
      <a href="vb_manifold.html">
        Next
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>