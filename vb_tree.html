

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Benchmarks for tree &mdash; Vbench performance benchmarks for scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.12-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Vbench performance benchmarks for scikit-learn" href="index.html" />
    <link rel="prev" title="Benchmarks for svm" href="vb_svm.html" />

  <!-- Reference the theme's stylesheet on the Google CDN -->
  <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/excite-bike/jquery-ui.css"
        type="text/css" rel="Stylesheet" />
 
  <!-- Reference jQuery and jQuery UI from the CDN. Remember
       that the order of these two elements is important -->
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js"></script>

<script type="text/javascript">
      $(function(){
        $(".profiler-output").accordion({collapsible: true, header: "p", active: false} );
      });
    </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="http://scikit-learn.org/">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="quick_start.html">Speed Quick Start</a></li>
            <li><a href="http://scikit-learn.org/dev/user_guide.html">User's Guide</a></li>
            <li><a href="http://scikit-learn.org/dev/developers/performance.html">Performance</a></li>
            <li><a href="http://github.com/scikit-learn/scikit-learn">Github</a></li>
            <li><a href="http://github.com/vene/scikit-learn-speed">Speed Github</a></li>
       </ul>
</div>
<!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
          <h3>Table Of Contents</h3>
          <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vb_cluster.html">Benchmarks for cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_covariance.html">Benchmarks for covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_decomposition.html">Benchmarks for decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_ensemble.html">Benchmarks for ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_gaussian_process.html">Benchmarks for gaussian_process</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_linear_model.html">Benchmarks for linear_model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_manifold.html">Benchmarks for manifold</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_mixture.html">Benchmarks for mixture</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_naive_bayes.html">Benchmarks for naive_bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_neighbors.html">Benchmarks for neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_pls.html">Benchmarks for pls</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_semi_supervised.html">Benchmarks for semi_supervised</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_svm.html">Benchmarks for svm</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Benchmarks for tree</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#decisiontreeclassifier-arcene">DecisionTreeClassifier-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#decisiontreeclassifier-madelon">DecisionTreeClassifier-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extratreeclassifier-arcene">ExtraTreeClassifier-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extratreeclassifier-madelon">ExtraTreeClassifier-madelon</a></li>
</ul>
</li>
</ul>

          <!--
	   <div class="rel rellarge">
	     
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  --
	<div class="rellink">
	<a href="vb_svm.html" title="Benchmarks for svm"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Benchmarks for s...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for svm
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page --
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.12-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Benchmarks for tree</a><ul>
<li><a class="reference internal" href="#decisiontreeclassifier-arcene">DecisionTreeClassifier-arcene</a></li>
<li><a class="reference internal" href="#decisiontreeclassifier-madelon">DecisionTreeClassifier-madelon</a></li>
<li><a class="reference internal" href="#extratreeclassifier-arcene">ExtraTreeClassifier-arcene</a></li>
<li><a class="reference internal" href="#extratreeclassifier-madelon">ExtraTreeClassifier-madelon</a></li>
</ul>
</li>
</ul>

    
  -->
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="benchmarks-for-tree">
<h1>Benchmarks for tree<a class="headerlink" href="#benchmarks-for-tree" title="Permalink to this headline">¶</a></h1>
<div class="section" id="decisiontreeclassifier-arcene">
<h2>DecisionTreeClassifier-arcene<a class="headerlink" href="#decisiontreeclassifier-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/DecisionTreeClassifier-arcene-step0-timing.png" src="_images/DecisionTreeClassifier-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/DecisionTreeClassifier-arcene-step0-memory.png" src="_images/DecisionTreeClassifier-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         112 function calls in 0.548 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.548    0.548 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.548    0.548 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.548    0.548 /tmp/vb_sklearn/sklearn/tree/tree.py:185(fit)
     1    0.441    0.441    0.522    0.522 {method 'build' of 'sklearn.tree._tree.Tree' objects}
     2    0.000    0.000    0.081    0.041 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
     2    0.081    0.041    0.081    0.041 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.022    0.022 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
     3    0.000    0.000    0.014    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     3    0.014    0.005    0.014    0.005 {method 'sum' of 'numpy.ndarray' objects}
    10    0.011    0.001    0.011    0.001 {numpy.core.multiarray.array}
     4    0.000    0.000    0.011    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     7    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     4    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     7    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {max}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/tree/tree.py
Function: fit at line 185
Total time: 0.643888 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   185                                               def fit(self, X, y,
   186                                                       sample_mask=None, X_argsorted=None,
   187                                                       check_input=True, sample_weight=None):
   188                                                   """Build a decision tree from the training set (X, y).
   189
   190                                                   Parameters
   191                                                   ----------
   192                                                   X : array-like, shape = [n_samples, n_features]
   193                                                       The training input samples. Use ``dtype=np.float32``
   194                                                       and ``order='F'`` for maximum efficiency.
   195
   196                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   197                                                       The target values (integers that correspond to classes in
   198                                                       classification, real numbers in regression).
   199                                                       Use ``dtype=np.float64`` and ``order='C'`` for maximum
   200                                                       efficiency.
   201
   202                                                   sample_mask : array-like, shape = [n_samples], dtype = bool or None
   203                                                       A bit mask that encodes the rows of ``X`` that should be
   204                                                       used to build the decision tree. It can be used for bagging
   205                                                       without the need to create of copy of ``X``.
   206                                                       If None a mask will be created that includes all samples.
   207
   208                                                   X_argsorted : array-like, shape = [n_samples, n_features] or None
   209                                                       Each column of ``X_argsorted`` holds the row indices of ``X``
   210                                                       sorted according to the value of the corresponding feature
   211                                                       in ascending order.
   212                                                       I.e. ``X[X_argsorted[i, k], k] &lt;= X[X_argsorted[j, k], k]``
   213                                                       for each j &gt; i.
   214                                                       If None, ``X_argsorted`` is computed internally.
   215                                                       The argument is supported to enable multiple decision trees
   216                                                       to share the data structure and to avoid re-computation in
   217                                                       tree ensembles. For maximum efficiency use dtype np.int32.
   218
   219                                                   sample_weight : array-like, shape = [n_samples] or None
   220                                                       Sample weights. If None, then samples are equally weighted. Splits
   221                                                       that would create child nodes with net zero or negative weight are
   222                                                       ignored while searching for a split in each node. In the case of
   223                                                       classification, splits are also ignored if they would result in any
   224                                                       single class carrying a negative weight in either child node.
   225
   226                                                   check_input : boolean, (default=True)
   227                                                       Allow to bypass several input checking.
   228                                                       Don't use this parameter unless you know what you do.
   229
   230                                                   Returns
   231                                                   -------
   232                                                   self : object
   233                                                       Returns self.
   234                                                   """
   235         1            6      6.0      0.0          if check_input:
   236         1         2909   2909.0      0.5              X, y = check_arrays(X, y)
   237         1           59     59.0      0.0          random_state = check_random_state(self.random_state)
   238
   239                                                   # Convert data
   240         1            9      9.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   241                                                           X.ndim != 2 or
   242                                                           not X.flags.fortran):
   243         1        30882  30882.0      4.8              X = array2d(X, dtype=DTYPE, order="F")
   244
   245         1           10     10.0      0.0          n_samples, self.n_features_ = X.shape
   246         1           12     12.0      0.0          is_classification = isinstance(self, ClassifierMixin)
   247
   248         1           40     40.0      0.0          y = np.atleast_1d(y)
   249         1            6      6.0      0.0          if y.ndim == 1:
   250                                                       # reshape is necessary to preserve the data contiguity against vs
   251                                                       # [:, np.newaxis] that does not.
   252         1           20     20.0      0.0              y = np.reshape(y, (-1, 1))
   253
   254         1            6      6.0      0.0          self.n_outputs_ = y.shape[1]
   255
   256         1            4      4.0      0.0          if is_classification:
   257         1           18     18.0      0.0              y = np.copy(y)
   258
   259         1            5      5.0      0.0              self.classes_ = []
   260         1            5      5.0      0.0              self.n_classes_ = []
   261
   262         2           13      6.5      0.0              for k in xrange(self.n_outputs_):
   263         1          109    109.0      0.0                  unique = np.unique(y[:, k])
   264         1            6      6.0      0.0                  self.classes_.append(unique)
   265         1            7      7.0      0.0                  self.n_classes_.append(unique.shape[0])
   266         1           32     32.0      0.0                  y[:, k] = np.searchsorted(unique, y[:, k])
   267
   268                                                   else:
   269                                                       self.classes_ = [None] * self.n_outputs_
   270                                                       self.n_classes_ = [1] * self.n_outputs_
   271
   272         1            9      9.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   273         1           18     18.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   274
   275         1            5      5.0      0.0          if is_classification:
   276         1            6      6.0      0.0              criterion = CLASSIFICATION[self.criterion](self.n_outputs_,
   277         1            8      8.0      0.0                                                         self.n_classes_)
   278                                                   else:
   279                                                       criterion = REGRESSION[self.criterion](self.n_outputs_)
   280
   281                                                   # Check parameters
   282         1            6      6.0      0.0          max_depth = np.inf if self.max_depth is None else self.max_depth
   283
   284         1            8      8.0      0.0          if isinstance(self.max_features, six.string_types):
   285                                                       if self.max_features == "auto":
   286                                                           if is_classification:
   287                                                               max_features = max(1, int(np.sqrt(self.n_features_)))
   288                                                           else:
   289                                                               max_features = self.n_features_
   290                                                       elif self.max_features == "sqrt":
   291                                                           max_features = max(1, int(np.sqrt(self.n_features_)))
   292                                                       elif self.max_features == "log2":
   293                                                           max_features = max(1, int(np.log2(self.n_features_)))
   294                                                       else:
   295                                                           raise ValueError(
   296                                                               'Invalid value for max_features. Allowed string '
   297                                                               'values are "auto", "sqrt" or "log2".')
   298         1            5      5.0      0.0          elif self.max_features is None:
   299         1            4      4.0      0.0              max_features = self.n_features_
   300                                                   else:
   301                                                       max_features = self.max_features
   302
   303         1            5      5.0      0.0          if len(y) != n_samples:
   304                                                       raise ValueError("Number of labels=%d does not match "
   305                                                                        "number of samples=%d" % (len(y), n_samples))
   306         1            5      5.0      0.0          if self.min_samples_split &lt;= 0:
   307                                                       raise ValueError("min_samples_split must be greater than zero.")
   308         1            4      4.0      0.0          if self.min_samples_leaf &lt;= 0:
   309                                                       raise ValueError("min_samples_leaf must be greater than zero.")
   310         1            5      5.0      0.0          if max_depth &lt;= 0:
   311                                                       raise ValueError("max_depth must be greater than zero. ")
   312         1            7      7.0      0.0          if self.min_density &lt; 0.0 or self.min_density &gt; 1.0:
   313                                                       raise ValueError("min_density must be in [0, 1]")
   314         1            6      6.0      0.0          if not (0 &lt; max_features &lt;= self.n_features_):
   315                                                       raise ValueError("max_features must be in (0, n_features]")
   316
   317         1            4      4.0      0.0          if sample_mask is not None:
   318                                                       sample_mask = np.asarray(sample_mask, dtype=np.bool)
   319
   320                                                       if sample_mask.shape[0] != n_samples:
   321                                                           raise ValueError("Length of sample_mask=%d does not match "
   322                                                                            "number of samples=%d"
   323                                                                            % (sample_mask.shape[0], n_samples))
   324
   325         1            5      5.0      0.0          if sample_weight is not None:
   326                                                       if (getattr(sample_weight, "dtype", None) != DOUBLE or
   327                                                               not sample_weight.flags.contiguous):
   328                                                           sample_weight = np.ascontiguousarray(
   329                                                               sample_weight, dtype=DOUBLE)
   330                                                       if len(sample_weight.shape) &gt; 1:
   331                                                           raise ValueError("Sample weights array has more "
   332                                                                            "than one dimension: %d" %
   333                                                                            len(sample_weight.shape))
   334                                                       if len(sample_weight) != n_samples:
   335                                                           raise ValueError("Number of weights=%d does not match "
   336                                                                            "number of samples=%d" %
   337                                                                            (len(sample_weight), n_samples))
   338
   339         1            5      5.0      0.0          if X_argsorted is not None:
   340                                                       X_argsorted = np.asarray(X_argsorted, dtype=np.int32,
   341                                                                                order='F')
   342                                                       if X_argsorted.shape != X.shape:
   343                                                           raise ValueError("Shape of X_argsorted does not match "
   344                                                                            "the shape of X")
   345
   346                                                   # Set min_samples_split sensibly
   347         1            5      5.0      0.0          min_samples_split = max(self.min_samples_split,
   348         1            7      7.0      0.0                                  2 * self.min_samples_leaf)
   349
   350                                                   # Build tree
   351         1            6      6.0      0.0          self.tree_ = _tree.Tree(self.n_features_, self.n_classes_,
   352         1            4      4.0      0.0                                  self.n_outputs_, criterion, max_depth,
   353         1            5      5.0      0.0                                  min_samples_split, self.min_samples_leaf,
   354         1            4      4.0      0.0                                  self.min_density, max_features,
   355         1          131    131.0      0.0                                  self.find_split_, random_state)
   356
   357         1            6      6.0      0.0          self.tree_.build(X, y,
   358         1            5      5.0      0.0                           sample_weight=sample_weight,
   359         1            4      4.0      0.0                           sample_mask=sample_mask,
   360         1       609406 609406.0     94.6                           X_argsorted=X_argsorted)
   361
   362         1            8      8.0      0.0          if self.n_outputs_ == 1:
   363         1            7      7.0      0.0              self.n_classes_ = self.n_classes_[0]
   364         1            7      7.0      0.0              self.classes_ = self.classes_[0]
   365
   366                                                   # Compute importances
   367         1            5      5.0      0.0          if self.compute_importances:
   368                                                       self.feature_importances_ = \
   369                                                           self.tree_.compute_feature_importances()
   370
   371         1            5      5.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="decisiontreeclassifier-madelon">
<h2>DecisionTreeClassifier-madelon<a class="headerlink" href="#decisiontreeclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/DecisionTreeClassifier-madelon-step0-timing.png" src="_images/DecisionTreeClassifier-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/DecisionTreeClassifier-madelon-step0-memory.png" src="_images/DecisionTreeClassifier-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         420 function calls in 1.772 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.772    1.772 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.772    1.772 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.772    1.772 /tmp/vb_sklearn/sklearn/tree/tree.py:185(fit)
     1    1.487    1.487    1.745    1.745 {method 'build' of 'sklearn.tree._tree.Tree' objects}
    46    0.000    0.000    0.257    0.006 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
    46    0.257    0.006    0.257    0.006 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.023    0.023 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
     3    0.000    0.000    0.016    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     3    0.015    0.005    0.015    0.005 {method 'sum' of 'numpy.ndarray' objects}
    54    0.010    0.000    0.010    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.010    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
    46    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    46    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
    46    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    46    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     7    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     4    0.000    0.000    0.000    0.000 {getattr}
     7    0.000    0.000    0.000    0.000 {len}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/tree/tree.py
Function: fit at line 185
Total time: 1.84715 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   185                                               def fit(self, X, y,
   186                                                       sample_mask=None, X_argsorted=None,
   187                                                       check_input=True, sample_weight=None):
   188                                                   """Build a decision tree from the training set (X, y).
   189
   190                                                   Parameters
   191                                                   ----------
   192                                                   X : array-like, shape = [n_samples, n_features]
   193                                                       The training input samples. Use ``dtype=np.float32``
   194                                                       and ``order='F'`` for maximum efficiency.
   195
   196                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   197                                                       The target values (integers that correspond to classes in
   198                                                       classification, real numbers in regression).
   199                                                       Use ``dtype=np.float64`` and ``order='C'`` for maximum
   200                                                       efficiency.
   201
   202                                                   sample_mask : array-like, shape = [n_samples], dtype = bool or None
   203                                                       A bit mask that encodes the rows of ``X`` that should be
   204                                                       used to build the decision tree. It can be used for bagging
   205                                                       without the need to create of copy of ``X``.
   206                                                       If None a mask will be created that includes all samples.
   207
   208                                                   X_argsorted : array-like, shape = [n_samples, n_features] or None
   209                                                       Each column of ``X_argsorted`` holds the row indices of ``X``
   210                                                       sorted according to the value of the corresponding feature
   211                                                       in ascending order.
   212                                                       I.e. ``X[X_argsorted[i, k], k] &lt;= X[X_argsorted[j, k], k]``
   213                                                       for each j &gt; i.
   214                                                       If None, ``X_argsorted`` is computed internally.
   215                                                       The argument is supported to enable multiple decision trees
   216                                                       to share the data structure and to avoid re-computation in
   217                                                       tree ensembles. For maximum efficiency use dtype np.int32.
   218
   219                                                   sample_weight : array-like, shape = [n_samples] or None
   220                                                       Sample weights. If None, then samples are equally weighted. Splits
   221                                                       that would create child nodes with net zero or negative weight are
   222                                                       ignored while searching for a split in each node. In the case of
   223                                                       classification, splits are also ignored if they would result in any
   224                                                       single class carrying a negative weight in either child node.
   225
   226                                                   check_input : boolean, (default=True)
   227                                                       Allow to bypass several input checking.
   228                                                       Don't use this parameter unless you know what you do.
   229
   230                                                   Returns
   231                                                   -------
   232                                                   self : object
   233                                                       Returns self.
   234                                                   """
   235         1            6      6.0      0.0          if check_input:
   236         1         2952   2952.0      0.2              X, y = check_arrays(X, y)
   237         1           49     49.0      0.0          random_state = check_random_state(self.random_state)
   238
   239                                                   # Convert data
   240         1            9      9.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   241                                                           X.ndim != 2 or
   242                                                           not X.flags.fortran):
   243         1        17878  17878.0      1.0              X = array2d(X, dtype=DTYPE, order="F")
   244
   245         1           10     10.0      0.0          n_samples, self.n_features_ = X.shape
   246         1           12     12.0      0.0          is_classification = isinstance(self, ClassifierMixin)
   247
   248         1           39     39.0      0.0          y = np.atleast_1d(y)
   249         1            6      6.0      0.0          if y.ndim == 1:
   250                                                       # reshape is necessary to preserve the data contiguity against vs
   251                                                       # [:, np.newaxis] that does not.
   252         1           20     20.0      0.0              y = np.reshape(y, (-1, 1))
   253
   254         1            6      6.0      0.0          self.n_outputs_ = y.shape[1]
   255
   256         1            5      5.0      0.0          if is_classification:
   257         1           20     20.0      0.0              y = np.copy(y)
   258
   259         1            5      5.0      0.0              self.classes_ = []
   260         1            5      5.0      0.0              self.n_classes_ = []
   261
   262         2           13      6.5      0.0              for k in xrange(self.n_outputs_):
   263         1          201    201.0      0.0                  unique = np.unique(y[:, k])
   264         1            7      7.0      0.0                  self.classes_.append(unique)
   265         1            7      7.0      0.0                  self.n_classes_.append(unique.shape[0])
   266         1           98     98.0      0.0                  y[:, k] = np.searchsorted(unique, y[:, k])
   267
   268                                                   else:
   269                                                       self.classes_ = [None] * self.n_outputs_
   270                                                       self.n_classes_ = [1] * self.n_outputs_
   271
   272         1            9      9.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   273         1           21     21.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   274
   275         1            5      5.0      0.0          if is_classification:
   276         1            6      6.0      0.0              criterion = CLASSIFICATION[self.criterion](self.n_outputs_,
   277         1            9      9.0      0.0                                                         self.n_classes_)
   278                                                   else:
   279                                                       criterion = REGRESSION[self.criterion](self.n_outputs_)
   280
   281                                                   # Check parameters
   282         1            6      6.0      0.0          max_depth = np.inf if self.max_depth is None else self.max_depth
   283
   284         1            9      9.0      0.0          if isinstance(self.max_features, six.string_types):
   285                                                       if self.max_features == "auto":
   286                                                           if is_classification:
   287                                                               max_features = max(1, int(np.sqrt(self.n_features_)))
   288                                                           else:
   289                                                               max_features = self.n_features_
   290                                                       elif self.max_features == "sqrt":
   291                                                           max_features = max(1, int(np.sqrt(self.n_features_)))
   292                                                       elif self.max_features == "log2":
   293                                                           max_features = max(1, int(np.log2(self.n_features_)))
   294                                                       else:
   295                                                           raise ValueError(
   296                                                               'Invalid value for max_features. Allowed string '
   297                                                               'values are "auto", "sqrt" or "log2".')
   298         1            4      4.0      0.0          elif self.max_features is None:
   299         1            5      5.0      0.0              max_features = self.n_features_
   300                                                   else:
   301                                                       max_features = self.max_features
   302
   303         1            5      5.0      0.0          if len(y) != n_samples:
   304                                                       raise ValueError("Number of labels=%d does not match "
   305                                                                        "number of samples=%d" % (len(y), n_samples))
   306         1            5      5.0      0.0          if self.min_samples_split &lt;= 0:
   307                                                       raise ValueError("min_samples_split must be greater than zero.")
   308         1            4      4.0      0.0          if self.min_samples_leaf &lt;= 0:
   309                                                       raise ValueError("min_samples_leaf must be greater than zero.")
   310         1            5      5.0      0.0          if max_depth &lt;= 0:
   311                                                       raise ValueError("max_depth must be greater than zero. ")
   312         1            7      7.0      0.0          if self.min_density &lt; 0.0 or self.min_density &gt; 1.0:
   313                                                       raise ValueError("min_density must be in [0, 1]")
   314         1            6      6.0      0.0          if not (0 &lt; max_features &lt;= self.n_features_):
   315                                                       raise ValueError("max_features must be in (0, n_features]")
   316
   317         1            5      5.0      0.0          if sample_mask is not None:
   318                                                       sample_mask = np.asarray(sample_mask, dtype=np.bool)
   319
   320                                                       if sample_mask.shape[0] != n_samples:
   321                                                           raise ValueError("Length of sample_mask=%d does not match "
   322                                                                            "number of samples=%d"
   323                                                                            % (sample_mask.shape[0], n_samples))
   324
   325         1            4      4.0      0.0          if sample_weight is not None:
   326                                                       if (getattr(sample_weight, "dtype", None) != DOUBLE or
   327                                                               not sample_weight.flags.contiguous):
   328                                                           sample_weight = np.ascontiguousarray(
   329                                                               sample_weight, dtype=DOUBLE)
   330                                                       if len(sample_weight.shape) &gt; 1:
   331                                                           raise ValueError("Sample weights array has more "
   332                                                                            "than one dimension: %d" %
   333                                                                            len(sample_weight.shape))
   334                                                       if len(sample_weight) != n_samples:
   335                                                           raise ValueError("Number of weights=%d does not match "
   336                                                                            "number of samples=%d" %
   337                                                                            (len(sample_weight), n_samples))
   338
   339         1            5      5.0      0.0          if X_argsorted is not None:
   340                                                       X_argsorted = np.asarray(X_argsorted, dtype=np.int32,
   341                                                                                order='F')
   342                                                       if X_argsorted.shape != X.shape:
   343                                                           raise ValueError("Shape of X_argsorted does not match "
   344                                                                            "the shape of X")
   345
   346                                                   # Set min_samples_split sensibly
   347         1            5      5.0      0.0          min_samples_split = max(self.min_samples_split,
   348         1            8      8.0      0.0                                  2 * self.min_samples_leaf)
   349
   350                                                   # Build tree
   351         1            5      5.0      0.0          self.tree_ = _tree.Tree(self.n_features_, self.n_classes_,
   352         1            5      5.0      0.0                                  self.n_outputs_, criterion, max_depth,
   353         1            5      5.0      0.0                                  min_samples_split, self.min_samples_leaf,
   354         1            4      4.0      0.0                                  self.min_density, max_features,
   355         1          132    132.0      0.0                                  self.find_split_, random_state)
   356
   357         1            7      7.0      0.0          self.tree_.build(X, y,
   358         1            5      5.0      0.0                           sample_weight=sample_weight,
   359         1            5      5.0      0.0                           sample_mask=sample_mask,
   360         1      1825484 1825484.0     98.8                           X_argsorted=X_argsorted)
   361
   362         1            5      5.0      0.0          if self.n_outputs_ == 1:
   363         1            5      5.0      0.0              self.n_classes_ = self.n_classes_[0]
   364         1            3      3.0      0.0              self.classes_ = self.classes_[0]
   365
   366                                                   # Compute importances
   367         1            2      2.0      0.0          if self.compute_importances:
   368                                                       self.feature_importances_ = \
   369                                                           self.tree_.compute_feature_importances()
   370
   371         1            2      2.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="extratreeclassifier-arcene">
<h2>ExtraTreeClassifier-arcene<a class="headerlink" href="#extratreeclassifier-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">ExtraTreeClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ExtraTreeClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ExtraTreeClassifier-arcene-step0-timing.png" src="_images/ExtraTreeClassifier-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ExtraTreeClassifier-arcene-step0-memory.png" src="_images/ExtraTreeClassifier-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         155 function calls in 0.259 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.259    0.259 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.259    0.259 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.259    0.259 /tmp/vb_sklearn/sklearn/tree/tree.py:185(fit)
     1    0.144    0.144    0.233    0.233 {method 'build' of 'sklearn.tree._tree.Tree' objects}
     8    0.000    0.000    0.089    0.011 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
     8    0.089    0.011    0.089    0.011 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.022    0.022 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
     3    0.000    0.000    0.014    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     3    0.013    0.004    0.013    0.004 {method 'sum' of 'numpy.ndarray' objects}
    16    0.011    0.001    0.011    0.001 {numpy.core.multiarray.array}
     4    0.000    0.000    0.011    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     8    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
     8    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     7    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
     8    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     8    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     6    0.000    0.000    0.000    0.000 {hasattr}
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     4    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {max}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     7    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/tree/tree.py
Function: fit at line 185
Total time: 0.317741 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   185                                               def fit(self, X, y,
   186                                                       sample_mask=None, X_argsorted=None,
   187                                                       check_input=True, sample_weight=None):
   188                                                   """Build a decision tree from the training set (X, y).
   189
   190                                                   Parameters
   191                                                   ----------
   192                                                   X : array-like, shape = [n_samples, n_features]
   193                                                       The training input samples. Use ``dtype=np.float32``
   194                                                       and ``order='F'`` for maximum efficiency.
   195
   196                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   197                                                       The target values (integers that correspond to classes in
   198                                                       classification, real numbers in regression).
   199                                                       Use ``dtype=np.float64`` and ``order='C'`` for maximum
   200                                                       efficiency.
   201
   202                                                   sample_mask : array-like, shape = [n_samples], dtype = bool or None
   203                                                       A bit mask that encodes the rows of ``X`` that should be
   204                                                       used to build the decision tree. It can be used for bagging
   205                                                       without the need to create of copy of ``X``.
   206                                                       If None a mask will be created that includes all samples.
   207
   208                                                   X_argsorted : array-like, shape = [n_samples, n_features] or None
   209                                                       Each column of ``X_argsorted`` holds the row indices of ``X``
   210                                                       sorted according to the value of the corresponding feature
   211                                                       in ascending order.
   212                                                       I.e. ``X[X_argsorted[i, k], k] &lt;= X[X_argsorted[j, k], k]``
   213                                                       for each j &gt; i.
   214                                                       If None, ``X_argsorted`` is computed internally.
   215                                                       The argument is supported to enable multiple decision trees
   216                                                       to share the data structure and to avoid re-computation in
   217                                                       tree ensembles. For maximum efficiency use dtype np.int32.
   218
   219                                                   sample_weight : array-like, shape = [n_samples] or None
   220                                                       Sample weights. If None, then samples are equally weighted. Splits
   221                                                       that would create child nodes with net zero or negative weight are
   222                                                       ignored while searching for a split in each node. In the case of
   223                                                       classification, splits are also ignored if they would result in any
   224                                                       single class carrying a negative weight in either child node.
   225
   226                                                   check_input : boolean, (default=True)
   227                                                       Allow to bypass several input checking.
   228                                                       Don't use this parameter unless you know what you do.
   229
   230                                                   Returns
   231                                                   -------
   232                                                   self : object
   233                                                       Returns self.
   234                                                   """
   235         1            5      5.0      0.0          if check_input:
   236         1         2959   2959.0      0.9              X, y = check_arrays(X, y)
   237         1           49     49.0      0.0          random_state = check_random_state(self.random_state)
   238
   239                                                   # Convert data
   240         1            8      8.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   241                                                           X.ndim != 2 or
   242                                                           not X.flags.fortran):
   243         1        17917  17917.0      5.6              X = array2d(X, dtype=DTYPE, order="F")
   244
   245         1           10     10.0      0.0          n_samples, self.n_features_ = X.shape
   246         1           11     11.0      0.0          is_classification = isinstance(self, ClassifierMixin)
   247
   248         1           40     40.0      0.0          y = np.atleast_1d(y)
   249         1            5      5.0      0.0          if y.ndim == 1:
   250                                                       # reshape is necessary to preserve the data contiguity against vs
   251                                                       # [:, np.newaxis] that does not.
   252         1           20     20.0      0.0              y = np.reshape(y, (-1, 1))
   253
   254         1            8      8.0      0.0          self.n_outputs_ = y.shape[1]
   255
   256         1            5      5.0      0.0          if is_classification:
   257         1           17     17.0      0.0              y = np.copy(y)
   258
   259         1            5      5.0      0.0              self.classes_ = []
   260         1            6      6.0      0.0              self.n_classes_ = []
   261
   262         2           13      6.5      0.0              for k in xrange(self.n_outputs_):
   263         1          108    108.0      0.0                  unique = np.unique(y[:, k])
   264         1            6      6.0      0.0                  self.classes_.append(unique)
   265         1            7      7.0      0.0                  self.n_classes_.append(unique.shape[0])
   266         1           32     32.0      0.0                  y[:, k] = np.searchsorted(unique, y[:, k])
   267
   268                                                   else:
   269                                                       self.classes_ = [None] * self.n_outputs_
   270                                                       self.n_classes_ = [1] * self.n_outputs_
   271
   272         1           10     10.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   273         1           17     17.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   274
   275         1            5      5.0      0.0          if is_classification:
   276         1            5      5.0      0.0              criterion = CLASSIFICATION[self.criterion](self.n_outputs_,
   277         1           10     10.0      0.0                                                         self.n_classes_)
   278                                                   else:
   279                                                       criterion = REGRESSION[self.criterion](self.n_outputs_)
   280
   281                                                   # Check parameters
   282         1            5      5.0      0.0          max_depth = np.inf if self.max_depth is None else self.max_depth
   283
   284         1            7      7.0      0.0          if isinstance(self.max_features, six.string_types):
   285         1            5      5.0      0.0              if self.max_features == "auto":
   286         1            4      4.0      0.0                  if is_classification:
   287         1           30     30.0      0.0                      max_features = max(1, int(np.sqrt(self.n_features_)))
   288                                                           else:
   289                                                               max_features = self.n_features_
   290                                                       elif self.max_features == "sqrt":
   291                                                           max_features = max(1, int(np.sqrt(self.n_features_)))
   292                                                       elif self.max_features == "log2":
   293                                                           max_features = max(1, int(np.log2(self.n_features_)))
   294                                                       else:
   295                                                           raise ValueError(
   296                                                               'Invalid value for max_features. Allowed string '
   297                                                               'values are "auto", "sqrt" or "log2".')
   298                                                   elif self.max_features is None:
   299                                                       max_features = self.n_features_
   300                                                   else:
   301                                                       max_features = self.max_features
   302
   303         1            6      6.0      0.0          if len(y) != n_samples:
   304                                                       raise ValueError("Number of labels=%d does not match "
   305                                                                        "number of samples=%d" % (len(y), n_samples))
   306         1            5      5.0      0.0          if self.min_samples_split &lt;= 0:
   307                                                       raise ValueError("min_samples_split must be greater than zero.")
   308         1            5      5.0      0.0          if self.min_samples_leaf &lt;= 0:
   309                                                       raise ValueError("min_samples_leaf must be greater than zero.")
   310         1            5      5.0      0.0          if max_depth &lt;= 0:
   311                                                       raise ValueError("max_depth must be greater than zero. ")
   312         1            5      5.0      0.0          if self.min_density &lt; 0.0 or self.min_density &gt; 1.0:
   313                                                       raise ValueError("min_density must be in [0, 1]")
   314         1            6      6.0      0.0          if not (0 &lt; max_features &lt;= self.n_features_):
   315                                                       raise ValueError("max_features must be in (0, n_features]")
   316
   317         1            4      4.0      0.0          if sample_mask is not None:
   318                                                       sample_mask = np.asarray(sample_mask, dtype=np.bool)
   319
   320                                                       if sample_mask.shape[0] != n_samples:
   321                                                           raise ValueError("Length of sample_mask=%d does not match "
   322                                                                            "number of samples=%d"
   323                                                                            % (sample_mask.shape[0], n_samples))
   324
   325         1            5      5.0      0.0          if sample_weight is not None:
   326                                                       if (getattr(sample_weight, "dtype", None) != DOUBLE or
   327                                                               not sample_weight.flags.contiguous):
   328                                                           sample_weight = np.ascontiguousarray(
   329                                                               sample_weight, dtype=DOUBLE)
   330                                                       if len(sample_weight.shape) &gt; 1:
   331                                                           raise ValueError("Sample weights array has more "
   332                                                                            "than one dimension: %d" %
   333                                                                            len(sample_weight.shape))
   334                                                       if len(sample_weight) != n_samples:
   335                                                           raise ValueError("Number of weights=%d does not match "
   336                                                                            "number of samples=%d" %
   337                                                                            (len(sample_weight), n_samples))
   338
   339         1            4      4.0      0.0          if X_argsorted is not None:
   340                                                       X_argsorted = np.asarray(X_argsorted, dtype=np.int32,
   341                                                                                order='F')
   342                                                       if X_argsorted.shape != X.shape:
   343                                                           raise ValueError("Shape of X_argsorted does not match "
   344                                                                            "the shape of X")
   345
   346                                                   # Set min_samples_split sensibly
   347         1            5      5.0      0.0          min_samples_split = max(self.min_samples_split,
   348         1            6      6.0      0.0                                  2 * self.min_samples_leaf)
   349
   350                                                   # Build tree
   351         1            5      5.0      0.0          self.tree_ = _tree.Tree(self.n_features_, self.n_classes_,
   352         1            5      5.0      0.0                                  self.n_outputs_, criterion, max_depth,
   353         1            5      5.0      0.0                                  min_samples_split, self.min_samples_leaf,
   354         1            5      5.0      0.0                                  self.min_density, max_features,
   355         1          145    145.0      0.0                                  self.find_split_, random_state)
   356
   357         1            7      7.0      0.0          self.tree_.build(X, y,
   358         1            5      5.0      0.0                           sample_weight=sample_weight,
   359         1            5      5.0      0.0                           sample_mask=sample_mask,
   360         1       296144 296144.0     93.2                           X_argsorted=X_argsorted)
   361
   362         1            8      8.0      0.0          if self.n_outputs_ == 1:
   363         1            7      7.0      0.0              self.n_classes_ = self.n_classes_[0]
   364         1            5      5.0      0.0              self.classes_ = self.classes_[0]
   365
   366                                                   # Compute importances
   367         1            5      5.0      0.0          if self.compute_importances:
   368                                                       self.feature_importances_ = \
   369                                                           self.tree_.compute_feature_importances()
   370
   371         1            5      5.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="extratreeclassifier-madelon">
<h2>ExtraTreeClassifier-madelon<a class="headerlink" href="#extratreeclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">ExtraTreeClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ExtraTreeClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ExtraTreeClassifier-madelon-step0-timing.png" src="_images/ExtraTreeClassifier-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ExtraTreeClassifier-madelon-step0-memory.png" src="_images/ExtraTreeClassifier-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         1107 function calls in 0.609 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.609    0.609 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.609    0.609 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.609    0.609 /tmp/vb_sklearn/sklearn/tree/tree.py:185(fit)
     1    0.306    0.306    0.581    0.581 {method 'build' of 'sklearn.tree._tree.Tree' objects}
   144    0.001    0.000    0.273    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
   144    0.272    0.002    0.272    0.002 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.023    0.023 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
     3    0.000    0.000    0.016    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     3    0.016    0.005    0.016    0.005 {method 'sum' of 'numpy.ndarray' objects}
   152    0.011    0.000    0.011    0.000 {numpy.core.multiarray.array}
     4    0.000    0.000    0.010    0.003 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
   144    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
   144    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
   144    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
   144    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     7    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     4    0.000    0.000    0.000    0.000 {getattr}
     7    0.000    0.000    0.000    0.000 {len}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/tree/tree.py
Function: fit at line 185
Total time: 0.669643 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   185                                               def fit(self, X, y,
   186                                                       sample_mask=None, X_argsorted=None,
   187                                                       check_input=True, sample_weight=None):
   188                                                   """Build a decision tree from the training set (X, y).
   189
   190                                                   Parameters
   191                                                   ----------
   192                                                   X : array-like, shape = [n_samples, n_features]
   193                                                       The training input samples. Use ``dtype=np.float32``
   194                                                       and ``order='F'`` for maximum efficiency.
   195
   196                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   197                                                       The target values (integers that correspond to classes in
   198                                                       classification, real numbers in regression).
   199                                                       Use ``dtype=np.float64`` and ``order='C'`` for maximum
   200                                                       efficiency.
   201
   202                                                   sample_mask : array-like, shape = [n_samples], dtype = bool or None
   203                                                       A bit mask that encodes the rows of ``X`` that should be
   204                                                       used to build the decision tree. It can be used for bagging
   205                                                       without the need to create of copy of ``X``.
   206                                                       If None a mask will be created that includes all samples.
   207
   208                                                   X_argsorted : array-like, shape = [n_samples, n_features] or None
   209                                                       Each column of ``X_argsorted`` holds the row indices of ``X``
   210                                                       sorted according to the value of the corresponding feature
   211                                                       in ascending order.
   212                                                       I.e. ``X[X_argsorted[i, k], k] &lt;= X[X_argsorted[j, k], k]``
   213                                                       for each j &gt; i.
   214                                                       If None, ``X_argsorted`` is computed internally.
   215                                                       The argument is supported to enable multiple decision trees
   216                                                       to share the data structure and to avoid re-computation in
   217                                                       tree ensembles. For maximum efficiency use dtype np.int32.
   218
   219                                                   sample_weight : array-like, shape = [n_samples] or None
   220                                                       Sample weights. If None, then samples are equally weighted. Splits
   221                                                       that would create child nodes with net zero or negative weight are
   222                                                       ignored while searching for a split in each node. In the case of
   223                                                       classification, splits are also ignored if they would result in any
   224                                                       single class carrying a negative weight in either child node.
   225
   226                                                   check_input : boolean, (default=True)
   227                                                       Allow to bypass several input checking.
   228                                                       Don't use this parameter unless you know what you do.
   229
   230                                                   Returns
   231                                                   -------
   232                                                   self : object
   233                                                       Returns self.
   234                                                   """
   235         1            6      6.0      0.0          if check_input:
   236         1         2953   2953.0      0.4              X, y = check_arrays(X, y)
   237         1           58     58.0      0.0          random_state = check_random_state(self.random_state)
   238
   239                                                   # Convert data
   240         1            8      8.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   241                                                           X.ndim != 2 or
   242                                                           not X.flags.fortran):
   243         1        29008  29008.0      4.3              X = array2d(X, dtype=DTYPE, order="F")
   244
   245         1           10     10.0      0.0          n_samples, self.n_features_ = X.shape
   246         1           12     12.0      0.0          is_classification = isinstance(self, ClassifierMixin)
   247
   248         1           40     40.0      0.0          y = np.atleast_1d(y)
   249         1            5      5.0      0.0          if y.ndim == 1:
   250                                                       # reshape is necessary to preserve the data contiguity against vs
   251                                                       # [:, np.newaxis] that does not.
   252         1           19     19.0      0.0              y = np.reshape(y, (-1, 1))
   253
   254         1            7      7.0      0.0          self.n_outputs_ = y.shape[1]
   255
   256         1            4      4.0      0.0          if is_classification:
   257         1           20     20.0      0.0              y = np.copy(y)
   258
   259         1            5      5.0      0.0              self.classes_ = []
   260         1            5      5.0      0.0              self.n_classes_ = []
   261
   262         2           13      6.5      0.0              for k in xrange(self.n_outputs_):
   263         1          201    201.0      0.0                  unique = np.unique(y[:, k])
   264         1            6      6.0      0.0                  self.classes_.append(unique)
   265         1            6      6.0      0.0                  self.n_classes_.append(unique.shape[0])
   266         1          107    107.0      0.0                  y[:, k] = np.searchsorted(unique, y[:, k])
   267
   268                                                   else:
   269                                                       self.classes_ = [None] * self.n_outputs_
   270                                                       self.n_classes_ = [1] * self.n_outputs_
   271
   272         1            9      9.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   273         1           22     22.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   274
   275         1            5      5.0      0.0          if is_classification:
   276         1            6      6.0      0.0              criterion = CLASSIFICATION[self.criterion](self.n_outputs_,
   277         1            9      9.0      0.0                                                         self.n_classes_)
   278                                                   else:
   279                                                       criterion = REGRESSION[self.criterion](self.n_outputs_)
   280
   281                                                   # Check parameters
   282         1            6      6.0      0.0          max_depth = np.inf if self.max_depth is None else self.max_depth
   283
   284         1            8      8.0      0.0          if isinstance(self.max_features, six.string_types):
   285         1            5      5.0      0.0              if self.max_features == "auto":
   286         1            5      5.0      0.0                  if is_classification:
   287         1           30     30.0      0.0                      max_features = max(1, int(np.sqrt(self.n_features_)))
   288                                                           else:
   289                                                               max_features = self.n_features_
   290                                                       elif self.max_features == "sqrt":
   291                                                           max_features = max(1, int(np.sqrt(self.n_features_)))
   292                                                       elif self.max_features == "log2":
   293                                                           max_features = max(1, int(np.log2(self.n_features_)))
   294                                                       else:
   295                                                           raise ValueError(
   296                                                               'Invalid value for max_features. Allowed string '
   297                                                               'values are "auto", "sqrt" or "log2".')
   298                                                   elif self.max_features is None:
   299                                                       max_features = self.n_features_
   300                                                   else:
   301                                                       max_features = self.max_features
   302
   303         1            6      6.0      0.0          if len(y) != n_samples:
   304                                                       raise ValueError("Number of labels=%d does not match "
   305                                                                        "number of samples=%d" % (len(y), n_samples))
   306         1            5      5.0      0.0          if self.min_samples_split &lt;= 0:
   307                                                       raise ValueError("min_samples_split must be greater than zero.")
   308         1            5      5.0      0.0          if self.min_samples_leaf &lt;= 0:
   309                                                       raise ValueError("min_samples_leaf must be greater than zero.")
   310         1            5      5.0      0.0          if max_depth &lt;= 0:
   311                                                       raise ValueError("max_depth must be greater than zero. ")
   312         1            6      6.0      0.0          if self.min_density &lt; 0.0 or self.min_density &gt; 1.0:
   313                                                       raise ValueError("min_density must be in [0, 1]")
   314         1            5      5.0      0.0          if not (0 &lt; max_features &lt;= self.n_features_):
   315                                                       raise ValueError("max_features must be in (0, n_features]")
   316
   317         1            5      5.0      0.0          if sample_mask is not None:
   318                                                       sample_mask = np.asarray(sample_mask, dtype=np.bool)
   319
   320                                                       if sample_mask.shape[0] != n_samples:
   321                                                           raise ValueError("Length of sample_mask=%d does not match "
   322                                                                            "number of samples=%d"
   323                                                                            % (sample_mask.shape[0], n_samples))
   324
   325         1            4      4.0      0.0          if sample_weight is not None:
   326                                                       if (getattr(sample_weight, "dtype", None) != DOUBLE or
   327                                                               not sample_weight.flags.contiguous):
   328                                                           sample_weight = np.ascontiguousarray(
   329                                                               sample_weight, dtype=DOUBLE)
   330                                                       if len(sample_weight.shape) &gt; 1:
   331                                                           raise ValueError("Sample weights array has more "
   332                                                                            "than one dimension: %d" %
   333                                                                            len(sample_weight.shape))
   334                                                       if len(sample_weight) != n_samples:
   335                                                           raise ValueError("Number of weights=%d does not match "
   336                                                                            "number of samples=%d" %
   337                                                                            (len(sample_weight), n_samples))
   338
   339         1            5      5.0      0.0          if X_argsorted is not None:
   340                                                       X_argsorted = np.asarray(X_argsorted, dtype=np.int32,
   341                                                                                order='F')
   342                                                       if X_argsorted.shape != X.shape:
   343                                                           raise ValueError("Shape of X_argsorted does not match "
   344                                                                            "the shape of X")
   345
   346                                                   # Set min_samples_split sensibly
   347         1            5      5.0      0.0          min_samples_split = max(self.min_samples_split,
   348         1            7      7.0      0.0                                  2 * self.min_samples_leaf)
   349
   350                                                   # Build tree
   351         1            5      5.0      0.0          self.tree_ = _tree.Tree(self.n_features_, self.n_classes_,
   352         1            5      5.0      0.0                                  self.n_outputs_, criterion, max_depth,
   353         1            4      4.0      0.0                                  min_samples_split, self.min_samples_leaf,
   354         1            5      5.0      0.0                                  self.min_density, max_features,
   355         1          110    110.0      0.0                                  self.find_split_, random_state)
   356
   357         1            6      6.0      0.0          self.tree_.build(X, y,
   358         1            4      4.0      0.0                           sample_weight=sample_weight,
   359         1            5      5.0      0.0                           sample_mask=sample_mask,
   360         1       636813 636813.0     95.1                           X_argsorted=X_argsorted)
   361
   362         1            8      8.0      0.0          if self.n_outputs_ == 1:
   363         1            7      7.0      0.0              self.n_classes_ = self.n_classes_[0]
   364         1            5      5.0      0.0              self.classes_ = self.classes_[0]
   365
   366                                                   # Compute importances
   367         1            5      5.0      0.0          if self.compute_importances:
   368                                                       self.feature_importances_ = \
   369                                                           self.tree_.compute_feature_importances()
   370
   371         1            5      5.0      0.0          return self</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>

        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; .
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/vb_tree.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="vb_svm.html">
        Previous
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>