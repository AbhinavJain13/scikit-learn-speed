

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Benchmarks for pls &mdash; Vbench performance benchmarks for scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.12-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Vbench performance benchmarks for scikit-learn" href="index.html" />
    <link rel="next" title="Benchmarks for semi_supervised" href="vb_semi_supervised.html" />
    <link rel="prev" title="Benchmarks for neighbors" href="vb_neighbors.html" />

  <!-- Reference the theme's stylesheet on the Google CDN -->
  <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/excite-bike/jquery-ui.css"
        type="text/css" rel="Stylesheet" />
 
  <!-- Reference jQuery and jQuery UI from the CDN. Remember
       that the order of these two elements is important -->
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js"></script>

<script type="text/javascript">
      $(function(){
        $(".profiler-output").accordion({collapsible: true, header: "p", active: false} );
      });
    </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="http://scikit-learn.org/">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="quick_start.html">Speed Quick Start</a></li>
            <li><a href="http://scikit-learn.org/dev/user_guide.html">User's Guide</a></li>
            <li><a href="http://scikit-learn.org/dev/developers/performance.html">Performance</a></li>
            <li><a href="http://github.com/scikit-learn/scikit-learn">Github</a></li>
            <li><a href="http://github.com/vene/scikit-learn-speed">Speed Github</a></li>
       </ul>
</div>
<!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
          <h3>Table Of Contents</h3>
          <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vb_cluster.html">Benchmarks for cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_covariance.html">Benchmarks for covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_decomposition.html">Benchmarks for decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_ensemble.html">Benchmarks for ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_gaussian_process.html">Benchmarks for gaussian_process</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_linear_model.html">Benchmarks for linear_model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_manifold.html">Benchmarks for manifold</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_mixture.html">Benchmarks for mixture</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_naive_bayes.html">Benchmarks for naive_bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_neighbors.html">Benchmarks for neighbors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Benchmarks for pls</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#cca-minimadelon">CCA-minimadelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cca-blobs">CCA-blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plscanonical-arcene">PLSCanonical-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plscanonical-blobs">PLSCanonical-blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plsregression-arcene">PLSRegression-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#plsregression-madelon">PLSRegression-madelon</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vb_semi_supervised.html">Benchmarks for semi_supervised</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_svm.html">Benchmarks for svm</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_tree.html">Benchmarks for tree</a></li>
</ul>

          <!--
	   <div class="rel rellarge">
	     
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  --
	<div class="rellink">
	<a href="vb_neighbors.html" title="Benchmarks for neighbors"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Benchmarks for n...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for neighbors
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="vb_semi_supervised.html" title="Benchmarks for semi_supervised"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Benchmarks for s...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for semi_supervised
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page --
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.12-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Benchmarks for pls</a><ul>
<li><a class="reference internal" href="#cca-minimadelon">CCA-minimadelon</a></li>
<li><a class="reference internal" href="#cca-blobs">CCA-blobs</a></li>
<li><a class="reference internal" href="#plscanonical-arcene">PLSCanonical-arcene</a></li>
<li><a class="reference internal" href="#plscanonical-blobs">PLSCanonical-blobs</a></li>
<li><a class="reference internal" href="#plsregression-arcene">PLSRegression-arcene</a></li>
<li><a class="reference internal" href="#plsregression-madelon">PLSRegression-madelon</a></li>
</ul>
</li>
</ul>

    
  -->
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="benchmarks-for-pls">
<h1>Benchmarks for pls<a class="headerlink" href="#benchmarks-for-pls" title="Permalink to this headline">¶</a></h1>
<div class="section" id="cca-minimadelon">
<h2>CCA-minimadelon<a class="headerlink" href="#cca-minimadelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">CCA</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;minimadelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">CCA</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/CCA-minimadelon-step0-timing.png" src="_images/CCA-minimadelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/CCA-minimadelon-step0-memory.png" src="_images/CCA-minimadelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         8343 function calls in 0.206 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.206    0.206 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.206    0.206 &lt;f&gt;:1(&lt;module&gt;)
     1    0.001    0.001    0.205    0.205 /tmp/vb_sklearn/sklearn/pls.py:221(fit)
     2    0.089    0.044    0.202    0.101 /tmp/vb_sklearn/sklearn/pls.py:18(_nipals_twoblocks_inner_loop)
  8023    0.095    0.000    0.095    0.000 {numpy.core._dotblas.dot}
     4    0.000    0.000    0.019    0.005 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:457(pinv)
     4    0.016    0.004    0.018    0.004 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:365(lstsq)
    14    0.002    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     1    0.001    0.001    0.001    0.001 /tmp/vb_sklearn/sklearn/pls.py:78(_center_scale_xy)
     4    0.000    0.000    0.001    0.000 {map}
     2    0.001    0.000    0.001    0.000 {method 'std' of 'numpy.ndarray' objects}
    28    0.001    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:253(inv)
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
    20    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     2    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     2    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}
    12    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     4    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1830(identity)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     4    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.generic' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    16    0.000    0.000    0.000    0.000 {getattr}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     2    0.000    0.000    0.000    0.000 {_warnings.warn}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
    16    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    20    0.000    0.000    0.000    0.000 {issubclass}
    12    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     7    0.000    0.000    0.000    0.000 {range}
     6    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     6    0.000    0.000    0.000    0.000 {hasattr}
     6    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    20    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     5    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
    19    0.000    0.000    0.000    0.000 {len}
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/pls.py
Function: fit at line 221
Total time: 0.221204 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   221                                               def fit(self, X, Y):
   222                                                   # copy since this will contains the residuals (deflated) matrices
   223         1            7      7.0      0.0          X, Y = check_arrays(X, Y, dtype=np.float, copy=self.copy,
   224         1          281    281.0      0.1                              sparse_format='dense')
   225
   226         1            5      5.0      0.0          if X.ndim != 2:
   227                                                       raise ValueError('X must be a 2D array')
   228         1            4      4.0      0.0          if Y.ndim == 1:
   229                                                       Y = Y.reshape((Y.size, 1))
   230         1            4      4.0      0.0          if Y.ndim != 2:
   231                                                       raise ValueError('Y must be a 1D or a 2D array')
   232
   233         1            5      5.0      0.0          n = X.shape[0]
   234         1            5      5.0      0.0          p = X.shape[1]
   235         1            4      4.0      0.0          q = Y.shape[1]
   236
   237         1            5      5.0      0.0          if n != Y.shape[0]:
   238                                                       raise ValueError(
   239                                                           'Incompatible shapes: X has %s samples, while Y '
   240                                                           'has %s' % (X.shape[0], Y.shape[0]))
   241         1            4      4.0      0.0          if self.n_components &lt; 1 or self.n_components &gt; p:
   242                                                       raise ValueError('invalid number of components')
   243         1            5      5.0      0.0          if self.algorithm not in ("svd", "nipals"):
   244                                                       raise ValueError("Got algorithm %s when only 'svd' "
   245                                                                        "and 'nipals' are known" % self.algorithm)
   246         1            4      4.0      0.0          if self.algorithm == "svd" and self.mode == "B":
   247                                                       raise ValueError('Incompatible configuration: mode B is not '
   248                                                                        'implemented with svd algorithm')
   249         1            5      5.0      0.0          if not self.deflation_mode in ["canonical", "regression"]:
   250                                                       raise ValueError('The deflation mode is unknown')
   251                                                   # Scale (in place)
   252                                                   X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_\
   253         1         1025   1025.0      0.5              = _center_scale_xy(X, Y, self.scale)
   254                                                   # Residuals (deflated) matrices
   255         1            5      5.0      0.0          Xk = X
   256         1            4      4.0      0.0          Yk = Y
   257                                                   # Results matrices
   258         1           11     11.0      0.0          self.x_scores_ = np.zeros((n, self.n_components))
   259         1            7      7.0      0.0          self.y_scores_ = np.zeros((n, self.n_components))
   260         1            8      8.0      0.0          self.x_weights_ = np.zeros((p, self.n_components))
   261         1           11     11.0      0.0          self.y_weights_ = np.zeros((q, self.n_components))
   262         1            8      8.0      0.0          self.x_loadings_ = np.zeros((p, self.n_components))
   263         1            6      6.0      0.0          self.y_loadings_ = np.zeros((q, self.n_components))
   264
   265                                                   # NIPALS algo: outer loop, over components
   266         3           17      5.7      0.0          for k in range(self.n_components):
   267                                                       #1) weights estimation (inner loop)
   268                                                       # -----------------------------------
   269         2            9      4.5      0.0              if self.algorithm == "nipals":
   270         2            8      4.0      0.0                  x_weights, y_weights = _nipals_twoblocks_inner_loop(
   271         2            9      4.5      0.0                      X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,
   272         2       217393 108696.5     98.3                      tol=self.tol, norm_y_weights=self.norm_y_weights)
   273                                                       elif self.algorithm == "svd":
   274                                                           x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)
   275                                                       # compute scores
   276         2           74     37.0      0.0              x_scores = np.dot(Xk, x_weights)
   277         2            9      4.5      0.0              if self.norm_y_weights:
   278         2           43     21.5      0.0                  y_ss = 1
   279                                                       else:
   280                                                           y_ss = np.dot(y_weights.T, y_weights)
   281         2           58     29.0      0.0              y_scores = np.dot(Yk, y_weights) / y_ss
   282                                                       # test for null variance
   283         2           90     45.0      0.0              if np.dot(x_scores.T, x_scores) &lt; np.finfo(np.double).eps:
   284                                                           warnings.warn('X scores are null at iteration %s' % k)
   285                                                       #2) Deflation (in place)
   286                                                       # ----------------------
   287                                                       # Possible memory footprint reduction may done here: in order to
   288                                                       # avoid the allocation of a data chunk for the rank-one
   289                                                       # approximations matrix which is then substracted to Xk, we suggest
   290                                                       # to perform a column-wise deflation.
   291                                                       #
   292                                                       # - regress Xk's on x_score
   293         2          157     78.5      0.1              x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)
   294                                                       # - substract rank-one approximations to obtain remainder matrix
   295         2          447    223.5      0.2              Xk -= np.dot(x_scores, x_loadings.T)
   296         2           14      7.0      0.0              if self.deflation_mode == "canonical":
   297                                                           # - regress Yk's on y_score, then substract rank-one approx.
   298         2           34     17.0      0.0                  y_loadings = (np.dot(Yk.T, y_scores)
   299         2           58     29.0      0.0                                / np.dot(y_scores.T, y_scores))
   300         2           74     37.0      0.0                  Yk -= np.dot(y_scores, y_loadings.T)
   301         2           12      6.0      0.0              if self.deflation_mode == "regression":
   302                                                           # - regress Yk's on x_score, then substract rank-one approx.
   303                                                           y_loadings = (np.dot(Yk.T, x_scores)
   304                                                                         / np.dot(x_scores.T, x_scores))
   305                                                           Yk -= np.dot(x_scores, y_loadings.T)
   306                                                       # 3) Store weights, scores and loadings # Notation:
   307         2           44     22.0      0.0              self.x_scores_[:, k] = x_scores.ravel()  # T
   308         2           26     13.0      0.0              self.y_scores_[:, k] = y_scores.ravel()  # U
   309         2           26     13.0      0.0              self.x_weights_[:, k] = x_weights.ravel()  # W
   310         2           22     11.0      0.0              self.y_weights_[:, k] = y_weights.ravel()  # C
   311         2           24     12.0      0.0              self.x_loadings_[:, k] = x_loadings.ravel()  # P
   312         2           22     11.0      0.0              self.y_loadings_[:, k] = y_loadings.ravel()  # Q
   313                                                   # Such that: X = TP' + Err and Y = UQ' + Err
   314
   315                                                   # 4) rotations from input space to transformed space (scores)
   316                                                   # T = X W(P'W)^-1 = XW* (W* : p x k matrix)
   317                                                   # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)
   318         1            5      5.0      0.0          self.x_rotations_ = np.dot(
   319         1            4      4.0      0.0              self.x_weights_,
   320         1          505    505.0      0.2              linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
   321         1            7      7.0      0.0          if Y.shape[1] &gt; 1:
   322         1            4      4.0      0.0              self.y_rotations_ = np.dot(
   323         1            5      5.0      0.0                  self.y_weights_,
   324         1          263    263.0      0.1                  linalg.inv(np.dot(self.y_loadings_.T, self.y_weights_)))
   325                                                   else:
   326                                                       self.y_rotations_ = np.ones(1)
   327
   328         1            5      5.0      0.0          if True or self.deflation_mode == "regression":
   329                                                       # Estimate regression coefficient
   330                                                       # Regress Y on T
   331                                                       # Y = TQ' + Err,
   332                                                       # Then express in function of X
   333                                                       # Y = X W(P'W)^-1Q' + Err = XB + Err
   334                                                       # =&gt; B = W*Q' (p x q)
   335         1          167    167.0      0.1              self.coefs = np.dot(self.x_rotations_, self.y_loadings_.T)
   336         1           90     90.0      0.0              self.coefs = (1. / self.x_std_.reshape((p, 1)) * self.coefs *
   337         1           52     52.0      0.0                            self.y_std_)
   338         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/pls.py
Function: transform at line 340
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   340                                               def transform(self, X, Y=None, copy=True):
   341                                                   """Apply the dimension reduction learned on the train data.
   342
   343                                                   Parameters
   344                                                   ----------
   345                                                   X : array-like of predictors, shape = [n_samples, p]
   346                                                       Training vectors, where n_samples in the number of samples and
   347                                                       p is the number of predictors.
   348
   349                                                   Y : array-like of response, shape = [n_samples, q], optional
   350                                                       Training vectors, where n_samples in the number of samples and
   351                                                       q is the number of response variables.
   352
   353                                                   copy : boolean
   354                                                       Whether to copy X and Y, or perform in-place normalization.
   355
   356                                                   Returns
   357                                                   -------
   358                                                   x_scores if Y is not given, (x_scores, y_scores) otherwise.
   359                                                   """
   360                                                   # Normalize
   361                                                   if copy:
   362                                                       Xc = (np.asarray(X) - self.x_mean_) / self.x_std_
   363                                                       if Y is not None:
   364                                                           Yc = (np.asarray(Y) - self.y_mean_) / self.y_std_
   365                                                   else:
   366                                                       X = np.asarray(X)
   367                                                       Xc -= self.x_mean_
   368                                                       Xc /= self.x_std_
   369                                                       if Y is not None:
   370                                                           Y = np.asarray(Y)
   371                                                           Yc -= self.y_mean_
   372                                                           Yc /= self.y_std_
   373                                                   # Apply rotation
   374                                                   x_scores = np.dot(Xc, self.x_rotations_)
   375                                                   if Y is not None:
   376                                                       y_scores = np.dot(Yc, self.y_rotations_)
   377                                                       return x_scores, y_scores
   378
   379                                                   return x_scores</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/CCA-minimadelon-step1-timing.png" src="_images/CCA-minimadelon-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/CCA-minimadelon-step1-memory.png" src="_images/CCA-minimadelon-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7 function calls in 0.001 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.001    0.001 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.001    0.001 /tmp/vb_sklearn/sklearn/pls.py:340(transform)
     1    0.000    0.000    0.000    0.000 {numpy.core._dotblas.dot}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/pls.py
Function: fit at line 221
Total time: 0.221204 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   221                                               def fit(self, X, Y):
   222                                                   # copy since this will contains the residuals (deflated) matrices
   223         1            7      7.0      0.0          X, Y = check_arrays(X, Y, dtype=np.float, copy=self.copy,
   224         1          281    281.0      0.1                              sparse_format='dense')
   225
   226         1            5      5.0      0.0          if X.ndim != 2:
   227                                                       raise ValueError('X must be a 2D array')
   228         1            4      4.0      0.0          if Y.ndim == 1:
   229                                                       Y = Y.reshape((Y.size, 1))
   230         1            4      4.0      0.0          if Y.ndim != 2:
   231                                                       raise ValueError('Y must be a 1D or a 2D array')
   232
   233         1            5      5.0      0.0          n = X.shape[0]
   234         1            5      5.0      0.0          p = X.shape[1]
   235         1            4      4.0      0.0          q = Y.shape[1]
   236
   237         1            5      5.0      0.0          if n != Y.shape[0]:
   238                                                       raise ValueError(
   239                                                           'Incompatible shapes: X has %s samples, while Y '
   240                                                           'has %s' % (X.shape[0], Y.shape[0]))
   241         1            4      4.0      0.0          if self.n_components &lt; 1 or self.n_components &gt; p:
   242                                                       raise ValueError('invalid number of components')
   243         1            5      5.0      0.0          if self.algorithm not in ("svd", "nipals"):
   244                                                       raise ValueError("Got algorithm %s when only 'svd' "
   245                                                                        "and 'nipals' are known" % self.algorithm)
   246         1            4      4.0      0.0          if self.algorithm == "svd" and self.mode == "B":
   247                                                       raise ValueError('Incompatible configuration: mode B is not '
   248                                                                        'implemented with svd algorithm')
   249         1            5      5.0      0.0          if not self.deflation_mode in ["canonical", "regression"]:
   250                                                       raise ValueError('The deflation mode is unknown')
   251                                                   # Scale (in place)
   252                                                   X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_\
   253         1         1025   1025.0      0.5              = _center_scale_xy(X, Y, self.scale)
   254                                                   # Residuals (deflated) matrices
   255         1            5      5.0      0.0          Xk = X
   256         1            4      4.0      0.0          Yk = Y
   257                                                   # Results matrices
   258         1           11     11.0      0.0          self.x_scores_ = np.zeros((n, self.n_components))
   259         1            7      7.0      0.0          self.y_scores_ = np.zeros((n, self.n_components))
   260         1            8      8.0      0.0          self.x_weights_ = np.zeros((p, self.n_components))
   261         1           11     11.0      0.0          self.y_weights_ = np.zeros((q, self.n_components))
   262         1            8      8.0      0.0          self.x_loadings_ = np.zeros((p, self.n_components))
   263         1            6      6.0      0.0          self.y_loadings_ = np.zeros((q, self.n_components))
   264
   265                                                   # NIPALS algo: outer loop, over components
   266         3           17      5.7      0.0          for k in range(self.n_components):
   267                                                       #1) weights estimation (inner loop)
   268                                                       # -----------------------------------
   269         2            9      4.5      0.0              if self.algorithm == "nipals":
   270         2            8      4.0      0.0                  x_weights, y_weights = _nipals_twoblocks_inner_loop(
   271         2            9      4.5      0.0                      X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,
   272         2       217393 108696.5     98.3                      tol=self.tol, norm_y_weights=self.norm_y_weights)
   273                                                       elif self.algorithm == "svd":
   274                                                           x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)
   275                                                       # compute scores
   276         2           74     37.0      0.0              x_scores = np.dot(Xk, x_weights)
   277         2            9      4.5      0.0              if self.norm_y_weights:
   278         2           43     21.5      0.0                  y_ss = 1
   279                                                       else:
   280                                                           y_ss = np.dot(y_weights.T, y_weights)
   281         2           58     29.0      0.0              y_scores = np.dot(Yk, y_weights) / y_ss
   282                                                       # test for null variance
   283         2           90     45.0      0.0              if np.dot(x_scores.T, x_scores) &lt; np.finfo(np.double).eps:
   284                                                           warnings.warn('X scores are null at iteration %s' % k)
   285                                                       #2) Deflation (in place)
   286                                                       # ----------------------
   287                                                       # Possible memory footprint reduction may done here: in order to
   288                                                       # avoid the allocation of a data chunk for the rank-one
   289                                                       # approximations matrix which is then substracted to Xk, we suggest
   290                                                       # to perform a column-wise deflation.
   291                                                       #
   292                                                       # - regress Xk's on x_score
   293         2          157     78.5      0.1              x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)
   294                                                       # - substract rank-one approximations to obtain remainder matrix
   295         2          447    223.5      0.2              Xk -= np.dot(x_scores, x_loadings.T)
   296         2           14      7.0      0.0              if self.deflation_mode == "canonical":
   297                                                           # - regress Yk's on y_score, then substract rank-one approx.
   298         2           34     17.0      0.0                  y_loadings = (np.dot(Yk.T, y_scores)
   299         2           58     29.0      0.0                                / np.dot(y_scores.T, y_scores))
   300         2           74     37.0      0.0                  Yk -= np.dot(y_scores, y_loadings.T)
   301         2           12      6.0      0.0              if self.deflation_mode == "regression":
   302                                                           # - regress Yk's on x_score, then substract rank-one approx.
   303                                                           y_loadings = (np.dot(Yk.T, x_scores)
   304                                                                         / np.dot(x_scores.T, x_scores))
   305                                                           Yk -= np.dot(x_scores, y_loadings.T)
   306                                                       # 3) Store weights, scores and loadings # Notation:
   307         2           44     22.0      0.0              self.x_scores_[:, k] = x_scores.ravel()  # T
   308         2           26     13.0      0.0              self.y_scores_[:, k] = y_scores.ravel()  # U
   309         2           26     13.0      0.0              self.x_weights_[:, k] = x_weights.ravel()  # W
   310         2           22     11.0      0.0              self.y_weights_[:, k] = y_weights.ravel()  # C
   311         2           24     12.0      0.0              self.x_loadings_[:, k] = x_loadings.ravel()  # P
   312         2           22     11.0      0.0              self.y_loadings_[:, k] = y_loadings.ravel()  # Q
   313                                                   # Such that: X = TP' + Err and Y = UQ' + Err
   314
   315                                                   # 4) rotations from input space to transformed space (scores)
   316                                                   # T = X W(P'W)^-1 = XW* (W* : p x k matrix)
   317                                                   # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)
   318         1            5      5.0      0.0          self.x_rotations_ = np.dot(
   319         1            4      4.0      0.0              self.x_weights_,
   320         1          505    505.0      0.2              linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
   321         1            7      7.0      0.0          if Y.shape[1] &gt; 1:
   322         1            4      4.0      0.0              self.y_rotations_ = np.dot(
   323         1            5      5.0      0.0                  self.y_weights_,
   324         1          263    263.0      0.1                  linalg.inv(np.dot(self.y_loadings_.T, self.y_weights_)))
   325                                                   else:
   326                                                       self.y_rotations_ = np.ones(1)
   327
   328         1            5      5.0      0.0          if True or self.deflation_mode == "regression":
   329                                                       # Estimate regression coefficient
   330                                                       # Regress Y on T
   331                                                       # Y = TQ' + Err,
   332                                                       # Then express in function of X
   333                                                       # Y = X W(P'W)^-1Q' + Err = XB + Err
   334                                                       # =&gt; B = W*Q' (p x q)
   335         1          167    167.0      0.1              self.coefs = np.dot(self.x_rotations_, self.y_loadings_.T)
   336         1           90     90.0      0.0              self.coefs = (1. / self.x_std_.reshape((p, 1)) * self.coefs *
   337         1           52     52.0      0.0                            self.y_std_)
   338         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/pls.py
Function: transform at line 340
Total time: 0.000658 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   340                                               def transform(self, X, Y=None, copy=True):
   341                                                   """Apply the dimension reduction learned on the train data.
   342
   343                                                   Parameters
   344                                                   ----------
   345                                                   X : array-like of predictors, shape = [n_samples, p]
   346                                                       Training vectors, where n_samples in the number of samples and
   347                                                       p is the number of predictors.
   348
   349                                                   Y : array-like of response, shape = [n_samples, q], optional
   350                                                       Training vectors, where n_samples in the number of samples and
   351                                                       q is the number of response variables.
   352
   353                                                   copy : boolean
   354                                                       Whether to copy X and Y, or perform in-place normalization.
   355
   356                                                   Returns
   357                                                   -------
   358                                                   x_scores if Y is not given, (x_scores, y_scores) otherwise.
   359                                                   """
   360                                                   # Normalize
   361         1            3      3.0      0.5          if copy:
   362         1          405    405.0     61.6              Xc = (np.asarray(X) - self.x_mean_) / self.x_std_
   363         1            3      3.0      0.5              if Y is not None:
   364                                                           Yc = (np.asarray(Y) - self.y_mean_) / self.y_std_
   365                                                   else:
   366                                                       X = np.asarray(X)
   367                                                       Xc -= self.x_mean_
   368                                                       Xc /= self.x_std_
   369                                                       if Y is not None:
   370                                                           Y = np.asarray(Y)
   371                                                           Yc -= self.y_mean_
   372                                                           Yc /= self.y_std_
   373                                                   # Apply rotation
   374         1          242    242.0     36.8          x_scores = np.dot(Xc, self.x_rotations_)
   375         1            3      3.0      0.5          if Y is not None:
   376                                                       y_scores = np.dot(Yc, self.y_rotations_)
   377                                                       return x_scores, y_scores
   378
   379         1            2      2.0      0.3          return x_scores</pre>
</div>
</div>
</div>
<div class="section" id="cca-blobs">
<h2>CCA-blobs<a class="headerlink" href="#cca-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">CCA</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">CCA</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/CCA-blobs-step0-timing.png" src="_images/CCA-blobs-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/CCA-blobs-step0-memory.png" src="_images/CCA-blobs-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>Traceback</p>
<div class="highlight-python"><pre>   Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 150, in run
    exec step in ns
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 260, in run
    mem_usages = magic_memit(ns, self.code, repeat=self.mem_repeat)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 672, in magic_memit
    raise RuntimeError('ERROR: all subprocesses exited unsuccessfully.'
RuntimeError: ERROR: all subprocesses exited unsuccessfully. Try again with the `-i` option.
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 293, in run
    prof.runcall(f)
  File "/sp/lib/python/cpython-2.7.2/lib/python2.7/cProfile.py", line 149, in runcall
    return func(*args, **kw)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 288, in f
    exec code in ns
  File "&lt;f&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 351, in run
    prof.runcall(f)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/line_profiler.py", line 137, in runcall
    return func(*args, **kw)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 348, in f
    exec code in ns
  File "&lt;f&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/CCA-blobs-step1-timing.png" src="_images/CCA-blobs-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/CCA-blobs-step1-memory.png" src="_images/CCA-blobs-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
</div>
<div class="section" id="plscanonical-arcene">
<h2>PLSCanonical-arcene<a class="headerlink" href="#plscanonical-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">PLSCanonical</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">PLSCanonical</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSCanonical-arcene-step0-timing.png" src="_images/PLSCanonical-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSCanonical-arcene-step0-memory.png" src="_images/PLSCanonical-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>Traceback</p>
<div class="highlight-python"><pre>   Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 150, in run
    exec step in ns
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 260, in run
    mem_usages = magic_memit(ns, self.code, repeat=self.mem_repeat)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 672, in magic_memit
    raise RuntimeError('ERROR: all subprocesses exited unsuccessfully.'
RuntimeError: ERROR: all subprocesses exited unsuccessfully. Try again with the `-i` option.
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 293, in run
    prof.runcall(f)
  File "/sp/lib/python/cpython-2.7.2/lib/python2.7/cProfile.py", line 149, in runcall
    return func(*args, **kw)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 288, in f
    exec code in ns
  File "&lt;f&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 351, in run
    prof.runcall(f)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/line_profiler.py", line 137, in runcall
    return func(*args, **kw)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 348, in f
    exec code in ns
  File "&lt;f&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSCanonical-arcene-step1-timing.png" src="_images/PLSCanonical-arcene-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSCanonical-arcene-step1-memory.png" src="_images/PLSCanonical-arcene-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
</div>
<div class="section" id="plscanonical-blobs">
<h2>PLSCanonical-blobs<a class="headerlink" href="#plscanonical-blobs" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">PLSCanonical</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;blobs&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">PLSCanonical</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSCanonical-blobs-step0-timing.png" src="_images/PLSCanonical-blobs-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSCanonical-blobs-step0-memory.png" src="_images/PLSCanonical-blobs-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>Traceback</p>
<div class="highlight-python"><pre>   Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 150, in run
    exec step in ns
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 260, in run
    mem_usages = magic_memit(ns, self.code, repeat=self.mem_repeat)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 672, in magic_memit
    raise RuntimeError('ERROR: all subprocesses exited unsuccessfully.'
RuntimeError: ERROR: all subprocesses exited unsuccessfully. Try again with the `-i` option.
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 293, in run
    prof.runcall(f)
  File "/sp/lib/python/cpython-2.7.2/lib/python2.7/cProfile.py", line 149, in runcall
    return func(*args, **kw)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 288, in f
    exec code in ns
  File "&lt;f&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs
Traceback (most recent call last):
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 351, in run
    prof.runcall(f)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/line_profiler.py", line 137, in runcall
    return func(*args, **kw)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py", line 348, in f
    exec code in ns
  File "&lt;f&gt;", line 1, in &lt;module&gt;
  File "/tmp/vb_sklearn/sklearn/pls.py", line 320, in fit
    linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py", line 287, in inv
    a1 = np.asarray_chkfinite(a)
  File "/home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py", line 590, in asarray_chkfinite
    "array must not contain infs or NaNs")
ValueError: array must not contain infs or NaNs</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSCanonical-blobs-step1-timing.png" src="_images/PLSCanonical-blobs-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSCanonical-blobs-step1-memory.png" src="_images/PLSCanonical-blobs-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
</div>
<div class="section" id="plsregression-arcene">
<h2>PLSRegression-arcene<a class="headerlink" href="#plsregression-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">PLSRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSRegression-arcene-step0-timing.png" src="_images/PLSRegression-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSRegression-arcene-step0-memory.png" src="_images/PLSRegression-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         143 function calls in 0.097 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.097    0.097 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.097    0.097 &lt;f&gt;:1(&lt;module&gt;)
     1    0.008    0.008    0.097    0.097 /tmp/vb_sklearn/sklearn/pls.py:221(fit)
     1    0.022    0.022    0.046    0.046 /tmp/vb_sklearn/sklearn/pls.py:78(_center_scale_xy)
    41    0.032    0.001    0.032    0.001 {numpy.core._dotblas.dot}
     2    0.020    0.010    0.020    0.010 {method 'std' of 'numpy.ndarray' objects}
     2    0.001    0.001    0.010    0.005 /tmp/vb_sklearn/sklearn/pls.py:18(_nipals_twoblocks_inner_loop)
     1    0.000    0.000    0.009    0.009 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     1    0.005    0.005    0.005    0.005 {method 'copy' of 'numpy.ndarray' objects}
     2    0.004    0.002    0.004    0.002 {method 'mean' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.003    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     2    0.003    0.001    0.003    0.001 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:253(inv)
     6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    12    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {getattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 {isinstance}
     2    0.000    0.000    0.000    0.000 {issubclass}
     5    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     3    0.000    0.000    0.000    0.000 {len}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/pls.py
Function: fit at line 221
Total time: 0.087214 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   221                                               def fit(self, X, Y):
   222                                                   # copy since this will contains the residuals (deflated) matrices
   223         1            7      7.0      0.0          X, Y = check_arrays(X, Y, dtype=np.float, copy=self.copy,
   224         1         5291   5291.0      6.1                              sparse_format='dense')
   225
   226         1            6      6.0      0.0          if X.ndim != 2:
   227                                                       raise ValueError('X must be a 2D array')
   228         1            4      4.0      0.0          if Y.ndim == 1:
   229         1           12     12.0      0.0              Y = Y.reshape((Y.size, 1))
   230         1            4      4.0      0.0          if Y.ndim != 2:
   231                                                       raise ValueError('Y must be a 1D or a 2D array')
   232
   233         1            6      6.0      0.0          n = X.shape[0]
   234         1            4      4.0      0.0          p = X.shape[1]
   235         1            5      5.0      0.0          q = Y.shape[1]
   236
   237         1            4      4.0      0.0          if n != Y.shape[0]:
   238                                                       raise ValueError(
   239                                                           'Incompatible shapes: X has %s samples, while Y '
   240                                                           'has %s' % (X.shape[0], Y.shape[0]))
   241         1            6      6.0      0.0          if self.n_components &lt; 1 or self.n_components &gt; p:
   242                                                       raise ValueError('invalid number of components')
   243         1            4      4.0      0.0          if self.algorithm not in ("svd", "nipals"):
   244                                                       raise ValueError("Got algorithm %s when only 'svd' "
   245                                                                        "and 'nipals' are known" % self.algorithm)
   246         1            4      4.0      0.0          if self.algorithm == "svd" and self.mode == "B":
   247                                                       raise ValueError('Incompatible configuration: mode B is not '
   248                                                                        'implemented with svd algorithm')
   249         1            4      4.0      0.0          if not self.deflation_mode in ["canonical", "regression"]:
   250                                                       raise ValueError('The deflation mode is unknown')
   251                                                   # Scale (in place)
   252                                                   X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_\
   253         1        39272  39272.0     45.0              = _center_scale_xy(X, Y, self.scale)
   254                                                   # Residuals (deflated) matrices
   255         1            5      5.0      0.0          Xk = X
   256         1            4      4.0      0.0          Yk = Y
   257                                                   # Results matrices
   258         1           15     15.0      0.0          self.x_scores_ = np.zeros((n, self.n_components))
   259         1            7      7.0      0.0          self.y_scores_ = np.zeros((n, self.n_components))
   260         1           33     33.0      0.0          self.x_weights_ = np.zeros((p, self.n_components))
   261         1            7      7.0      0.0          self.y_weights_ = np.zeros((q, self.n_components))
   262         1           36     36.0      0.0          self.x_loadings_ = np.zeros((p, self.n_components))
   263         1            8      8.0      0.0          self.y_loadings_ = np.zeros((q, self.n_components))
   264
   265                                                   # NIPALS algo: outer loop, over components
   266         3           22      7.3      0.0          for k in range(self.n_components):
   267                                                       #1) weights estimation (inner loop)
   268                                                       # -----------------------------------
   269         2            9      4.5      0.0              if self.algorithm == "nipals":
   270         2            9      4.5      0.0                  x_weights, y_weights = _nipals_twoblocks_inner_loop(
   271         2            8      4.0      0.0                      X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,
   272         2         9664   4832.0     11.1                      tol=self.tol, norm_y_weights=self.norm_y_weights)
   273                                                       elif self.algorithm == "svd":
   274                                                           x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)
   275                                                       # compute scores
   276         2         3560   1780.0      4.1              x_scores = np.dot(Xk, x_weights)
   277         2           15      7.5      0.0              if self.norm_y_weights:
   278                                                           y_ss = 1
   279                                                       else:
   280         2           38     19.0      0.0                  y_ss = np.dot(y_weights.T, y_weights)
   281         2           78     39.0      0.1              y_scores = np.dot(Yk, y_weights) / y_ss
   282                                                       # test for null variance
   283         2          118     59.0      0.1              if np.dot(x_scores.T, x_scores) &lt; np.finfo(np.double).eps:
   284                                                           warnings.warn('X scores are null at iteration %s' % k)
   285                                                       #2) Deflation (in place)
   286                                                       # ----------------------
   287                                                       # Possible memory footprint reduction may done here: in order to
   288                                                       # avoid the allocation of a data chunk for the rank-one
   289                                                       # approximations matrix which is then substracted to Xk, we suggest
   290                                                       # to perform a column-wise deflation.
   291                                                       #
   292                                                       # - regress Xk's on x_score
   293         2         5101   2550.5      5.8              x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)
   294                                                       # - substract rank-one approximations to obtain remainder matrix
   295         2        21544  10772.0     24.7              Xk -= np.dot(x_scores, x_loadings.T)
   296         2           18      9.0      0.0              if self.deflation_mode == "canonical":
   297                                                           # - regress Yk's on y_score, then substract rank-one approx.
   298                                                           y_loadings = (np.dot(Yk.T, y_scores)
   299                                                                         / np.dot(y_scores.T, y_scores))
   300                                                           Yk -= np.dot(y_scores, y_loadings.T)
   301         2           10      5.0      0.0              if self.deflation_mode == "regression":
   302                                                           # - regress Yk's on x_score, then substract rank-one approx.
   303         2           64     32.0      0.1                  y_loadings = (np.dot(Yk.T, x_scores)
   304         2           57     28.5      0.1                                / np.dot(x_scores.T, x_scores))
   305         2           40     20.0      0.0                  Yk -= np.dot(x_scores, y_loadings.T)
   306                                                       # 3) Store weights, scores and loadings # Notation:
   307         2           87     43.5      0.1              self.x_scores_[:, k] = x_scores.ravel()  # T
   308         2           29     14.5      0.0              self.y_scores_[:, k] = y_scores.ravel()  # U
   309         2          105     52.5      0.1              self.x_weights_[:, k] = x_weights.ravel()  # W
   310         2           26     13.0      0.0              self.y_weights_[:, k] = y_weights.ravel()  # C
   311         2          113     56.5      0.1              self.x_loadings_[:, k] = x_loadings.ravel()  # P
   312         2           25     12.5      0.0              self.y_loadings_[:, k] = y_loadings.ravel()  # Q
   313                                                   # Such that: X = TP' + Err and Y = UQ' + Err
   314
   315                                                   # 4) rotations from input space to transformed space (scores)
   316                                                   # T = X W(P'W)^-1 = XW* (W* : p x k matrix)
   317                                                   # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)
   318         1            5      5.0      0.0          self.x_rotations_ = np.dot(
   319         1            5      5.0      0.0              self.x_weights_,
   320         1         1267   1267.0      1.5              linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
   321         1            8      8.0      0.0          if Y.shape[1] &gt; 1:
   322                                                       self.y_rotations_ = np.dot(
   323                                                           self.y_weights_,
   324                                                           linalg.inv(np.dot(self.y_loadings_.T, self.y_weights_)))
   325                                                   else:
   326         1           31     31.0      0.0              self.y_rotations_ = np.ones(1)
   327
   328         1            5      5.0      0.0          if True or self.deflation_mode == "regression":
   329                                                       # Estimate regression coefficient
   330                                                       # Regress Y on T
   331                                                       # Y = TQ' + Err,
   332                                                       # Then express in function of X
   333                                                       # Y = X W(P'W)^-1Q' + Err = XB + Err
   334                                                       # =&gt; B = W*Q' (p x q)
   335         1           90     90.0      0.1              self.coefs = np.dot(self.x_rotations_, self.y_loadings_.T)
   336         1          255    255.0      0.3              self.coefs = (1. / self.x_std_.reshape((p, 1)) * self.coefs *
   337         1           56     56.0      0.1                            self.y_std_)
   338         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/pls.py
Function: transform at line 340
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   340                                               def transform(self, X, Y=None, copy=True):
   341                                                   """Apply the dimension reduction learned on the train data.
   342
   343                                                   Parameters
   344                                                   ----------
   345                                                   X : array-like of predictors, shape = [n_samples, p]
   346                                                       Training vectors, where n_samples in the number of samples and
   347                                                       p is the number of predictors.
   348
   349                                                   Y : array-like of response, shape = [n_samples, q], optional
   350                                                       Training vectors, where n_samples in the number of samples and
   351                                                       q is the number of response variables.
   352
   353                                                   copy : boolean
   354                                                       Whether to copy X and Y, or perform in-place normalization.
   355
   356                                                   Returns
   357                                                   -------
   358                                                   x_scores if Y is not given, (x_scores, y_scores) otherwise.
   359                                                   """
   360                                                   # Normalize
   361                                                   if copy:
   362                                                       Xc = (np.asarray(X) - self.x_mean_) / self.x_std_
   363                                                       if Y is not None:
   364                                                           Yc = (np.asarray(Y) - self.y_mean_) / self.y_std_
   365                                                   else:
   366                                                       X = np.asarray(X)
   367                                                       Xc -= self.x_mean_
   368                                                       Xc /= self.x_std_
   369                                                       if Y is not None:
   370                                                           Y = np.asarray(Y)
   371                                                           Yc -= self.y_mean_
   372                                                           Yc /= self.y_std_
   373                                                   # Apply rotation
   374                                                   x_scores = np.dot(Xc, self.x_rotations_)
   375                                                   if Y is not None:
   376                                                       y_scores = np.dot(Yc, self.y_rotations_)
   377                                                       return x_scores, y_scores
   378
   379                                                   return x_scores</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSRegression-arcene-step1-timing.png" src="_images/PLSRegression-arcene-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSRegression-arcene-step1-memory.png" src="_images/PLSRegression-arcene-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7 function calls in 0.029 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.029    0.029 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.029    0.029 &lt;f&gt;:1(&lt;module&gt;)
     1    0.022    0.022    0.029    0.029 /tmp/vb_sklearn/sklearn/pls.py:340(transform)
     1    0.007    0.007    0.007    0.007 {numpy.core._dotblas.dot}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/pls.py
Function: fit at line 221
Total time: 0.087214 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   221                                               def fit(self, X, Y):
   222                                                   # copy since this will contains the residuals (deflated) matrices
   223         1            7      7.0      0.0          X, Y = check_arrays(X, Y, dtype=np.float, copy=self.copy,
   224         1         5291   5291.0      6.1                              sparse_format='dense')
   225
   226         1            6      6.0      0.0          if X.ndim != 2:
   227                                                       raise ValueError('X must be a 2D array')
   228         1            4      4.0      0.0          if Y.ndim == 1:
   229         1           12     12.0      0.0              Y = Y.reshape((Y.size, 1))
   230         1            4      4.0      0.0          if Y.ndim != 2:
   231                                                       raise ValueError('Y must be a 1D or a 2D array')
   232
   233         1            6      6.0      0.0          n = X.shape[0]
   234         1            4      4.0      0.0          p = X.shape[1]
   235         1            5      5.0      0.0          q = Y.shape[1]
   236
   237         1            4      4.0      0.0          if n != Y.shape[0]:
   238                                                       raise ValueError(
   239                                                           'Incompatible shapes: X has %s samples, while Y '
   240                                                           'has %s' % (X.shape[0], Y.shape[0]))
   241         1            6      6.0      0.0          if self.n_components &lt; 1 or self.n_components &gt; p:
   242                                                       raise ValueError('invalid number of components')
   243         1            4      4.0      0.0          if self.algorithm not in ("svd", "nipals"):
   244                                                       raise ValueError("Got algorithm %s when only 'svd' "
   245                                                                        "and 'nipals' are known" % self.algorithm)
   246         1            4      4.0      0.0          if self.algorithm == "svd" and self.mode == "B":
   247                                                       raise ValueError('Incompatible configuration: mode B is not '
   248                                                                        'implemented with svd algorithm')
   249         1            4      4.0      0.0          if not self.deflation_mode in ["canonical", "regression"]:
   250                                                       raise ValueError('The deflation mode is unknown')
   251                                                   # Scale (in place)
   252                                                   X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_\
   253         1        39272  39272.0     45.0              = _center_scale_xy(X, Y, self.scale)
   254                                                   # Residuals (deflated) matrices
   255         1            5      5.0      0.0          Xk = X
   256         1            4      4.0      0.0          Yk = Y
   257                                                   # Results matrices
   258         1           15     15.0      0.0          self.x_scores_ = np.zeros((n, self.n_components))
   259         1            7      7.0      0.0          self.y_scores_ = np.zeros((n, self.n_components))
   260         1           33     33.0      0.0          self.x_weights_ = np.zeros((p, self.n_components))
   261         1            7      7.0      0.0          self.y_weights_ = np.zeros((q, self.n_components))
   262         1           36     36.0      0.0          self.x_loadings_ = np.zeros((p, self.n_components))
   263         1            8      8.0      0.0          self.y_loadings_ = np.zeros((q, self.n_components))
   264
   265                                                   # NIPALS algo: outer loop, over components
   266         3           22      7.3      0.0          for k in range(self.n_components):
   267                                                       #1) weights estimation (inner loop)
   268                                                       # -----------------------------------
   269         2            9      4.5      0.0              if self.algorithm == "nipals":
   270         2            9      4.5      0.0                  x_weights, y_weights = _nipals_twoblocks_inner_loop(
   271         2            8      4.0      0.0                      X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,
   272         2         9664   4832.0     11.1                      tol=self.tol, norm_y_weights=self.norm_y_weights)
   273                                                       elif self.algorithm == "svd":
   274                                                           x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)
   275                                                       # compute scores
   276         2         3560   1780.0      4.1              x_scores = np.dot(Xk, x_weights)
   277         2           15      7.5      0.0              if self.norm_y_weights:
   278                                                           y_ss = 1
   279                                                       else:
   280         2           38     19.0      0.0                  y_ss = np.dot(y_weights.T, y_weights)
   281         2           78     39.0      0.1              y_scores = np.dot(Yk, y_weights) / y_ss
   282                                                       # test for null variance
   283         2          118     59.0      0.1              if np.dot(x_scores.T, x_scores) &lt; np.finfo(np.double).eps:
   284                                                           warnings.warn('X scores are null at iteration %s' % k)
   285                                                       #2) Deflation (in place)
   286                                                       # ----------------------
   287                                                       # Possible memory footprint reduction may done here: in order to
   288                                                       # avoid the allocation of a data chunk for the rank-one
   289                                                       # approximations matrix which is then substracted to Xk, we suggest
   290                                                       # to perform a column-wise deflation.
   291                                                       #
   292                                                       # - regress Xk's on x_score
   293         2         5101   2550.5      5.8              x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)
   294                                                       # - substract rank-one approximations to obtain remainder matrix
   295         2        21544  10772.0     24.7              Xk -= np.dot(x_scores, x_loadings.T)
   296         2           18      9.0      0.0              if self.deflation_mode == "canonical":
   297                                                           # - regress Yk's on y_score, then substract rank-one approx.
   298                                                           y_loadings = (np.dot(Yk.T, y_scores)
   299                                                                         / np.dot(y_scores.T, y_scores))
   300                                                           Yk -= np.dot(y_scores, y_loadings.T)
   301         2           10      5.0      0.0              if self.deflation_mode == "regression":
   302                                                           # - regress Yk's on x_score, then substract rank-one approx.
   303         2           64     32.0      0.1                  y_loadings = (np.dot(Yk.T, x_scores)
   304         2           57     28.5      0.1                                / np.dot(x_scores.T, x_scores))
   305         2           40     20.0      0.0                  Yk -= np.dot(x_scores, y_loadings.T)
   306                                                       # 3) Store weights, scores and loadings # Notation:
   307         2           87     43.5      0.1              self.x_scores_[:, k] = x_scores.ravel()  # T
   308         2           29     14.5      0.0              self.y_scores_[:, k] = y_scores.ravel()  # U
   309         2          105     52.5      0.1              self.x_weights_[:, k] = x_weights.ravel()  # W
   310         2           26     13.0      0.0              self.y_weights_[:, k] = y_weights.ravel()  # C
   311         2          113     56.5      0.1              self.x_loadings_[:, k] = x_loadings.ravel()  # P
   312         2           25     12.5      0.0              self.y_loadings_[:, k] = y_loadings.ravel()  # Q
   313                                                   # Such that: X = TP' + Err and Y = UQ' + Err
   314
   315                                                   # 4) rotations from input space to transformed space (scores)
   316                                                   # T = X W(P'W)^-1 = XW* (W* : p x k matrix)
   317                                                   # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)
   318         1            5      5.0      0.0          self.x_rotations_ = np.dot(
   319         1            5      5.0      0.0              self.x_weights_,
   320         1         1267   1267.0      1.5              linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
   321         1            8      8.0      0.0          if Y.shape[1] &gt; 1:
   322                                                       self.y_rotations_ = np.dot(
   323                                                           self.y_weights_,
   324                                                           linalg.inv(np.dot(self.y_loadings_.T, self.y_weights_)))
   325                                                   else:
   326         1           31     31.0      0.0              self.y_rotations_ = np.ones(1)
   327
   328         1            5      5.0      0.0          if True or self.deflation_mode == "regression":
   329                                                       # Estimate regression coefficient
   330                                                       # Regress Y on T
   331                                                       # Y = TQ' + Err,
   332                                                       # Then express in function of X
   333                                                       # Y = X W(P'W)^-1Q' + Err = XB + Err
   334                                                       # =&gt; B = W*Q' (p x q)
   335         1           90     90.0      0.1              self.coefs = np.dot(self.x_rotations_, self.y_loadings_.T)
   336         1          255    255.0      0.3              self.coefs = (1. / self.x_std_.reshape((p, 1)) * self.coefs *
   337         1           56     56.0      0.1                            self.y_std_)
   338         1            4      4.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/pls.py
Function: transform at line 340
Total time: 0.028884 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   340                                               def transform(self, X, Y=None, copy=True):
   341                                                   """Apply the dimension reduction learned on the train data.
   342
   343                                                   Parameters
   344                                                   ----------
   345                                                   X : array-like of predictors, shape = [n_samples, p]
   346                                                       Training vectors, where n_samples in the number of samples and
   347                                                       p is the number of predictors.
   348
   349                                                   Y : array-like of response, shape = [n_samples, q], optional
   350                                                       Training vectors, where n_samples in the number of samples and
   351                                                       q is the number of response variables.
   352
   353                                                   copy : boolean
   354                                                       Whether to copy X and Y, or perform in-place normalization.
   355
   356                                                   Returns
   357                                                   -------
   358                                                   x_scores if Y is not given, (x_scores, y_scores) otherwise.
   359                                                   """
   360                                                   # Normalize
   361         1            4      4.0      0.0          if copy:
   362         1        22093  22093.0     76.5              Xc = (np.asarray(X) - self.x_mean_) / self.x_std_
   363         1            4      4.0      0.0              if Y is not None:
   364                                                           Yc = (np.asarray(Y) - self.y_mean_) / self.y_std_
   365                                                   else:
   366                                                       X = np.asarray(X)
   367                                                       Xc -= self.x_mean_
   368                                                       Xc /= self.x_std_
   369                                                       if Y is not None:
   370                                                           Y = np.asarray(Y)
   371                                                           Yc -= self.y_mean_
   372                                                           Yc /= self.y_std_
   373                                                   # Apply rotation
   374         1         6776   6776.0     23.5          x_scores = np.dot(Xc, self.x_rotations_)
   375         1            4      4.0      0.0          if Y is not None:
   376                                                       y_scores = np.dot(Yc, self.y_rotations_)
   377                                                       return x_scores, y_scores
   378
   379         1            3      3.0      0.0          return x_scores</pre>
</div>
</div>
</div>
<div class="section" id="plsregression-madelon">
<h2>PLSRegression-madelon<a class="headerlink" href="#plsregression-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.pls</span> <span class="kn">import</span> <span class="n">PLSRegression</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSRegression-madelon-step0-timing.png" src="_images/PLSRegression-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSRegression-madelon-step0-memory.png" src="_images/PLSRegression-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         143 function calls in 0.105 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.105    0.105 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.105    0.105 &lt;f&gt;:1(&lt;module&gt;)
     1    0.006    0.006    0.105    0.105 /tmp/vb_sklearn/sklearn/pls.py:221(fit)
     1    0.013    0.013    0.073    0.073 /tmp/vb_sklearn/sklearn/pls.py:78(_center_scale_xy)
     2    0.043    0.022    0.043    0.022 {method 'std' of 'numpy.ndarray' objects}
    41    0.020    0.000    0.020    0.000 {numpy.core._dotblas.dot}
     2    0.017    0.009    0.017    0.009 {method 'mean' of 'numpy.ndarray' objects}
     2    0.001    0.000    0.006    0.003 /tmp/vb_sklearn/sklearn/pls.py:18(_nipals_twoblocks_inner_loop)
     1    0.000    0.000    0.005    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     1    0.003    0.003    0.003    0.003 {method 'copy' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.002    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
     2    0.002    0.001    0.002    0.001 {method 'sum' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/basic.py:253(inv)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:60(get_lapack_funcs)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:526(asarray_chkfinite)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     3    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/getlimits.py:91(__new__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:45(find_best_lapack_type)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     6    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     6    0.000    0.000    0.000    0.000 {hasattr}
    12    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/lapack.py:23(cast_to_lapack_prefix)
     4    0.000    0.000    0.000    0.000 {getattr}
     2    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     2    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 {issubclass}
     1    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     5    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 {isinstance}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/linalg/misc.py:22(_datacopied)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
     3    0.000    0.000    0.000    0.000 {len}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/pls.py
Function: fit at line 221
Total time: 0.09993 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   221                                               def fit(self, X, Y):
   222                                                   # copy since this will contains the residuals (deflated) matrices
   223         1            4      4.0      0.0          X, Y = check_arrays(X, Y, dtype=np.float, copy=self.copy,
   224         1         3489   3489.0      3.5                              sparse_format='dense')
   225
   226         1            4      4.0      0.0          if X.ndim != 2:
   227                                                       raise ValueError('X must be a 2D array')
   228         1            5      5.0      0.0          if Y.ndim == 1:
   229         1            9      9.0      0.0              Y = Y.reshape((Y.size, 1))
   230         1            2      2.0      0.0          if Y.ndim != 2:
   231                                                       raise ValueError('Y must be a 1D or a 2D array')
   232
   233         1            2      2.0      0.0          n = X.shape[0]
   234         1            3      3.0      0.0          p = X.shape[1]
   235         1            2      2.0      0.0          q = Y.shape[1]
   236
   237         1            2      2.0      0.0          if n != Y.shape[0]:
   238                                                       raise ValueError(
   239                                                           'Incompatible shapes: X has %s samples, while Y '
   240                                                           'has %s' % (X.shape[0], Y.shape[0]))
   241         1            4      4.0      0.0          if self.n_components &lt; 1 or self.n_components &gt; p:
   242                                                       raise ValueError('invalid number of components')
   243         1            3      3.0      0.0          if self.algorithm not in ("svd", "nipals"):
   244                                                       raise ValueError("Got algorithm %s when only 'svd' "
   245                                                                        "and 'nipals' are known" % self.algorithm)
   246         1            2      2.0      0.0          if self.algorithm == "svd" and self.mode == "B":
   247                                                       raise ValueError('Incompatible configuration: mode B is not '
   248                                                                        'implemented with svd algorithm')
   249         1            3      3.0      0.0          if not self.deflation_mode in ["canonical", "regression"]:
   250                                                       raise ValueError('The deflation mode is unknown')
   251                                                   # Scale (in place)
   252                                                   X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_\
   253         1        69820  69820.0     69.9              = _center_scale_xy(X, Y, self.scale)
   254                                                   # Residuals (deflated) matrices
   255         1            4      4.0      0.0          Xk = X
   256         1            2      2.0      0.0          Yk = Y
   257                                                   # Results matrices
   258         1           33     33.0      0.0          self.x_scores_ = np.zeros((n, self.n_components))
   259         1            7      7.0      0.0          self.y_scores_ = np.zeros((n, self.n_components))
   260         1            6      6.0      0.0          self.x_weights_ = np.zeros((p, self.n_components))
   261         1            3      3.0      0.0          self.y_weights_ = np.zeros((q, self.n_components))
   262         1            5      5.0      0.0          self.x_loadings_ = np.zeros((p, self.n_components))
   263         1            5      5.0      0.0          self.y_loadings_ = np.zeros((q, self.n_components))
   264
   265                                                   # NIPALS algo: outer loop, over components
   266         3           15      5.0      0.0          for k in range(self.n_components):
   267                                                       #1) weights estimation (inner loop)
   268                                                       # -----------------------------------
   269         2            6      3.0      0.0              if self.algorithm == "nipals":
   270         2            5      2.5      0.0                  x_weights, y_weights = _nipals_twoblocks_inner_loop(
   271         2            4      2.0      0.0                      X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,
   272         2         5916   2958.0      5.9                      tol=self.tol, norm_y_weights=self.norm_y_weights)
   273                                                       elif self.algorithm == "svd":
   274                                                           x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)
   275                                                       # compute scores
   276         2         2165   1082.5      2.2              x_scores = np.dot(Xk, x_weights)
   277         2            9      4.5      0.0              if self.norm_y_weights:
   278                                                           y_ss = 1
   279                                                       else:
   280         2           26     13.0      0.0                  y_ss = np.dot(y_weights.T, y_weights)
   281         2          102     51.0      0.1              y_scores = np.dot(Yk, y_weights) / y_ss
   282                                                       # test for null variance
   283         2           85     42.5      0.1              if np.dot(x_scores.T, x_scores) &lt; np.finfo(np.double).eps:
   284                                                           warnings.warn('X scores are null at iteration %s' % k)
   285                                                       #2) Deflation (in place)
   286                                                       # ----------------------
   287                                                       # Possible memory footprint reduction may done here: in order to
   288                                                       # avoid the allocation of a data chunk for the rank-one
   289                                                       # approximations matrix which is then substracted to Xk, we suggest
   290                                                       # to perform a column-wise deflation.
   291                                                       #
   292                                                       # - regress Xk's on x_score
   293         2         2752   1376.0      2.8              x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)
   294                                                       # - substract rank-one approximations to obtain remainder matrix
   295         2        14508   7254.0     14.5              Xk -= np.dot(x_scores, x_loadings.T)
   296         2           13      6.5      0.0              if self.deflation_mode == "canonical":
   297                                                           # - regress Yk's on y_score, then substract rank-one approx.
   298                                                           y_loadings = (np.dot(Yk.T, y_scores)
   299                                                                         / np.dot(y_scores.T, y_scores))
   300                                                           Yk -= np.dot(y_scores, y_loadings.T)
   301         2            5      2.5      0.0              if self.deflation_mode == "regression":
   302                                                           # - regress Yk's on x_score, then substract rank-one approx.
   303         2           54     27.0      0.1                  y_loadings = (np.dot(Yk.T, x_scores)
   304         2           45     22.5      0.0                                / np.dot(x_scores.T, x_scores))
   305         2           44     22.0      0.0                  Yk -= np.dot(x_scores, y_loadings.T)
   306                                                       # 3) Store weights, scores and loadings # Notation:
   307         2           89     44.5      0.1              self.x_scores_[:, k] = x_scores.ravel()  # T
   308         2           35     17.5      0.0              self.y_scores_[:, k] = y_scores.ravel()  # U
   309         2           21     10.5      0.0              self.x_weights_[:, k] = x_weights.ravel()  # W
   310         2           14      7.0      0.0              self.y_weights_[:, k] = y_weights.ravel()  # C
   311         2           21     10.5      0.0              self.x_loadings_[:, k] = x_loadings.ravel()  # P
   312         2           14      7.0      0.0              self.y_loadings_[:, k] = y_loadings.ravel()  # Q
   313                                                   # Such that: X = TP' + Err and Y = UQ' + Err
   314
   315                                                   # 4) rotations from input space to transformed space (scores)
   316                                                   # T = X W(P'W)^-1 = XW* (W* : p x k matrix)
   317                                                   # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)
   318         1            3      3.0      0.0          self.x_rotations_ = np.dot(
   319         1            2      2.0      0.0              self.x_weights_,
   320         1          465    465.0      0.5              linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
   321         1            4      4.0      0.0          if Y.shape[1] &gt; 1:
   322                                                       self.y_rotations_ = np.dot(
   323                                                           self.y_weights_,
   324                                                           linalg.inv(np.dot(self.y_loadings_.T, self.y_weights_)))
   325                                                   else:
   326         1           21     21.0      0.0              self.y_rotations_ = np.ones(1)
   327
   328         1            3      3.0      0.0          if True or self.deflation_mode == "regression":
   329                                                       # Estimate regression coefficient
   330                                                       # Regress Y on T
   331                                                       # Y = TQ' + Err,
   332                                                       # Then express in function of X
   333                                                       # Y = X W(P'W)^-1Q' + Err = XB + Err
   334                                                       # =&gt; B = W*Q' (p x q)
   335         1           16     16.0      0.0              self.coefs = np.dot(self.x_rotations_, self.y_loadings_.T)
   336         1           29     29.0      0.0              self.coefs = (1. / self.x_std_.reshape((p, 1)) * self.coefs *
   337         1           18     18.0      0.0                            self.y_std_)
   338         1            2      2.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/pls.py
Function: transform at line 340
Total time: 0 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   340                                               def transform(self, X, Y=None, copy=True):
   341                                                   """Apply the dimension reduction learned on the train data.
   342
   343                                                   Parameters
   344                                                   ----------
   345                                                   X : array-like of predictors, shape = [n_samples, p]
   346                                                       Training vectors, where n_samples in the number of samples and
   347                                                       p is the number of predictors.
   348
   349                                                   Y : array-like of response, shape = [n_samples, q], optional
   350                                                       Training vectors, where n_samples in the number of samples and
   351                                                       q is the number of response variables.
   352
   353                                                   copy : boolean
   354                                                       Whether to copy X and Y, or perform in-place normalization.
   355
   356                                                   Returns
   357                                                   -------
   358                                                   x_scores if Y is not given, (x_scores, y_scores) otherwise.
   359                                                   """
   360                                                   # Normalize
   361                                                   if copy:
   362                                                       Xc = (np.asarray(X) - self.x_mean_) / self.x_std_
   363                                                       if Y is not None:
   364                                                           Yc = (np.asarray(Y) - self.y_mean_) / self.y_std_
   365                                                   else:
   366                                                       X = np.asarray(X)
   367                                                       Xc -= self.x_mean_
   368                                                       Xc /= self.x_std_
   369                                                       if Y is not None:
   370                                                           Y = np.asarray(Y)
   371                                                           Yc -= self.y_mean_
   372                                                           Yc /= self.y_std_
   373                                                   # Apply rotation
   374                                                   x_scores = np.dot(Xc, self.x_rotations_)
   375                                                   if Y is not None:
   376                                                       y_scores = np.dot(Yc, self.y_rotations_)
   377                                                       return x_scores, y_scores
   378
   379                                                   return x_scores</pre>
</div>
</div>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/PLSRegression-madelon-step1-timing.png" src="_images/PLSRegression-madelon-step1-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/PLSRegression-madelon-step1-memory.png" src="_images/PLSRegression-madelon-step1-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         7 function calls in 0.018 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.018    0.018 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.018    0.018 &lt;f&gt;:1(&lt;module&gt;)
     1    0.014    0.014    0.018    0.018 /tmp/vb_sklearn/sklearn/pls.py:340(transform)
     1    0.004    0.004    0.004    0.004 {numpy.core._dotblas.dot}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.array}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/pls.py
Function: fit at line 221
Total time: 0.09993 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   221                                               def fit(self, X, Y):
   222                                                   # copy since this will contains the residuals (deflated) matrices
   223         1            4      4.0      0.0          X, Y = check_arrays(X, Y, dtype=np.float, copy=self.copy,
   224         1         3489   3489.0      3.5                              sparse_format='dense')
   225
   226         1            4      4.0      0.0          if X.ndim != 2:
   227                                                       raise ValueError('X must be a 2D array')
   228         1            5      5.0      0.0          if Y.ndim == 1:
   229         1            9      9.0      0.0              Y = Y.reshape((Y.size, 1))
   230         1            2      2.0      0.0          if Y.ndim != 2:
   231                                                       raise ValueError('Y must be a 1D or a 2D array')
   232
   233         1            2      2.0      0.0          n = X.shape[0]
   234         1            3      3.0      0.0          p = X.shape[1]
   235         1            2      2.0      0.0          q = Y.shape[1]
   236
   237         1            2      2.0      0.0          if n != Y.shape[0]:
   238                                                       raise ValueError(
   239                                                           'Incompatible shapes: X has %s samples, while Y '
   240                                                           'has %s' % (X.shape[0], Y.shape[0]))
   241         1            4      4.0      0.0          if self.n_components &lt; 1 or self.n_components &gt; p:
   242                                                       raise ValueError('invalid number of components')
   243         1            3      3.0      0.0          if self.algorithm not in ("svd", "nipals"):
   244                                                       raise ValueError("Got algorithm %s when only 'svd' "
   245                                                                        "and 'nipals' are known" % self.algorithm)
   246         1            2      2.0      0.0          if self.algorithm == "svd" and self.mode == "B":
   247                                                       raise ValueError('Incompatible configuration: mode B is not '
   248                                                                        'implemented with svd algorithm')
   249         1            3      3.0      0.0          if not self.deflation_mode in ["canonical", "regression"]:
   250                                                       raise ValueError('The deflation mode is unknown')
   251                                                   # Scale (in place)
   252                                                   X, Y, self.x_mean_, self.y_mean_, self.x_std_, self.y_std_\
   253         1        69820  69820.0     69.9              = _center_scale_xy(X, Y, self.scale)
   254                                                   # Residuals (deflated) matrices
   255         1            4      4.0      0.0          Xk = X
   256         1            2      2.0      0.0          Yk = Y
   257                                                   # Results matrices
   258         1           33     33.0      0.0          self.x_scores_ = np.zeros((n, self.n_components))
   259         1            7      7.0      0.0          self.y_scores_ = np.zeros((n, self.n_components))
   260         1            6      6.0      0.0          self.x_weights_ = np.zeros((p, self.n_components))
   261         1            3      3.0      0.0          self.y_weights_ = np.zeros((q, self.n_components))
   262         1            5      5.0      0.0          self.x_loadings_ = np.zeros((p, self.n_components))
   263         1            5      5.0      0.0          self.y_loadings_ = np.zeros((q, self.n_components))
   264
   265                                                   # NIPALS algo: outer loop, over components
   266         3           15      5.0      0.0          for k in range(self.n_components):
   267                                                       #1) weights estimation (inner loop)
   268                                                       # -----------------------------------
   269         2            6      3.0      0.0              if self.algorithm == "nipals":
   270         2            5      2.5      0.0                  x_weights, y_weights = _nipals_twoblocks_inner_loop(
   271         2            4      2.0      0.0                      X=Xk, Y=Yk, mode=self.mode, max_iter=self.max_iter,
   272         2         5916   2958.0      5.9                      tol=self.tol, norm_y_weights=self.norm_y_weights)
   273                                                       elif self.algorithm == "svd":
   274                                                           x_weights, y_weights = _svd_cross_product(X=Xk, Y=Yk)
   275                                                       # compute scores
   276         2         2165   1082.5      2.2              x_scores = np.dot(Xk, x_weights)
   277         2            9      4.5      0.0              if self.norm_y_weights:
   278                                                           y_ss = 1
   279                                                       else:
   280         2           26     13.0      0.0                  y_ss = np.dot(y_weights.T, y_weights)
   281         2          102     51.0      0.1              y_scores = np.dot(Yk, y_weights) / y_ss
   282                                                       # test for null variance
   283         2           85     42.5      0.1              if np.dot(x_scores.T, x_scores) &lt; np.finfo(np.double).eps:
   284                                                           warnings.warn('X scores are null at iteration %s' % k)
   285                                                       #2) Deflation (in place)
   286                                                       # ----------------------
   287                                                       # Possible memory footprint reduction may done here: in order to
   288                                                       # avoid the allocation of a data chunk for the rank-one
   289                                                       # approximations matrix which is then substracted to Xk, we suggest
   290                                                       # to perform a column-wise deflation.
   291                                                       #
   292                                                       # - regress Xk's on x_score
   293         2         2752   1376.0      2.8              x_loadings = np.dot(Xk.T, x_scores) / np.dot(x_scores.T, x_scores)
   294                                                       # - substract rank-one approximations to obtain remainder matrix
   295         2        14508   7254.0     14.5              Xk -= np.dot(x_scores, x_loadings.T)
   296         2           13      6.5      0.0              if self.deflation_mode == "canonical":
   297                                                           # - regress Yk's on y_score, then substract rank-one approx.
   298                                                           y_loadings = (np.dot(Yk.T, y_scores)
   299                                                                         / np.dot(y_scores.T, y_scores))
   300                                                           Yk -= np.dot(y_scores, y_loadings.T)
   301         2            5      2.5      0.0              if self.deflation_mode == "regression":
   302                                                           # - regress Yk's on x_score, then substract rank-one approx.
   303         2           54     27.0      0.1                  y_loadings = (np.dot(Yk.T, x_scores)
   304         2           45     22.5      0.0                                / np.dot(x_scores.T, x_scores))
   305         2           44     22.0      0.0                  Yk -= np.dot(x_scores, y_loadings.T)
   306                                                       # 3) Store weights, scores and loadings # Notation:
   307         2           89     44.5      0.1              self.x_scores_[:, k] = x_scores.ravel()  # T
   308         2           35     17.5      0.0              self.y_scores_[:, k] = y_scores.ravel()  # U
   309         2           21     10.5      0.0              self.x_weights_[:, k] = x_weights.ravel()  # W
   310         2           14      7.0      0.0              self.y_weights_[:, k] = y_weights.ravel()  # C
   311         2           21     10.5      0.0              self.x_loadings_[:, k] = x_loadings.ravel()  # P
   312         2           14      7.0      0.0              self.y_loadings_[:, k] = y_loadings.ravel()  # Q
   313                                                   # Such that: X = TP' + Err and Y = UQ' + Err
   314
   315                                                   # 4) rotations from input space to transformed space (scores)
   316                                                   # T = X W(P'W)^-1 = XW* (W* : p x k matrix)
   317                                                   # U = Y C(Q'C)^-1 = YC* (W* : q x k matrix)
   318         1            3      3.0      0.0          self.x_rotations_ = np.dot(
   319         1            2      2.0      0.0              self.x_weights_,
   320         1          465    465.0      0.5              linalg.inv(np.dot(self.x_loadings_.T, self.x_weights_)))
   321         1            4      4.0      0.0          if Y.shape[1] &gt; 1:
   322                                                       self.y_rotations_ = np.dot(
   323                                                           self.y_weights_,
   324                                                           linalg.inv(np.dot(self.y_loadings_.T, self.y_weights_)))
   325                                                   else:
   326         1           21     21.0      0.0              self.y_rotations_ = np.ones(1)
   327
   328         1            3      3.0      0.0          if True or self.deflation_mode == "regression":
   329                                                       # Estimate regression coefficient
   330                                                       # Regress Y on T
   331                                                       # Y = TQ' + Err,
   332                                                       # Then express in function of X
   333                                                       # Y = X W(P'W)^-1Q' + Err = XB + Err
   334                                                       # =&gt; B = W*Q' (p x q)
   335         1           16     16.0      0.0              self.coefs = np.dot(self.x_rotations_, self.y_loadings_.T)
   336         1           29     29.0      0.0              self.coefs = (1. / self.x_std_.reshape((p, 1)) * self.coefs *
   337         1           18     18.0      0.0                            self.y_std_)
   338         1            2      2.0      0.0          return self

File: /tmp/vb_sklearn/sklearn/pls.py
Function: transform at line 340
Total time: 0.043264 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   340                                               def transform(self, X, Y=None, copy=True):
   341                                                   """Apply the dimension reduction learned on the train data.
   342
   343                                                   Parameters
   344                                                   ----------
   345                                                   X : array-like of predictors, shape = [n_samples, p]
   346                                                       Training vectors, where n_samples in the number of samples and
   347                                                       p is the number of predictors.
   348
   349                                                   Y : array-like of response, shape = [n_samples, q], optional
   350                                                       Training vectors, where n_samples in the number of samples and
   351                                                       q is the number of response variables.
   352
   353                                                   copy : boolean
   354                                                       Whether to copy X and Y, or perform in-place normalization.
   355
   356                                                   Returns
   357                                                   -------
   358                                                   x_scores if Y is not given, (x_scores, y_scores) otherwise.
   359                                                   """
   360                                                   # Normalize
   361         1            2      2.0      0.0          if copy:
   362         1        13921  13921.0     32.2              Xc = (np.asarray(X) - self.x_mean_) / self.x_std_
   363         1            3      3.0      0.0              if Y is not None:
   364                                                           Yc = (np.asarray(Y) - self.y_mean_) / self.y_std_
   365                                                   else:
   366                                                       X = np.asarray(X)
   367                                                       Xc -= self.x_mean_
   368                                                       Xc /= self.x_std_
   369                                                       if Y is not None:
   370                                                           Y = np.asarray(Y)
   371                                                           Yc -= self.y_mean_
   372                                                           Yc /= self.y_std_
   373                                                   # Apply rotation
   374         1        29333  29333.0     67.8          x_scores = np.dot(Xc, self.x_rotations_)
   375         1            3      3.0      0.0          if Y is not None:
   376                                                       y_scores = np.dot(Yc, self.y_rotations_)
   377                                                       return x_scores, y_scores
   378
   379         1            2      2.0      0.0          return x_scores</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>

        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; .
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/vb_pls.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="vb_neighbors.html">
        Previous
      </a>  
    </div>
    <div class="buttonNext">
      <a href="vb_semi_supervised.html">
        Next
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>