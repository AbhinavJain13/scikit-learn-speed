

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Benchmarks for ensemble &mdash; Vbench performance benchmarks for scikit-learn</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.12-git',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="top" title="Vbench performance benchmarks for scikit-learn" href="index.html" />
    <link rel="next" title="Benchmarks for gaussian_process" href="vb_gaussian_process.html" />
    <link rel="prev" title="Benchmarks for decomposition" href="vb_decomposition.html" />

  <!-- Reference the theme's stylesheet on the Google CDN -->
  <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/excite-bike/jquery-ui.css"
        type="text/css" rel="Stylesheet" />
 
  <!-- Reference jQuery and jQuery UI from the CDN. Remember
       that the order of these two elements is important -->
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js"></script>

<script type="text/javascript">
      $(function(){
        $(".profiler-output").accordion({collapsible: true, header: "p", active: false} );
      });
    </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22606712-2']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

  </head>
  <body>

    <div class="header-wrapper">
      <div class="header">
          <p class="logo"><a href="http://scikit-learn.org/">
            <img src="_static/scikit-learn-logo-small.png" alt="Logo"/>
          </a>
          </p><div class="navbar">
          <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="quick_start.html">Speed Quick Start</a></li>
            <li><a href="http://scikit-learn.org/dev/user_guide.html">User's Guide</a></li>
            <li><a href="http://scikit-learn.org/dev/developers/performance.html">Performance</a></li>
            <li><a href="http://github.com/scikit-learn/scikit-learn">Github</a></li>
            <li><a href="http://github.com/vene/scikit-learn-speed">Speed Github</a></li>
       </ul>
</div>
<!-- end navbar --></div>
    </div>

    <div class="content-wrapper">

      <div class="sphinxsidebar">
	<div class="sphinxsidebarwrapper">
          <h3>Table Of Contents</h3>
          <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vb_cluster.html">Benchmarks for cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_covariance.html">Benchmarks for covariance</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_decomposition.html">Benchmarks for decomposition</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Benchmarks for ensemble</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#randomforestclassifier-arcene">RandomForestClassifier-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#randomforestclassifier-madelon">RandomForestClassifier-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extratreesclassifier-arcene">ExtraTreesClassifier-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extratreesclassifier-madelon">ExtraTreesClassifier-madelon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradientboostingclassifier-arcene">GradientBoostingClassifier-arcene</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gradientboostingclassifier-madelon">GradientBoostingClassifier-madelon</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vb_gaussian_process.html">Benchmarks for gaussian_process</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_linear_model.html">Benchmarks for linear_model</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_manifold.html">Benchmarks for manifold</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_mixture.html">Benchmarks for mixture</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_naive_bayes.html">Benchmarks for naive_bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_neighbors.html">Benchmarks for neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_pls.html">Benchmarks for pls</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_semi_supervised.html">Benchmarks for semi_supervised</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_svm.html">Benchmarks for svm</a></li>
<li class="toctree-l1"><a class="reference internal" href="vb_tree.html">Benchmarks for tree</a></li>
</ul>

          <!--
	   <div class="rel rellarge">
	     
	<!-- rellinks[1:] is an ugly hack to avoid link to module
	    index  --
	<div class="rellink">
	<a href="vb_decomposition.html" title="Benchmarks for decomposition"
	    accesskey="P">Previous
	    <br>
	    <span class="smallrellink">
	    Benchmarks for d...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for decomposition
	    </span>
	    
	    </a>
	</div>
	    <div class="spacer">
	    &nbsp;
	    </div>
	
	<div class="rellink">
	<a href="vb_gaussian_process.html" title="Benchmarks for gaussian_process"
	    accesskey="N">Next
	    <br>
	    <span class="smallrellink">
	    Benchmarks for g...
	    </span>
	    <span class="hiddenrellink">
	    Benchmarks for gaussian_process
	    </span>
	    
	    </a>
	</div>
	<!-- Ad a link to the 'up' page --
    </div>
    <p style="text-align: center; background-color: #FFE4E4">This documentation is
    for scikit-learn <strong>version 0.12-git</strong>
    &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    
    <h3>Citing</h3>
    <p>If you use the software, please consider
    <a href="about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <h3>This page</h3>
	<ul>
<li><a class="reference internal" href="#">Benchmarks for ensemble</a><ul>
<li><a class="reference internal" href="#randomforestclassifier-arcene">RandomForestClassifier-arcene</a></li>
<li><a class="reference internal" href="#randomforestclassifier-madelon">RandomForestClassifier-madelon</a></li>
<li><a class="reference internal" href="#extratreesclassifier-arcene">ExtraTreesClassifier-arcene</a></li>
<li><a class="reference internal" href="#extratreesclassifier-madelon">ExtraTreesClassifier-madelon</a></li>
<li><a class="reference internal" href="#gradientboostingclassifier-arcene">GradientBoostingClassifier-arcene</a></li>
<li><a class="reference internal" href="#gradientboostingclassifier-madelon">GradientBoostingClassifier-madelon</a></li>
</ul>
</li>
</ul>

    
  -->
    </div>
	  </div>


      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="benchmarks-for-ensemble">
<h1>Benchmarks for ensemble<a class="headerlink" href="#benchmarks-for-ensemble" title="Permalink to this headline">¶</a></h1>
<div class="section" id="randomforestclassifier-arcene">
<h2>RandomForestClassifier-arcene<a class="headerlink" href="#randomforestclassifier-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/RandomForestClassifier-arcene-step0-timing.png" src="_images/RandomForestClassifier-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/RandomForestClassifier-arcene-step0-memory.png" src="_images/RandomForestClassifier-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         5263 function calls (5183 primitive calls) in 0.670 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    0.670    0.670 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    0.670    0.670 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    0.670    0.670 /tmp/vb_sklearn/sklearn/ensemble/forest.py:270(fit)
     2    0.000    0.000    0.654    0.327 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:454(__call__)
     2    0.000    0.000    0.653    0.327 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:307(dispatch)
     2    0.000    0.000    0.653    0.327 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:132(__init__)
     1    0.001    0.001    0.607    0.607 /tmp/vb_sklearn/sklearn/ensemble/forest.py:69(_parallel_build_trees)
    10    0.001    0.000    0.598    0.060 /tmp/vb_sklearn/sklearn/tree/tree.py:194(fit)
    10    0.587    0.059    0.596    0.060 {method 'build' of 'sklearn.tree._tree.Tree' objects}
    12    0.000    0.000    0.053    0.004 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
    12    0.053    0.004    0.053    0.004 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.046    0.046 /tmp/vb_sklearn/sklearn/ensemble/forest.py:182(_parallel_X_argsort)
     1    0.000    0.000    0.013    0.013 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
    71    0.008    0.000    0.008    0.000 {numpy.core.multiarray.array}
    34    0.000    0.000    0.008    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    22    0.008    0.000    0.008    0.000 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.008    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
    10    0.000    0.000    0.006    0.001 /tmp/vb_sklearn/sklearn/ensemble/base.py:51(_make_estimator)
    40    0.002    0.000    0.005    0.000 /tmp/vb_sklearn/sklearn/base.py:188(get_params)
 90/10    0.001    0.000    0.004    0.000 /tmp/vb_sklearn/sklearn/base.py:15(clone)
    20    0.000    0.000    0.003    0.000 /tmp/vb_sklearn/sklearn/base.py:218(set_params)
     1    0.000    0.000    0.002    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
    40    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/base.py:163(_get_param_names)
    12    0.001    0.000    0.001    0.000 {numpy.core.multiarray.concatenate}
    40    0.000    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:801(getargspec)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:228(hstack)
    80    0.000    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:145(deepcopy)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:339(__enter__)
    31    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
    40    0.000    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:741(getargs)
    83    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    11    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
   367    0.000    0.000    0.000    0.000 {isinstance}
    83    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   320    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:318(__init__)
   320    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:355(__exit__)
   260    0.000    0.000    0.000    0.000 {hasattr}
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:267(_keep_alive)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
   543    0.000    0.000    0.000    0.000 {getattr}
    20    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
    31    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
    22    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:112(delayed)
   246    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:314(&lt;genexpr&gt;)
    80    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/base.py:58(&lt;genexpr&gt;)
    21    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
    30    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/six.py:266(iteritems)
    10    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
   465    0.000    0.000    0.000    0.000 {len}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
    41    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:555(__init__)
     2    0.000    0.000    0.000    0.000 {cPickle.dumps}
    40    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    22    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:365(&lt;genexpr&gt;)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
    80    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x781380}
    22    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:67(ismethod)
    13    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    40    0.000    0.000    0.000    0.000 &lt;string&gt;:8(__new__)
    10    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
    11    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:407(retrieve)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
    86    0.000    0.000    0.000    0.000 {setattr}
    10    0.000    0.000    0.000    0.000 {numpy.lib._compiled_base.bincount}
    42    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:160(__init__)
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:17(update_wrapper)
    44    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:39(short_format_time)
    11    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
   160    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:209(iscode)
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:142(isfunction)
   240    0.000    0.000    0.000    0.000 {id}
     1    0.000    0.000    0.000    0.000 {map}
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:198(_deepcopy_atomic)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
    49    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
    10    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:187(_partition_features)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:159(_partition_trees)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:23(_squeeze_time)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
    20    0.000    0.000    0.000    0.000 {max}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:294(__init__)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    30    0.000    0.000    0.000    0.000 {iter}
    30    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:39(wraps)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
     4    0.000    0.000    0.000    0.000 {time.time}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {min}
     2    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:119(delayed_function)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:354(_print)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:60(_verbosity_filter)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:137(get)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/ensemble/forest.py
Function: fit at line 270
Total time: 0.759928 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   270                                               def fit(self, X, y, sample_weight=None):
   271                                                   """Build a forest of trees from the training set (X, y).
   272
   273                                                   Parameters
   274                                                   ----------
   275                                                   X : array-like of shape = [n_samples, n_features]
   276                                                       The training input samples.
   277
   278                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   279                                                       The target values (integers that correspond to classes in
   280                                                       classification, real numbers in regression).
   281
   282                                                   sample_weight : array-like, shape = [n_samples] or None
   283                                                       Sample weights. If None, then samples are equally weighted. Splits
   284                                                       that would create child nodes with net zero or negative weight are
   285                                                       ignored while searching for a split in each node. In the case of
   286                                                       classification, splits are also ignored if they would result in any
   287                                                       single class carrying a negative weight in either child node.
   288
   289                                                   Returns
   290                                                   -------
   291                                                   self : object
   292                                                       Returns self.
   293                                                   """
   294         1           27     27.0      0.0          random_state = check_random_state(self.random_state)
   295
   296                                                   # Precompute some data
   297         1         1731   1731.0      0.2          X, y = check_arrays(X, y, sparse_format="dense")
   298         1            6      6.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   299                                                           X.ndim != 2 or
   300                                                           not X.flags.fortran):
   301         1        10781  10781.0      1.4              X = array2d(X, dtype=DTYPE, order="F")
   302
   303         1            8      8.0      0.0          n_samples, self.n_features_ = X.shape
   304
   305         1            4      4.0      0.0          if not self.bootstrap and self.oob_score:
   306                                                       raise ValueError("Out of bag estimation only available"
   307                                                                        " if bootstrap=True")
   308
   309         1           22     22.0      0.0          sample_mask = np.ones((n_samples,), dtype=np.bool)
   310
   311         1           23     23.0      0.0          n_jobs, _, starts = _partition_features(self, self.n_features_)
   312
   313         1           17     17.0      0.0          all_X_argsorted = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   314         1            5      5.0      0.0              delayed(_parallel_X_argsort)(
   315                                                           X[:, starts[i]:starts[i + 1]])
   316         1       106116 106116.0     14.0              for i in xrange(n_jobs))
   317
   318         1         1261   1261.0      0.2          X_argsorted = np.asfortranarray(np.hstack(all_X_argsorted))
   319
   320         1           36     36.0      0.0          y = np.atleast_1d(y)
   321         1            8      8.0      0.0          if y.ndim == 1:
   322                                                       # reshape is necessary to preserve the data contiguity against vs
   323                                                       # [:, np.newaxis] that does not.
   324         1           21     21.0      0.0              y = np.reshape(y, (-1, 1))
   325
   326         1            9      9.0      0.0          self.n_outputs_ = y.shape[1]
   327
   328         1           11     11.0      0.0          if isinstance(self.base_estimator, ClassifierMixin):
   329         1           21     21.0      0.0              y = np.copy(y)
   330
   331         1            7      7.0      0.0              if self.n_outputs_ == 1:
   332         1          124    124.0      0.0                  self.classes_ = np.unique(y)
   333         1            8      8.0      0.0                  self.n_classes_ = len(self.classes_)
   334
   335                                                       else:
   336                                                           self.classes_ = []
   337                                                           self.n_classes_ = []
   338
   339                                                           for k in xrange(self.n_outputs_):
   340                                                               unique = np.unique(y[:, k])
   341                                                               self.classes_.append(unique)
   342                                                               self.n_classes_.append(unique.shape[0])
   343                                                               y[:, k] = np.searchsorted(unique, y[:, k])
   344
   345                                                   else:
   346                                                       if self.n_outputs_ == 1:
   347                                                           self.classes_ = None
   348                                                           self.n_classes_ = 1
   349
   350                                                       else:
   351                                                           self.classes_ = [None] * self.n_outputs_
   352                                                           self.n_classes_ = [1] * self.n_outputs_
   353
   354         1           11     11.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   355         1           22     22.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   356
   357                                                   # Assign chunk of trees to jobs
   358         1           34     34.0      0.0          n_jobs, n_trees, _ = _partition_trees(self)
   359
   360                                                   # Precalculate the random states
   361         2           33     16.5      0.0          seeds = [random_state.randint(MAX_INT, size=i) for i in n_trees]
   362
   363                                                   # Parallel loop
   364         1           25     25.0      0.0          all_trees = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   365         1            9      9.0      0.0              delayed(_parallel_build_trees)(
   366                                                           n_trees[i],
   367                                                           self,
   368                                                           X,
   369                                                           y,
   370                                                           sample_weight,
   371                                                           sample_mask,
   372                                                           X_argsorted,
   373                                                           seeds[i],
   374                                                           verbose=self.verbose)
   375         1       639457 639457.0     84.1              for i in range(n_jobs))
   376
   377                                                   # Reduce
   378        11           78      7.1      0.0          self.estimators_ = [tree for tree in itertools.chain(*all_trees)]
   379
   380                                                   # Calculate out of bag predictions and score
   381         1            7      7.0      0.0          if self.oob_score:
   382                                                       if isinstance(self, ClassifierMixin):
   383                                                           self.oob_decision_function_ = []
   384                                                           self.oob_score_ = 0.0
   385                                                           n_classes_ = self.n_classes_
   386                                                           classes_ = self.classes_
   387
   388                                                           if self.n_outputs_ == 1:
   389                                                               n_classes_ = [n_classes_]
   390                                                               classes_ = [classes_]
   391
   392                                                           predictions = []
   393
   394                                                           for k in xrange(self.n_outputs_):
   395                                                               predictions.append(np.zeros((n_samples,
   396                                                                                            n_classes_[k])))
   397
   398                                                           for estimator in self.estimators_:
   399                                                               mask = np.ones(n_samples, dtype=np.bool)
   400                                                               mask[estimator.indices_] = False
   401                                                               p_estimator = estimator.predict_proba(X[mask, :])
   402
   403                                                               if self.n_outputs_ == 1:
   404                                                                   p_estimator = [p_estimator]
   405
   406                                                               for k in xrange(self.n_outputs_):
   407                                                                   predictions[k][mask, :] += p_estimator[k]
   408
   409                                                           for k in xrange(self.n_outputs_):
   410                                                               if (predictions[k].sum(axis=1) == 0).any():
   411                                                                   warn("Some inputs do not have OOB scores. "
   412                                                                        "This probably means too few trees were used "
   413                                                                        "to compute any reliable oob estimates.")
   414
   415                                                               decision = (predictions[k] /
   416                                                                           predictions[k].sum(axis=1)[:, np.newaxis])
   417                                                               self.oob_decision_function_.append(decision)
   418                                                               self.oob_score_ += np.mean(
   419                                                                   (y[:, k] == classes_[k].take(
   420                                                                       np.argmax(predictions[k], axis=1),
   421                                                                       axis=0)))
   422
   423                                                           if self.n_outputs_ == 1:
   424                                                               self.oob_decision_function_ = \
   425                                                                   self.oob_decision_function_[0]
   426
   427                                                           self.oob_score_ /= self.n_outputs_
   428
   429                                                       else:
   430                                                           # Regression:
   431                                                           predictions = np.zeros((n_samples, self.n_outputs_))
   432                                                           n_predictions = np.zeros((n_samples, self.n_outputs_))
   433
   434                                                           for estimator in self.estimators_:
   435                                                               mask = np.ones(n_samples, dtype=np.bool)
   436                                                               mask[estimator.indices_] = False
   437                                                               p_estimator = estimator.predict(X[mask, :])
   438
   439                                                               if self.n_outputs_ == 1:
   440                                                                   p_estimator = p_estimator[:, np.newaxis]
   441
   442                                                               predictions[mask, :] += p_estimator
   443                                                               n_predictions[mask, :] += 1
   444
   445                                                           if (n_predictions == 0).any():
   446                                                               warn("Some inputs do not have OOB scores. "
   447                                                                    "This probably means too few trees were used "
   448                                                                    "to compute any reliable oob estimates.")
   449                                                               n_predictions[n_predictions == 0] = 1
   450
   451                                                           predictions /= n_predictions
   452                                                           self.oob_prediction_ = predictions
   453
   454                                                           if self.n_outputs_ == 1:
   455                                                               self.oob_prediction_ = \
   456                                                                   self.oob_prediction_.reshape((n_samples, ))
   457
   458                                                           self.oob_score_ = 0.0
   459
   460                                                           for k in xrange(self.n_outputs_):
   461                                                               self.oob_score_ += r2_score(y[:, k],
   462                                                                                           predictions[:, k])
   463
   464                                                           self.oob_score_ /= self.n_outputs_
   465
   466         1            6      6.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="randomforestclassifier-madelon">
<h2>RandomForestClassifier-madelon<a class="headerlink" href="#randomforestclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/RandomForestClassifier-madelon-step0-timing.png" src="_images/RandomForestClassifier-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/RandomForestClassifier-madelon-step0-memory.png" src="_images/RandomForestClassifier-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         9624 function calls (9544 primitive calls) in 2.890 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    2.890    2.890 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    2.890    2.890 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    2.890    2.890 /tmp/vb_sklearn/sklearn/ensemble/forest.py:270(fit)
     2    0.000    0.000    2.863    1.431 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:454(__call__)
     2    0.000    0.000    2.862    1.431 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:307(dispatch)
     2    0.000    0.000    2.862    1.431 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:132(__init__)
     1    0.002    0.002    2.720    2.720 /tmp/vb_sklearn/sklearn/ensemble/forest.py:69(_parallel_build_trees)
    10    0.002    0.000    2.703    0.270 /tmp/vb_sklearn/sklearn/tree/tree.py:194(fit)
    10    1.818    0.182    2.697    0.270 {method 'build' of 'sklearn.tree._tree.Tree' objects}
   635    0.002    0.000    1.007    0.002 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
   635    1.004    0.002    1.004    0.002 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.142    0.142 /tmp/vb_sklearn/sklearn/ensemble/forest.py:182(_parallel_X_argsort)
     1    0.000    0.000    0.022    0.022 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
    22    0.016    0.001    0.016    0.001 {method 'sum' of 'numpy.ndarray' objects}
   694    0.015    0.000    0.015    0.000 {numpy.core.multiarray.array}
     3    0.000    0.000    0.015    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
    34    0.000    0.000    0.012    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    10    0.000    0.000    0.011    0.001 /tmp/vb_sklearn/sklearn/ensemble/base.py:51(_make_estimator)
    40    0.003    0.000    0.008    0.000 /tmp/vb_sklearn/sklearn/base.py:188(get_params)
 90/10    0.001    0.000    0.008    0.001 /tmp/vb_sklearn/sklearn/base.py:15(clone)
   645    0.002    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
   635    0.002    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
    20    0.000    0.000    0.005    0.000 /tmp/vb_sklearn/sklearn/base.py:218(set_params)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
    11    0.001    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
    40    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/base.py:163(_get_param_names)
   645    0.002    0.000    0.002    0.000 {method 'fill' of 'numpy.ndarray' objects}
   645    0.002    0.000    0.002    0.000 {numpy.core.multiarray.empty}
    40    0.000    0.000    0.002    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:801(getargspec)
    12    0.002    0.000    0.002    0.000 {numpy.core.multiarray.concatenate}
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:339(__enter__)
    80    0.001    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:145(deepcopy)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:228(hstack)
    11    0.001    0.000    0.001    0.000 {method 'sort' of 'numpy.ndarray' objects}
    31    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
    83    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    40    0.001    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:741(getargs)
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
   367    0.000    0.000    0.001    0.000 {isinstance}
    10    0.001    0.000    0.001    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
    83    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    21    0.001    0.000    0.001    0.000 {method 'randint' of 'mtrand.RandomState' objects}
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:355(__exit__)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:318(__init__)
    20    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
   543    0.001    0.000    0.001    0.000 {getattr}
    80    0.000    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:267(_keep_alive)
   260    0.001    0.000    0.001    0.000 {hasattr}
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
    31    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
    10    0.000    0.000    0.000    0.000 {numpy.lib._compiled_base.bincount}
   246    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:112(delayed)
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:314(&lt;genexpr&gt;)
    10    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    41    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
    30    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/six.py:266(iteritems)
    80    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/base.py:58(&lt;genexpr&gt;)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:555(__init__)
   465    0.000    0.000    0.000    0.000 {len}
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
    40    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
   240    0.000    0.000    0.000    0.000 {id}
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:67(ismethod)
    11    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {cPickle.dumps}
    13    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:142(isfunction)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:365(&lt;genexpr&gt;)
    80    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x781380}
    40    0.000    0.000    0.000    0.000 &lt;string&gt;:8(__new__)
    86    0.000    0.000    0.000    0.000 {setattr}
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:160(__init__)
    44    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:407(retrieve)
    42    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
   160    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:209(iscode)
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:17(update_wrapper)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:39(short_format_time)
    10    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}
    49    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {map}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:198(_deepcopy_atomic)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
    20    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:159(_partition_trees)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:23(_squeeze_time)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:187(_partition_features)
    30    0.000    0.000    0.000    0.000 {iter}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    30    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:294(__init__)
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:39(wraps)
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {time.time}
     2    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {min}
     2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:354(_print)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:137(get)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:119(delayed_function)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:60(_verbosity_filter)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/ensemble/forest.py
Function: fit at line 270
Total time: 2.99156 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   270                                               def fit(self, X, y, sample_weight=None):
   271                                                   """Build a forest of trees from the training set (X, y).
   272
   273                                                   Parameters
   274                                                   ----------
   275                                                   X : array-like of shape = [n_samples, n_features]
   276                                                       The training input samples.
   277
   278                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   279                                                       The target values (integers that correspond to classes in
   280                                                       classification, real numbers in regression).
   281
   282                                                   sample_weight : array-like, shape = [n_samples] or None
   283                                                       Sample weights. If None, then samples are equally weighted. Splits
   284                                                       that would create child nodes with net zero or negative weight are
   285                                                       ignored while searching for a split in each node. In the case of
   286                                                       classification, splits are also ignored if they would result in any
   287                                                       single class carrying a negative weight in either child node.
   288
   289                                                   Returns
   290                                                   -------
   291                                                   self : object
   292                                                       Returns self.
   293                                                   """
   294         1           49     49.0      0.0          random_state = check_random_state(self.random_state)
   295
   296                                                   # Precompute some data
   297         1        16122  16122.0      0.5          X, y = check_arrays(X, y, sparse_format="dense")
   298         1           10     10.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   299                                                           X.ndim != 2 or
   300                                                           not X.flags.fortran):
   301         1        17749  17749.0      0.6              X = array2d(X, dtype=DTYPE, order="F")
   302
   303         1           13     13.0      0.0          n_samples, self.n_features_ = X.shape
   304
   305         1            6      6.0      0.0          if not self.bootstrap and self.oob_score:
   306                                                       raise ValueError("Out of bag estimation only available"
   307                                                                        " if bootstrap=True")
   308
   309         1           34     34.0      0.0          sample_mask = np.ones((n_samples,), dtype=np.bool)
   310
   311         1           36     36.0      0.0          n_jobs, _, starts = _partition_features(self, self.n_features_)
   312
   313         1           28     28.0      0.0          all_X_argsorted = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   314         1            8      8.0      0.0              delayed(_parallel_X_argsort)(
   315                                                           X[:, starts[i]:starts[i + 1]])
   316         1       163214 163214.0      5.5              for i in xrange(n_jobs))
   317
   318         1         1310   1310.0      0.0          X_argsorted = np.asfortranarray(np.hstack(all_X_argsorted))
   319
   320         1           35     35.0      0.0          y = np.atleast_1d(y)
   321         1            8      8.0      0.0          if y.ndim == 1:
   322                                                       # reshape is necessary to preserve the data contiguity against vs
   323                                                       # [:, np.newaxis] that does not.
   324         1           22     22.0      0.0              y = np.reshape(y, (-1, 1))
   325
   326         1           10     10.0      0.0          self.n_outputs_ = y.shape[1]
   327
   328         1           12     12.0      0.0          if isinstance(self.base_estimator, ClassifierMixin):
   329         1           25     25.0      0.0              y = np.copy(y)
   330
   331         1            7      7.0      0.0              if self.n_outputs_ == 1:
   332         1          217    217.0      0.0                  self.classes_ = np.unique(y)
   333         1            9      9.0      0.0                  self.n_classes_ = len(self.classes_)
   334
   335                                                       else:
   336                                                           self.classes_ = []
   337                                                           self.n_classes_ = []
   338
   339                                                           for k in xrange(self.n_outputs_):
   340                                                               unique = np.unique(y[:, k])
   341                                                               self.classes_.append(unique)
   342                                                               self.n_classes_.append(unique.shape[0])
   343                                                               y[:, k] = np.searchsorted(unique, y[:, k])
   344
   345                                                   else:
   346                                                       if self.n_outputs_ == 1:
   347                                                           self.classes_ = None
   348                                                           self.n_classes_ = 1
   349
   350                                                       else:
   351                                                           self.classes_ = [None] * self.n_outputs_
   352                                                           self.n_classes_ = [1] * self.n_outputs_
   353
   354         1           10     10.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   355         1           26     26.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   356
   357                                                   # Assign chunk of trees to jobs
   358         1           34     34.0      0.0          n_jobs, n_trees, _ = _partition_trees(self)
   359
   360                                                   # Precalculate the random states
   361         2           35     17.5      0.0          seeds = [random_state.randint(MAX_INT, size=i) for i in n_trees]
   362
   363                                                   # Parallel loop
   364         1           26     26.0      0.0          all_trees = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   365         1            9      9.0      0.0              delayed(_parallel_build_trees)(
   366                                                           n_trees[i],
   367                                                           self,
   368                                                           X,
   369                                                           y,
   370                                                           sample_weight,
   371                                                           sample_mask,
   372                                                           X_argsorted,
   373                                                           seeds[i],
   374                                                           verbose=self.verbose)
   375         1      2792396 2792396.0     93.3              for i in range(n_jobs))
   376
   377                                                   # Reduce
   378        11           84      7.6      0.0          self.estimators_ = [tree for tree in itertools.chain(*all_trees)]
   379
   380                                                   # Calculate out of bag predictions and score
   381         1            7      7.0      0.0          if self.oob_score:
   382                                                       if isinstance(self, ClassifierMixin):
   383                                                           self.oob_decision_function_ = []
   384                                                           self.oob_score_ = 0.0
   385                                                           n_classes_ = self.n_classes_
   386                                                           classes_ = self.classes_
   387
   388                                                           if self.n_outputs_ == 1:
   389                                                               n_classes_ = [n_classes_]
   390                                                               classes_ = [classes_]
   391
   392                                                           predictions = []
   393
   394                                                           for k in xrange(self.n_outputs_):
   395                                                               predictions.append(np.zeros((n_samples,
   396                                                                                            n_classes_[k])))
   397
   398                                                           for estimator in self.estimators_:
   399                                                               mask = np.ones(n_samples, dtype=np.bool)
   400                                                               mask[estimator.indices_] = False
   401                                                               p_estimator = estimator.predict_proba(X[mask, :])
   402
   403                                                               if self.n_outputs_ == 1:
   404                                                                   p_estimator = [p_estimator]
   405
   406                                                               for k in xrange(self.n_outputs_):
   407                                                                   predictions[k][mask, :] += p_estimator[k]
   408
   409                                                           for k in xrange(self.n_outputs_):
   410                                                               if (predictions[k].sum(axis=1) == 0).any():
   411                                                                   warn("Some inputs do not have OOB scores. "
   412                                                                        "This probably means too few trees were used "
   413                                                                        "to compute any reliable oob estimates.")
   414
   415                                                               decision = (predictions[k] /
   416                                                                           predictions[k].sum(axis=1)[:, np.newaxis])
   417                                                               self.oob_decision_function_.append(decision)
   418                                                               self.oob_score_ += np.mean(
   419                                                                   (y[:, k] == classes_[k].take(
   420                                                                       np.argmax(predictions[k], axis=1),
   421                                                                       axis=0)))
   422
   423                                                           if self.n_outputs_ == 1:
   424                                                               self.oob_decision_function_ = \
   425                                                                   self.oob_decision_function_[0]
   426
   427                                                           self.oob_score_ /= self.n_outputs_
   428
   429                                                       else:
   430                                                           # Regression:
   431                                                           predictions = np.zeros((n_samples, self.n_outputs_))
   432                                                           n_predictions = np.zeros((n_samples, self.n_outputs_))
   433
   434                                                           for estimator in self.estimators_:
   435                                                               mask = np.ones(n_samples, dtype=np.bool)
   436                                                               mask[estimator.indices_] = False
   437                                                               p_estimator = estimator.predict(X[mask, :])
   438
   439                                                               if self.n_outputs_ == 1:
   440                                                                   p_estimator = p_estimator[:, np.newaxis]
   441
   442                                                               predictions[mask, :] += p_estimator
   443                                                               n_predictions[mask, :] += 1
   444
   445                                                           if (n_predictions == 0).any():
   446                                                               warn("Some inputs do not have OOB scores. "
   447                                                                    "This probably means too few trees were used "
   448                                                                    "to compute any reliable oob estimates.")
   449                                                               n_predictions[n_predictions == 0] = 1
   450
   451                                                           predictions /= n_predictions
   452                                                           self.oob_prediction_ = predictions
   453
   454                                                           if self.n_outputs_ == 1:
   455                                                               self.oob_prediction_ = \
   456                                                                   self.oob_prediction_.reshape((n_samples, ))
   457
   458                                                           self.oob_score_ = 0.0
   459
   460                                                           for k in xrange(self.n_outputs_):
   461                                                               self.oob_score_ += r2_score(y[:, k],
   462                                                                                           predictions[:, k])
   463
   464                                                           self.oob_score_ /= self.n_outputs_
   465
   466         1            7      7.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="extratreesclassifier-arcene">
<h2>ExtraTreesClassifier-arcene<a class="headerlink" href="#extratreesclassifier-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ExtraTreesClassifier-arcene-step0-timing.png" src="_images/ExtraTreesClassifier-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ExtraTreesClassifier-arcene-step0-memory.png" src="_images/ExtraTreesClassifier-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         5377 function calls (5297 primitive calls) in 1.480 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    1.480    1.480 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    1.480    1.480 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    1.480    1.480 /tmp/vb_sklearn/sklearn/ensemble/forest.py:270(fit)
     2    0.000    0.000    1.449    0.725 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:454(__call__)
     2    0.000    0.000    1.449    0.724 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:307(dispatch)
     2    0.000    0.000    1.449    0.724 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:132(__init__)
     1    0.000    0.000    1.367    1.367 /tmp/vb_sklearn/sklearn/ensemble/forest.py:69(_parallel_build_trees)
    10    0.002    0.000    1.354    0.135 /tmp/vb_sklearn/sklearn/tree/tree.py:194(fit)
    10    1.267    0.127    1.350    0.135 {method 'build' of 'sklearn.tree._tree.Tree' objects}
    44    0.000    0.000    0.161    0.004 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
    44    0.161    0.004    0.161    0.004 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.082    0.082 /tmp/vb_sklearn/sklearn/ensemble/forest.py:182(_parallel_X_argsort)
     1    0.000    0.000    0.025    0.025 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
   103    0.017    0.000    0.017    0.000 {numpy.core.multiarray.array}
    34    0.000    0.000    0.017    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    12    0.014    0.001    0.014    0.001 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.013    0.004 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
    10    0.000    0.000    0.010    0.001 /tmp/vb_sklearn/sklearn/ensemble/base.py:51(_make_estimator)
    40    0.003    0.000    0.008    0.000 /tmp/vb_sklearn/sklearn/base.py:188(get_params)
 90/10    0.001    0.000    0.007    0.001 /tmp/vb_sklearn/sklearn/base.py:15(clone)
    20    0.000    0.000    0.004    0.000 /tmp/vb_sklearn/sklearn/base.py:218(set_params)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
    40    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/base.py:163(_get_param_names)
    12    0.002    0.000    0.002    0.000 {numpy.core.multiarray.concatenate}
    40    0.000    0.000    0.002    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:801(getargspec)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:228(hstack)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:339(__enter__)
    80    0.001    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:145(deepcopy)
    11    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
    31    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
    40    0.001    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:741(getargs)
    83    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
   357    0.000    0.000    0.001    0.000 {isinstance}
    83    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:318(__init__)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:355(__exit__)
   260    0.001    0.000    0.001    0.000 {hasattr}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
    44    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:267(_keep_alive)
   533    0.000    0.000    0.000    0.000 {getattr}
    44    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
    31    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:112(delayed)
   246    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:314(&lt;genexpr&gt;)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:786(__init__)
    30    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/six.py:266(iteritems)
    10    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    41    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
    44    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
    44    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
    80    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/base.py:58(&lt;genexpr&gt;)
    40    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
   445    0.000    0.000    0.000    0.000 {len}
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:555(__init__)
     2    0.000    0.000    0.000    0.000 {cPickle.dumps}
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:67(ismethod)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:365(&lt;genexpr&gt;)
    13    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    11    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
    80    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x781380}
    40    0.000    0.000    0.000    0.000 &lt;string&gt;:8(__new__)
    10    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
    86    0.000    0.000    0.000    0.000 {setattr}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:407(retrieve)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:160(__init__)
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:17(update_wrapper)
    42    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
    11    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
   160    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    44    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:39(short_format_time)
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:209(iscode)
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:142(isfunction)
   240    0.000    0.000    0.000    0.000 {id}
    11    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {map}
    49    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:198(_deepcopy_atomic)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:159(_partition_trees)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:187(_partition_features)
    20    0.000    0.000    0.000    0.000 {max}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:23(_squeeze_time)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:294(__init__)
    30    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:39(wraps)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
    30    0.000    0.000    0.000    0.000 {iter}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     4    0.000    0.000    0.000    0.000 {time.time}
     2    0.000    0.000    0.000    0.000 {min}
     2    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:354(_print)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:60(_verbosity_filter)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:119(delayed_function)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:137(get)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/ensemble/forest.py
Function: fit at line 270
Total time: 1.60349 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   270                                               def fit(self, X, y, sample_weight=None):
   271                                                   """Build a forest of trees from the training set (X, y).
   272
   273                                                   Parameters
   274                                                   ----------
   275                                                   X : array-like of shape = [n_samples, n_features]
   276                                                       The training input samples.
   277
   278                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   279                                                       The target values (integers that correspond to classes in
   280                                                       classification, real numbers in regression).
   281
   282                                                   sample_weight : array-like, shape = [n_samples] or None
   283                                                       Sample weights. If None, then samples are equally weighted. Splits
   284                                                       that would create child nodes with net zero or negative weight are
   285                                                       ignored while searching for a split in each node. In the case of
   286                                                       classification, splits are also ignored if they would result in any
   287                                                       single class carrying a negative weight in either child node.
   288
   289                                                   Returns
   290                                                   -------
   291                                                   self : object
   292                                                       Returns self.
   293                                                   """
   294         1           45     45.0      0.0          random_state = check_random_state(self.random_state)
   295
   296                                                   # Precompute some data
   297         1         2650   2650.0      0.2          X, y = check_arrays(X, y, sparse_format="dense")
   298         1           10     10.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   299                                                           X.ndim != 2 or
   300                                                           not X.flags.fortran):
   301         1        29661  29661.0      1.8              X = array2d(X, dtype=DTYPE, order="F")
   302
   303         1           12     12.0      0.0          n_samples, self.n_features_ = X.shape
   304
   305         1            8      8.0      0.0          if not self.bootstrap and self.oob_score:
   306                                                       raise ValueError("Out of bag estimation only available"
   307                                                                        " if bootstrap=True")
   308
   309         1           32     32.0      0.0          sample_mask = np.ones((n_samples,), dtype=np.bool)
   310
   311         1           36     36.0      0.0          n_jobs, _, starts = _partition_features(self, self.n_features_)
   312
   313         1           27     27.0      0.0          all_X_argsorted = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   314         1            8      8.0      0.0              delayed(_parallel_X_argsort)(
   315                                                           X[:, starts[i]:starts[i + 1]])
   316         1        92663  92663.0      5.8              for i in xrange(n_jobs))
   317
   318         1         1226   1226.0      0.1          X_argsorted = np.asfortranarray(np.hstack(all_X_argsorted))
   319
   320         1           36     36.0      0.0          y = np.atleast_1d(y)
   321         1            7      7.0      0.0          if y.ndim == 1:
   322                                                       # reshape is necessary to preserve the data contiguity against vs
   323                                                       # [:, np.newaxis] that does not.
   324         1           21     21.0      0.0              y = np.reshape(y, (-1, 1))
   325
   326         1           15     15.0      0.0          self.n_outputs_ = y.shape[1]
   327
   328         1           12     12.0      0.0          if isinstance(self.base_estimator, ClassifierMixin):
   329         1           23     23.0      0.0              y = np.copy(y)
   330
   331         1            6      6.0      0.0              if self.n_outputs_ == 1:
   332         1          124    124.0      0.0                  self.classes_ = np.unique(y)
   333         1            8      8.0      0.0                  self.n_classes_ = len(self.classes_)
   334
   335                                                       else:
   336                                                           self.classes_ = []
   337                                                           self.n_classes_ = []
   338
   339                                                           for k in xrange(self.n_outputs_):
   340                                                               unique = np.unique(y[:, k])
   341                                                               self.classes_.append(unique)
   342                                                               self.n_classes_.append(unique.shape[0])
   343                                                               y[:, k] = np.searchsorted(unique, y[:, k])
   344
   345                                                   else:
   346                                                       if self.n_outputs_ == 1:
   347                                                           self.classes_ = None
   348                                                           self.n_classes_ = 1
   349
   350                                                       else:
   351                                                           self.classes_ = [None] * self.n_outputs_
   352                                                           self.n_classes_ = [1] * self.n_outputs_
   353
   354         1           11     11.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   355         1           22     22.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   356
   357                                                   # Assign chunk of trees to jobs
   358         1           37     37.0      0.0          n_jobs, n_trees, _ = _partition_trees(self)
   359
   360                                                   # Precalculate the random states
   361         2           33     16.5      0.0          seeds = [random_state.randint(MAX_INT, size=i) for i in n_trees]
   362
   363                                                   # Parallel loop
   364         1           25     25.0      0.0          all_trees = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   365         1            9      9.0      0.0              delayed(_parallel_build_trees)(
   366                                                           n_trees[i],
   367                                                           self,
   368                                                           X,
   369                                                           y,
   370                                                           sample_weight,
   371                                                           sample_mask,
   372                                                           X_argsorted,
   373                                                           seeds[i],
   374                                                           verbose=self.verbose)
   375         1      1476628 1476628.0     92.1              for i in range(n_jobs))
   376
   377                                                   # Reduce
   378        11           82      7.5      0.0          self.estimators_ = [tree for tree in itertools.chain(*all_trees)]
   379
   380                                                   # Calculate out of bag predictions and score
   381         1            8      8.0      0.0          if self.oob_score:
   382                                                       if isinstance(self, ClassifierMixin):
   383                                                           self.oob_decision_function_ = []
   384                                                           self.oob_score_ = 0.0
   385                                                           n_classes_ = self.n_classes_
   386                                                           classes_ = self.classes_
   387
   388                                                           if self.n_outputs_ == 1:
   389                                                               n_classes_ = [n_classes_]
   390                                                               classes_ = [classes_]
   391
   392                                                           predictions = []
   393
   394                                                           for k in xrange(self.n_outputs_):
   395                                                               predictions.append(np.zeros((n_samples,
   396                                                                                            n_classes_[k])))
   397
   398                                                           for estimator in self.estimators_:
   399                                                               mask = np.ones(n_samples, dtype=np.bool)
   400                                                               mask[estimator.indices_] = False
   401                                                               p_estimator = estimator.predict_proba(X[mask, :])
   402
   403                                                               if self.n_outputs_ == 1:
   404                                                                   p_estimator = [p_estimator]
   405
   406                                                               for k in xrange(self.n_outputs_):
   407                                                                   predictions[k][mask, :] += p_estimator[k]
   408
   409                                                           for k in xrange(self.n_outputs_):
   410                                                               if (predictions[k].sum(axis=1) == 0).any():
   411                                                                   warn("Some inputs do not have OOB scores. "
   412                                                                        "This probably means too few trees were used "
   413                                                                        "to compute any reliable oob estimates.")
   414
   415                                                               decision = (predictions[k] /
   416                                                                           predictions[k].sum(axis=1)[:, np.newaxis])
   417                                                               self.oob_decision_function_.append(decision)
   418                                                               self.oob_score_ += np.mean(
   419                                                                   (y[:, k] == classes_[k].take(
   420                                                                       np.argmax(predictions[k], axis=1),
   421                                                                       axis=0)))
   422
   423                                                           if self.n_outputs_ == 1:
   424                                                               self.oob_decision_function_ = \
   425                                                                   self.oob_decision_function_[0]
   426
   427                                                           self.oob_score_ /= self.n_outputs_
   428
   429                                                       else:
   430                                                           # Regression:
   431                                                           predictions = np.zeros((n_samples, self.n_outputs_))
   432                                                           n_predictions = np.zeros((n_samples, self.n_outputs_))
   433
   434                                                           for estimator in self.estimators_:
   435                                                               mask = np.ones(n_samples, dtype=np.bool)
   436                                                               mask[estimator.indices_] = False
   437                                                               p_estimator = estimator.predict(X[mask, :])
   438
   439                                                               if self.n_outputs_ == 1:
   440                                                                   p_estimator = p_estimator[:, np.newaxis]
   441
   442                                                               predictions[mask, :] += p_estimator
   443                                                               n_predictions[mask, :] += 1
   444
   445                                                           if (n_predictions == 0).any():
   446                                                               warn("Some inputs do not have OOB scores. "
   447                                                                    "This probably means too few trees were used "
   448                                                                    "to compute any reliable oob estimates.")
   449                                                               n_predictions[n_predictions == 0] = 1
   450
   451                                                           predictions /= n_predictions
   452                                                           self.oob_prediction_ = predictions
   453
   454                                                           if self.n_outputs_ == 1:
   455                                                               self.oob_prediction_ = \
   456                                                                   self.oob_prediction_.reshape((n_samples, ))
   457
   458                                                           self.oob_score_ = 0.0
   459
   460                                                           for k in xrange(self.n_outputs_):
   461                                                               self.oob_score_ += r2_score(y[:, k],
   462                                                                                           predictions[:, k])
   463
   464                                                           self.oob_score_ /= self.n_outputs_
   465
   466         1            7      7.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="extratreesclassifier-madelon">
<h2>ExtraTreesClassifier-madelon<a class="headerlink" href="#extratreesclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;random_state&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/ExtraTreesClassifier-madelon-step0-timing.png" src="_images/ExtraTreesClassifier-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/ExtraTreesClassifier-madelon-step0-memory.png" src="_images/ExtraTreesClassifier-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         15618 function calls (15538 primitive calls) in 5.074 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000    5.074    5.074 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000    5.074    5.074 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000    5.074    5.074 /tmp/vb_sklearn/sklearn/ensemble/forest.py:270(fit)
     2    0.000    0.000    5.046    2.523 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:454(__call__)
     2    0.000    0.000    5.045    2.523 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:307(dispatch)
     2    0.000    0.000    5.045    2.523 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:132(__init__)
     1    0.000    0.000    4.903    4.903 /tmp/vb_sklearn/sklearn/ensemble/forest.py:69(_parallel_build_trees)
    10    0.002    0.000    4.889    0.489 /tmp/vb_sklearn/sklearn/tree/tree.py:194(fit)
    10    3.388    0.339    4.882    0.488 {method 'build' of 'sklearn.tree._tree.Tree' objects}
  1507    0.017    0.000    1.586    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
  1507    1.569    0.001    1.569    0.001 {method 'argsort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.142    0.142 /tmp/vb_sklearn/sklearn/ensemble/forest.py:182(_parallel_X_argsort)
  1507    0.005    0.000    0.025    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
  1507    0.017    0.000    0.024    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
     1    0.000    0.000    0.022    0.022 /tmp/vb_sklearn/sklearn/utils/validation.py:76(array2d)
  1566    0.019    0.000    0.019    0.000 {numpy.core.multiarray.array}
    12    0.015    0.001    0.015    0.001 {method 'sum' of 'numpy.ndarray' objects}
     3    0.000    0.000    0.015    0.005 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
  1507    0.015    0.000    0.015    0.000 {numpy.core.multiarray.empty}
    34    0.000    0.000    0.012    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
    10    0.000    0.000    0.011    0.001 /tmp/vb_sklearn/sklearn/ensemble/base.py:51(_make_estimator)
    40    0.003    0.000    0.008    0.000 /tmp/vb_sklearn/sklearn/base.py:188(get_params)
 90/10    0.001    0.000    0.008    0.001 /tmp/vb_sklearn/sklearn/base.py:15(clone)
    20    0.000    0.000    0.005    0.000 /tmp/vb_sklearn/sklearn/base.py:218(set_params)
  1507    0.004    0.000    0.004    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
    11    0.001    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
    40    0.000    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/base.py:163(_get_param_names)
    12    0.002    0.000    0.002    0.000 {numpy.core.multiarray.concatenate}
    40    0.000    0.000    0.002    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:801(getargspec)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:339(__enter__)
     1    0.000    0.000    0.001    0.001 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:228(hstack)
    11    0.001    0.000    0.001    0.000 {method 'sort' of 'numpy.ndarray' objects}
    80    0.001    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:145(deepcopy)
    31    0.000    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
    83    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
    40    0.001    0.000    0.001    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:741(getargs)
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
    10    0.001    0.000    0.001    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
    83    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
   357    0.000    0.000    0.001    0.000 {isinstance}
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:355(__exit__)
   320    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/warnings.py:318(__init__)
   260    0.001    0.000    0.001    0.000 {hasattr}
    10    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:267(_keep_alive)
   533    0.000    0.000    0.000    0.000 {getattr}
    31    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:112(delayed)
   246    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
    12    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:314(&lt;genexpr&gt;)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:786(__init__)
    10    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}
    40    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}
    30    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/six.py:266(iteritems)
    11    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/function_base.py:781(copy)
    41    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
    80    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/base.py:58(&lt;genexpr&gt;)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:555(__init__)
   445    0.000    0.000    0.000    0.000 {len}
    11    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {cPickle.dumps}
    13    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:67(ismethod)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:365(&lt;genexpr&gt;)
    80    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x781380}
    40    0.000    0.000    0.000    0.000 &lt;string&gt;:8(__new__)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:407(retrieve)
    10    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:160(__init__)
    86    0.000    0.000    0.000    0.000 {setattr}
    11    0.000    0.000    0.000    0.000 {method 'randint' of 'mtrand.RandomState' objects}
    42    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}
    44    0.000    0.000    0.000    0.000 {range}
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:17(update_wrapper)
   160    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:209(iscode)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:39(short_format_time)
    40    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/inspect.py:142(isfunction)
   240    0.000    0.000    0.000    0.000 {id}
    49    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 {map}
    20    0.000    0.000    0.000    0.000 {max}
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:159(_partition_trees)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:58(atleast_2d)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:289(ascontiguousarray)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/forest.py:187(_partition_features)
    80    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/copy.py:198(_deepcopy_atomic)
    10    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/logger.py:23(_squeeze_time)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
    30    0.000    0.000    0.000    0.000 {method 'iteritems' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:294(__init__)
     2    0.000    0.000    0.000    0.000 /sp/lib/python/cpython-2.7.2/lib/python2.7/functools.py:39(wraps)
    30    0.000    0.000    0.000    0.000 {iter}
     1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {min}
     4    0.000    0.000    0.000    0.000 {time.time}
     2    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     2    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:60(_verbosity_filter)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:137(get)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:354(_print)
     2    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/externals/joblib/parallel.py:119(delayed_function)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/ensemble/forest.py
Function: fit at line 270
Total time: 5.1955 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   270                                               def fit(self, X, y, sample_weight=None):
   271                                                   """Build a forest of trees from the training set (X, y).
   272
   273                                                   Parameters
   274                                                   ----------
   275                                                   X : array-like of shape = [n_samples, n_features]
   276                                                       The training input samples.
   277
   278                                                   y : array-like, shape = [n_samples] or [n_samples, n_outputs]
   279                                                       The target values (integers that correspond to classes in
   280                                                       classification, real numbers in regression).
   281
   282                                                   sample_weight : array-like, shape = [n_samples] or None
   283                                                       Sample weights. If None, then samples are equally weighted. Splits
   284                                                       that would create child nodes with net zero or negative weight are
   285                                                       ignored while searching for a split in each node. In the case of
   286                                                       classification, splits are also ignored if they would result in any
   287                                                       single class carrying a negative weight in either child node.
   288
   289                                                   Returns
   290                                                   -------
   291                                                   self : object
   292                                                       Returns self.
   293                                                   """
   294         1           49     49.0      0.0          random_state = check_random_state(self.random_state)
   295
   296                                                   # Precompute some data
   297         1         2937   2937.0      0.1          X, y = check_arrays(X, y, sparse_format="dense")
   298         1           11     11.0      0.0          if (getattr(X, "dtype", None) != DTYPE or
   299                                                           X.ndim != 2 or
   300                                                           not X.flags.fortran):
   301         1        27973  27973.0      0.5              X = array2d(X, dtype=DTYPE, order="F")
   302
   303         1           12     12.0      0.0          n_samples, self.n_features_ = X.shape
   304
   305         1            8      8.0      0.0          if not self.bootstrap and self.oob_score:
   306                                                       raise ValueError("Out of bag estimation only available"
   307                                                                        " if bootstrap=True")
   308
   309         1           45     45.0      0.0          sample_mask = np.ones((n_samples,), dtype=np.bool)
   310
   311         1           36     36.0      0.0          n_jobs, _, starts = _partition_features(self, self.n_features_)
   312
   313         1           26     26.0      0.0          all_X_argsorted = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   314         1            8      8.0      0.0              delayed(_parallel_X_argsort)(
   315                                                           X[:, starts[i]:starts[i + 1]])
   316         1       168574 168574.0      3.2              for i in xrange(n_jobs))
   317
   318         1         1307   1307.0      0.0          X_argsorted = np.asfortranarray(np.hstack(all_X_argsorted))
   319
   320         1           36     36.0      0.0          y = np.atleast_1d(y)
   321         1            7      7.0      0.0          if y.ndim == 1:
   322                                                       # reshape is necessary to preserve the data contiguity against vs
   323                                                       # [:, np.newaxis] that does not.
   324         1           22     22.0      0.0              y = np.reshape(y, (-1, 1))
   325
   326         1            9      9.0      0.0          self.n_outputs_ = y.shape[1]
   327
   328         1           11     11.0      0.0          if isinstance(self.base_estimator, ClassifierMixin):
   329         1           24     24.0      0.0              y = np.copy(y)
   330
   331         1            7      7.0      0.0              if self.n_outputs_ == 1:
   332         1          231    231.0      0.0                  self.classes_ = np.unique(y)
   333         1            8      8.0      0.0                  self.n_classes_ = len(self.classes_)
   334
   335                                                       else:
   336                                                           self.classes_ = []
   337                                                           self.n_classes_ = []
   338
   339                                                           for k in xrange(self.n_outputs_):
   340                                                               unique = np.unique(y[:, k])
   341                                                               self.classes_.append(unique)
   342                                                               self.n_classes_.append(unique.shape[0])
   343                                                               y[:, k] = np.searchsorted(unique, y[:, k])
   344
   345                                                   else:
   346                                                       if self.n_outputs_ == 1:
   347                                                           self.classes_ = None
   348                                                           self.n_classes_ = 1
   349
   350                                                       else:
   351                                                           self.classes_ = [None] * self.n_outputs_
   352                                                           self.n_classes_ = [1] * self.n_outputs_
   353
   354         1           11     11.0      0.0          if getattr(y, "dtype", None) != DOUBLE or not y.flags.contiguous:
   355         1           27     27.0      0.0              y = np.ascontiguousarray(y, dtype=DOUBLE)
   356
   357                                                   # Assign chunk of trees to jobs
   358         1           38     38.0      0.0          n_jobs, n_trees, _ = _partition_trees(self)
   359
   360                                                   # Precalculate the random states
   361         2           33     16.5      0.0          seeds = [random_state.randint(MAX_INT, size=i) for i in n_trees]
   362
   363                                                   # Parallel loop
   364         1           25     25.0      0.0          all_trees = Parallel(n_jobs=n_jobs, verbose=self.verbose)(
   365         1            9      9.0      0.0              delayed(_parallel_build_trees)(
   366                                                           n_trees[i],
   367                                                           self,
   368                                                           X,
   369                                                           y,
   370                                                           sample_weight,
   371                                                           sample_mask,
   372                                                           X_argsorted,
   373                                                           seeds[i],
   374                                                           verbose=self.verbose)
   375         1      4993905 4993905.0     96.1              for i in range(n_jobs))
   376
   377                                                   # Reduce
   378        11           97      8.8      0.0          self.estimators_ = [tree for tree in itertools.chain(*all_trees)]
   379
   380                                                   # Calculate out of bag predictions and score
   381         1            7      7.0      0.0          if self.oob_score:
   382                                                       if isinstance(self, ClassifierMixin):
   383                                                           self.oob_decision_function_ = []
   384                                                           self.oob_score_ = 0.0
   385                                                           n_classes_ = self.n_classes_
   386                                                           classes_ = self.classes_
   387
   388                                                           if self.n_outputs_ == 1:
   389                                                               n_classes_ = [n_classes_]
   390                                                               classes_ = [classes_]
   391
   392                                                           predictions = []
   393
   394                                                           for k in xrange(self.n_outputs_):
   395                                                               predictions.append(np.zeros((n_samples,
   396                                                                                            n_classes_[k])))
   397
   398                                                           for estimator in self.estimators_:
   399                                                               mask = np.ones(n_samples, dtype=np.bool)
   400                                                               mask[estimator.indices_] = False
   401                                                               p_estimator = estimator.predict_proba(X[mask, :])
   402
   403                                                               if self.n_outputs_ == 1:
   404                                                                   p_estimator = [p_estimator]
   405
   406                                                               for k in xrange(self.n_outputs_):
   407                                                                   predictions[k][mask, :] += p_estimator[k]
   408
   409                                                           for k in xrange(self.n_outputs_):
   410                                                               if (predictions[k].sum(axis=1) == 0).any():
   411                                                                   warn("Some inputs do not have OOB scores. "
   412                                                                        "This probably means too few trees were used "
   413                                                                        "to compute any reliable oob estimates.")
   414
   415                                                               decision = (predictions[k] /
   416                                                                           predictions[k].sum(axis=1)[:, np.newaxis])
   417                                                               self.oob_decision_function_.append(decision)
   418                                                               self.oob_score_ += np.mean(
   419                                                                   (y[:, k] == classes_[k].take(
   420                                                                       np.argmax(predictions[k], axis=1),
   421                                                                       axis=0)))
   422
   423                                                           if self.n_outputs_ == 1:
   424                                                               self.oob_decision_function_ = \
   425                                                                   self.oob_decision_function_[0]
   426
   427                                                           self.oob_score_ /= self.n_outputs_
   428
   429                                                       else:
   430                                                           # Regression:
   431                                                           predictions = np.zeros((n_samples, self.n_outputs_))
   432                                                           n_predictions = np.zeros((n_samples, self.n_outputs_))
   433
   434                                                           for estimator in self.estimators_:
   435                                                               mask = np.ones(n_samples, dtype=np.bool)
   436                                                               mask[estimator.indices_] = False
   437                                                               p_estimator = estimator.predict(X[mask, :])
   438
   439                                                               if self.n_outputs_ == 1:
   440                                                                   p_estimator = p_estimator[:, np.newaxis]
   441
   442                                                               predictions[mask, :] += p_estimator
   443                                                               n_predictions[mask, :] += 1
   444
   445                                                           if (n_predictions == 0).any():
   446                                                               warn("Some inputs do not have OOB scores. "
   447                                                                    "This probably means too few trees were used "
   448                                                                    "to compute any reliable oob estimates.")
   449                                                               n_predictions[n_predictions == 0] = 1
   450
   451                                                           predictions /= n_predictions
   452                                                           self.oob_prediction_ = predictions
   453
   454                                                           if self.n_outputs_ == 1:
   455                                                               self.oob_prediction_ = \
   456                                                                   self.oob_prediction_.reshape((n_samples, ))
   457
   458                                                           self.oob_score_ = 0.0
   459
   460                                                           for k in xrange(self.n_outputs_):
   461                                                               self.oob_score_ += r2_score(y[:, k],
   462                                                                                           predictions[:, k])
   463
   464                                                           self.oob_score_ /= self.n_outputs_
   465
   466         1            7      7.0      0.0          return self</pre>
</div>
</div>
</div>
<div class="section" id="gradientboostingclassifier-arcene">
<h2>GradientBoostingClassifier-arcene<a class="headerlink" href="#gradientboostingclassifier-arcene" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;arcene&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/GradientBoostingClassifier-arcene-step0-timing.png" src="_images/GradientBoostingClassifier-arcene-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/GradientBoostingClassifier-arcene-step0-memory.png" src="_images/GradientBoostingClassifier-arcene-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         11534 function calls in 42.105 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000   42.105   42.105 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000   42.104   42.104 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000   42.104   42.104 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:823(fit)
     1    0.002    0.002   42.104   42.104 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:488(fit)
   100    0.005    0.000   41.994    0.420 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:455(_fit_stage)
   100    0.014    0.000   41.876    0.419 /tmp/vb_sklearn/sklearn/tree/tree.py:194(fit)
   100   41.843    0.418   41.847    0.418 {method 'build' of 'sklearn.tree._tree.Tree' objects}
   100    0.018    0.000    0.105    0.001 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:141(update_terminal_regions)
   782    0.060    0.000    0.084    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:350(_update_terminal_region)
     1    0.000    0.000    0.081    0.081 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
     1    0.081    0.081    0.081    0.081 {method 'argsort' of 'numpy.ndarray' objects}
  1666    0.016    0.000    0.016    0.000 {method 'sum' of 'numpy.ndarray' objects}
   405    0.015    0.000    0.015    0.000 {numpy.core.multiarray.array}
   883    0.003    0.000    0.013    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     2    0.000    0.000    0.012    0.006 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
   100    0.006    0.000    0.008    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:340(__call__)
   100    0.002    0.000    0.007    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   100    0.006    0.000    0.006    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:346(negative_gradient)
  1664    0.006    0.000    0.006    0.000 {method 'take' of 'numpy.ndarray' objects}
   100    0.001    0.000    0.006    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
  1285    0.003    0.000    0.005    0.000 {isinstance}
   882    0.004    0.000    0.004    0.000 {numpy.core.multiarray.where}
     1    0.004    0.004    0.004    0.004 {method 'astype' of 'numpy.ndarray' objects}
   303    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
   101    0.001    0.000    0.004    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
     1    0.000    0.000    0.003    0.003 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     2    0.000    0.000    0.003    0.001 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
   100    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
   100    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
   100    0.002    0.000    0.002    0.000 {method 'apply' of 'sklearn.tree._tree.Tree' objects}
   100    0.000    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2299(mean)
   100    0.002    0.000    0.002    0.000 {method 'mean' of 'numpy.ndarray' objects}
   100    0.001    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:745(__init__)
   100    0.001    0.000    0.001    0.000 {method 'max' of 'numpy.ndarray' objects}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
   100    0.001    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:160(__init__)
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
   200    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
   100    0.001    0.000    0.001    0.000 {method 'copy' of 'numpy.ndarray' objects}
   400    0.001    0.000    0.001    0.000 {getattr}
   100    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
   201    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
   100    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
   101    0.000    0.000    0.000    0.000 {range}
   303    0.000    0.000    0.000    0.000 {len}
   101    0.000    0.000    0.000    0.000 {max}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
   102    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:78(fit)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:330(__init__)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:85(predict)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:337(init_estimator)
     4    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:118(__init__)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py
Function: fit at line 823
Total time: 42.3894 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   823                                               def fit(self, X, y):
   824                                                   """Fit the gradient boosting model.
   825
   826                                                   Parameters
   827                                                   ----------
   828                                                   X : array-like, shape = [n_samples, n_features]
   829                                                       Training vectors, where n_samples is the number of samples
   830                                                       and n_features is the number of features. Use fortran-style
   831                                                       to avoid memory copies.
   832
   833                                                   y : array-like, shape = [n_samples]
   834                                                       Target values (integers in classification, real numbers in
   835                                                       regression)
   836                                                       For classification, labels must correspond to classes
   837                                                       ``0, 1, ..., n_classes_-1``
   838
   839                                                   Returns
   840                                                   -------
   841                                                   self : object
   842                                                       Returns self.
   843                                                   """
   844         1          103    103.0      0.0          self.classes_ = np.unique(y)
   845         1            3      3.0      0.0          self.n_classes_ = len(self.classes_)
   846         1           16     16.0      0.0          y = np.searchsorted(self.classes_, y)
   847
   848         1     42389257 42389257.0    100.0          return super(GradientBoostingClassifier, self).fit(X, y)</pre>
</div>
</div>
</div>
<div class="section" id="gradientboostingclassifier-madelon">
<h2>GradientBoostingClassifier-madelon<a class="headerlink" href="#gradientboostingclassifier-madelon" title="Permalink to this headline">¶</a></h2>
<p><strong>Benchmark setup</strong></p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">deps</span> <span class="kn">import</span> <span class="n">load_data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s">&#39;madelon&#39;</span><span class="p">)</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p><strong>Benchmark statement</strong></p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">obj</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Execution time</strong></p>
<img alt="_images/GradientBoostingClassifier-madelon-step0-timing.png" src="_images/GradientBoostingClassifier-madelon-step0-timing.png" style="width: 6in;" />
<p><strong>Memory usage</strong></p>
<img alt="_images/GradientBoostingClassifier-madelon-step0-memory.png" src="_images/GradientBoostingClassifier-madelon-step0-memory.png" style="width: 6in;" />
<p><strong>Additional output</strong></p>
<div class="profiler-output container">
<p>cProfile</p>
<div class="highlight-python"><pre>         11622 function calls in 29.255 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    0.000    0.000   29.255   29.255 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/vbench/benchmark.py:286(f)
     1    0.000    0.000   29.255   29.255 &lt;f&gt;:1(&lt;module&gt;)
     1    0.000    0.000   29.255   29.255 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:823(fit)
     1    0.002    0.002   29.255   29.255 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:488(fit)
   100    0.005    0.000   29.027    0.290 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:455(_fit_stage)
   100    0.010    0.000   28.807    0.288 /tmp/vb_sklearn/sklearn/tree/tree.py:194(fit)
   100   28.778    0.288   28.781    0.288 {method 'build' of 'sklearn.tree._tree.Tree' objects}
   100    0.033    0.000    0.188    0.002 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:141(update_terminal_regions)
     1    0.000    0.000    0.141    0.141 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:598(argsort)
     1    0.141    0.141    0.141    0.141 {method 'argsort' of 'numpy.ndarray' objects}
   793    0.060    0.000    0.115    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:350(_update_terminal_region)
   100    0.063    0.001    0.066    0.001 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:340(__call__)
   100    0.037    0.000    0.037    0.000 {method 'apply' of 'sklearn.tree._tree.Tree' objects}
   893    0.030    0.000    0.030    0.000 {numpy.core.multiarray.where}
   100    0.026    0.000    0.026    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:346(negative_gradient)
  1688    0.019    0.000    0.019    0.000 {method 'sum' of 'numpy.ndarray' objects}
   405    0.015    0.000    0.015    0.000 {numpy.core.multiarray.array}
   894    0.003    0.000    0.014    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1379(sum)
     2    0.000    0.000    0.011    0.006 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:325(asfortranarray)
  1686    0.010    0.000    0.010    0.000 {method 'take' of 'numpy.ndarray' objects}
   100    0.002    0.000    0.007    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1774(amax)
   100    0.001    0.000    0.005    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:32(_wrapit)
  1296    0.003    0.000    0.005    0.000 {isinstance}
     1    0.004    0.004    0.004    0.004 {method 'astype' of 'numpy.ndarray' objects}
   303    0.001    0.000    0.004    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:167(asarray)
   101    0.001    0.000    0.004    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:234(check_random_state)
     1    0.000    0.000    0.004    0.004 /tmp/vb_sklearn/sklearn/utils/validation.py:127(check_arrays)
     2    0.000    0.000    0.003    0.002 /tmp/vb_sklearn/sklearn/utils/validation.py:15(_assert_all_finite)
   100    0.000    0.000    0.003    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2299(mean)
   100    0.002    0.000    0.002    0.000 {method 'mean' of 'numpy.ndarray' objects}
   100    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/abc.py:128(__instancecheck__)
   100    0.001    0.000    0.002    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/shape_base.py:6(atleast_1d)
   100    0.001    0.000    0.002    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:745(__init__)
   100    0.001    0.000    0.001    0.000 {method 'max' of 'numpy.ndarray' objects}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:237(asanyarray)
   100    0.001    0.000    0.001    0.000 /tmp/vb_sklearn/sklearn/tree/tree.py:160(__init__)
   100    0.001    0.000    0.001    0.000 {method 'copy' of 'numpy.ndarray' objects}
   100    0.000    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:107(reshape)
   200    0.001    0.000    0.001    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/_weakrefset.py:68(__contains__)
   100    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}
   201    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}
   400    0.000    0.000    0.000    0.000 {getattr}
   101    0.000    0.000    0.000    0.000 {range}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/lib/arraysetops.py:90(unique)
   100    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:449(isfortran)
   303    0.000    0.000    0.000    0.000 {len}
   101    0.000    0.000    0.000    0.000 {max}
   102    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:78(fit)
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:757(searchsorted)
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/base.py:553(isspmatrix)
     1    0.000    0.000    0.000    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}
     2    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/scipy/sparse/sputils.py:116(_isinstance)
     1    0.000    0.000    0.000    0.000 {method 'sort' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:85(predict)
     1    0.000    0.000    0.000    0.000 {numpy.core.multiarray.concatenate}
     3    0.000    0.000    0.000    0.000 {numpy.core.multiarray.empty}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:1044(ravel)
     3    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/utils/validation.py:120(_num_samples)
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:330(__init__)
     2    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 {method 'flatten' of 'numpy.ndarray' objects}
     1    0.000    0.000    0.000    0.000 /home/slave/virtualenvs/cpython-2.7.2/lib/python2.7/site-packages/numpy/core/numeric.py:1791(ones)
     4    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}
     6    0.000    0.000    0.000    0.000 {hasattr}
     2    0.000    0.000    0.000    0.000 {numpy.core.multiarray.zeros}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:337(init_estimator)
     5    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}
     1    0.000    0.000    0.000    0.000 /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py:118(__init__)
     1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}</pre>
</div>
<p>LineProfiler</p>
<div class="highlight-python"><pre>   Timer unit: 1e-06 s

File: /tmp/vb_sklearn/sklearn/ensemble/gradient_boosting.py
Function: fit at line 823
Total time: 29.4017 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   823                                               def fit(self, X, y):
   824                                                   """Fit the gradient boosting model.
   825
   826                                                   Parameters
   827                                                   ----------
   828                                                   X : array-like, shape = [n_samples, n_features]
   829                                                       Training vectors, where n_samples is the number of samples
   830                                                       and n_features is the number of features. Use fortran-style
   831                                                       to avoid memory copies.
   832
   833                                                   y : array-like, shape = [n_samples]
   834                                                       Target values (integers in classification, real numbers in
   835                                                       regression)
   836                                                       For classification, labels must correspond to classes
   837                                                       ``0, 1, ..., n_classes_-1``
   838
   839                                                   Returns
   840                                                   -------
   841                                                   self : object
   842                                                       Returns self.
   843                                                   """
   844         1          208    208.0      0.0          self.classes_ = np.unique(y)
   845         1            4      4.0      0.0          self.n_classes_ = len(self.classes_)
   846         1           94     94.0      0.0          y = np.searchsorted(self.classes_, y)
   847
   848         1     29401379 29401379.0    100.0          return super(GradientBoostingClassifier, self).fit(X, y)</pre>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>

        <div class="clearer"></div>
      </div>
    </div>
  

    <div class="footer">
        &copy; .
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3. Design by <a href="http://desgrana.es">Desgrana</a>.
    <span style="padding-left: 5ex;">
    <a href="_sources/vb_ensemble.txt"
	    rel="nofollow">Show this page source</a>
    </span>
    </div>
     <div class="rel rellarge">
    
    <div class="buttonPrevious">
      <a href="vb_decomposition.html">
        Previous
      </a>  
    </div>
    <div class="buttonNext">
      <a href="vb_gaussian_process.html">
        Next
      </a>  
    </div>
    
     </div>
     <script type="text/javascript">
       $("div.buttonNext, div.buttonPrevious").hover(
           function () {
               $(this).css('background-color', '#FF9C34');
           },
           function () {
               $(this).css('background-color', '#A7D6E2');
           }
       );
     </script>
  </body>
</html>